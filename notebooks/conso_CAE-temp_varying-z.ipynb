{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "from scipy import stats\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "path_main_folder = '/home/antorosi/Documents/AutoEncoder'\n",
    "\n",
    "sys.path.append(path_main_folder)\n",
    "\n",
    "from CVAE.cvae import compile_cvae, run_cvae\n",
    "from CVAE.cvae_model import CVAE_temp\n",
    "from conso.load_shape_data import *  \n",
    "from conso.conso_helpers import plot_latent_space_projection, pyplot_latent_space_projection_temp, pyplot_latent_space_projection_error\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and shape data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "path_data = os.path.join(path_main_folder, 'data')\n",
    "dict_data_conso = load_data_conso(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Holiday day information\n",
    "holiday_days_csv = os.path.join(path_data, \"joursFeries.csv\")\n",
    "holiday_days_df = pd.read_csv(holiday_days_csv, sep=\";\")\n",
    "holiday_days_df.ds = pd.to_datetime(holiday_days_df.ds)\n",
    "holiday_days_df['is_hd'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unifomization\n",
    "data_conso_df, dict_colnames_conso = get_uniformed_data_conso(dict_data_conso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change ganularity ?\n",
    "name_granu = '30m'\n",
    "data_conso_df = change_granularity(data_conso_df, granularity=\"30min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x_conso dataframe for autoencoder purpose\n",
    "x_conso = get_x_conso_autoencoder(data_conso_df, dict_colnames_conso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "date_test_start = datetime.date(2017,1,1)\n",
    "date_test_end = datetime.date(2017,12,31)\n",
    "dict_xconso = get_train_test_x_conso(x_conso, date_test_start, date_test_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize x_conso\n",
    "type_scaler = 's'\n",
    "dict_xconso, _ = normalize_xconso(dict_xconso, dict_colnames_conso, type_scaler = 'standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_type_cond = 'm-wd-temp'\n",
    "name_train = '1234' # 1: first period ; 0 all periods\n",
    "name_type_x = 'c'\n",
    "type_x = ['conso']\n",
    "type_cond = ['month', 'weekday', 'temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset_autoencoder(dict_xconso=dict_xconso, type_x=type_x, type_cond=type_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify dataset to fit with new data format\n",
    "for type_set in ['train', 'test']:\n",
    "    \n",
    "    cond_pre = dataset[type_set]['x'][1][:,:14]\n",
    "    to_emb = dataset[type_set]['x'][1][:,14:]\n",
    "    x = dataset[type_set]['x'][0]\n",
    "\n",
    "    dataset[type_set]['x'] = [x, cond_pre, to_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 48)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['x'][2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = os.path.join(path_main_folder, 'out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "e_dims=[24,12]\n",
    "d_dims=[12,24]\n",
    "emb_dims=[2]\n",
    "cond_pre_dim = dataset['train']['x'][1].shape[1]\n",
    "input_dim = dataset['train']['x'][0].shape[1]\n",
    "to_emb_dim = dataset['train']['x'][2].shape[1]\n",
    "z_dims = list(np.arange(1,13))\n",
    "beta = 0\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_benchmark = os.path.join(path_out,'benchmark_cae_1')\n",
    "\n",
    "if not os.path.exists(path_benchmark):\n",
    "    os.mkdir(path_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_benchmark,\"config.txt\"),'w') as file: \n",
    "    file.write('cond pred dim : ' + str(cond_pre_dim) + '\\n')\n",
    "    file.write('emb_dims : ' + str(emb_dims) + '\\n')\n",
    "    file.write('e_dims : ' + str(e_dims) + '\\n') \n",
    "    file.write('d_dims : ' + str(d_dims) + '\\n') \n",
    "    file.write('train_set : ' + str(name_train) + '\\n') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['name', 'z_dim','emb_dims','layer_dims','batchsize','best_iter',\n",
    "                                           'train_mse', 'test_mse', 'last_train_mse', 'last_test_mse'])\n",
    "path_results = path_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= Model1=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 1), (None, 1 1886        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 1)            0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1728        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,712\n",
      "Trainable params: 3,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 1)            13          enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 1)            13          enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,886\n",
      "Trainable params: 1,886\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 17)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           216         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n",
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 135us/step - loss: 28.6660 - kl_loss: 39.5929 - recon_loss: 28.6660 - val_loss: 12.5888 - val_kl_loss: 90.6695 - val_recon_loss: 12.5888\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 7.2444 - kl_loss: 92.4101 - recon_loss: 7.2444 - val_loss: 3.7382 - val_kl_loss: 115.4001 - val_recon_loss: 3.7382\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 2.6934 - kl_loss: 100.2890 - recon_loss: 2.6934 - val_loss: 2.1878 - val_kl_loss: 116.9913 - val_recon_loss: 2.1878\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 1.8089 - kl_loss: 96.7952 - recon_loss: 1.8089 - val_loss: 1.4462 - val_kl_loss: 113.2349 - val_recon_loss: 1.4462\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 1.3776 - kl_loss: 94.1120 - recon_loss: 1.3776 - val_loss: 1.4425 - val_kl_loss: 110.0508 - val_recon_loss: 1.4425\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 1.1612 - kl_loss: 93.5182 - recon_loss: 1.1612 - val_loss: 1.0240 - val_kl_loss: 111.4668 - val_recon_loss: 1.0240\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 67us/step - loss: 1.0216 - kl_loss: 91.9087 - recon_loss: 1.0216 - val_loss: 0.9600 - val_kl_loss: 110.3403 - val_recon_loss: 0.9600\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.9232 - kl_loss: 91.9167 - recon_loss: 0.9232 - val_loss: 0.9434 - val_kl_loss: 117.1712 - val_recon_loss: 0.9434\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.8733 - kl_loss: 92.1265 - recon_loss: 0.8733 - val_loss: 0.8033 - val_kl_loss: 108.6713 - val_recon_loss: 0.8033\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.8236 - kl_loss: 90.9472 - recon_loss: 0.8236 - val_loss: 0.8660 - val_kl_loss: 110.8176 - val_recon_loss: 0.8660\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.7893 - kl_loss: 89.3433 - recon_loss: 0.7893 - val_loss: 0.8551 - val_kl_loss: 112.8303 - val_recon_loss: 0.8551\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.7675 - kl_loss: 88.2131 - recon_loss: 0.7675 - val_loss: 0.7449 - val_kl_loss: 107.6729 - val_recon_loss: 0.7449\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.7371 - kl_loss: 87.3320 - recon_loss: 0.7371 - val_loss: 0.9469 - val_kl_loss: 99.6494 - val_recon_loss: 0.9469\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.7125 - kl_loss: 85.5947 - recon_loss: 0.7125 - val_loss: 1.0472 - val_kl_loss: 95.2739 - val_recon_loss: 1.0472\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.7031 - kl_loss: 84.8517 - recon_loss: 0.7031 - val_loss: 0.9329 - val_kl_loss: 108.1131 - val_recon_loss: 0.9329\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.6769 - kl_loss: 83.8745 - recon_loss: 0.6769 - val_loss: 0.6670 - val_kl_loss: 100.9831 - val_recon_loss: 0.6670\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.6626 - kl_loss: 82.0643 - recon_loss: 0.6626 - val_loss: 0.6602 - val_kl_loss: 95.2149 - val_recon_loss: 0.6602\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.6481 - kl_loss: 80.4049 - recon_loss: 0.6481 - val_loss: 0.7971 - val_kl_loss: 95.2434 - val_recon_loss: 0.7971\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.6251 - kl_loss: 78.3731 - recon_loss: 0.6251 - val_loss: 0.7001 - val_kl_loss: 95.1118 - val_recon_loss: 0.7001\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.6157 - kl_loss: 77.1333 - recon_loss: 0.6157 - val_loss: 0.5897 - val_kl_loss: 95.6887 - val_recon_loss: 0.5897\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.5958 - kl_loss: 76.5174 - recon_loss: 0.5958 - val_loss: 0.7832 - val_kl_loss: 88.3803 - val_recon_loss: 0.7832\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.5914 - kl_loss: 75.7853 - recon_loss: 0.5914 - val_loss: 0.6731 - val_kl_loss: 91.4272 - val_recon_loss: 0.6731\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.5737 - kl_loss: 75.2370 - recon_loss: 0.5737 - val_loss: 1.0367 - val_kl_loss: 91.8169 - val_recon_loss: 1.0367\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.5734 - kl_loss: 74.8593 - recon_loss: 0.5734 - val_loss: 0.5656 - val_kl_loss: 89.3785 - val_recon_loss: 0.5656\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.5649 - kl_loss: 73.7525 - recon_loss: 0.5649 - val_loss: 0.8690 - val_kl_loss: 87.6721 - val_recon_loss: 0.8690\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.5571 - kl_loss: 73.4433 - recon_loss: 0.5571 - val_loss: 0.8877 - val_kl_loss: 86.2500 - val_recon_loss: 0.8877\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.5593 - kl_loss: 71.9891 - recon_loss: 0.5593 - val_loss: 0.5571 - val_kl_loss: 85.8276 - val_recon_loss: 0.5571\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.5452 - kl_loss: 71.3909 - recon_loss: 0.5452 - val_loss: 0.8108 - val_kl_loss: 95.9312 - val_recon_loss: 0.8108\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.5401 - kl_loss: 71.4505 - recon_loss: 0.5401 - val_loss: 0.5882 - val_kl_loss: 86.1858 - val_recon_loss: 0.5882\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.5345 - kl_loss: 70.7946 - recon_loss: 0.5345 - val_loss: 0.6379 - val_kl_loss: 85.6357 - val_recon_loss: 0.6379\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.5296 - kl_loss: 69.3042 - recon_loss: 0.5296 - val_loss: 0.5248 - val_kl_loss: 82.7795 - val_recon_loss: 0.5248\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.5281 - kl_loss: 68.3672 - recon_loss: 0.5281 - val_loss: 0.5828 - val_kl_loss: 81.3813 - val_recon_loss: 0.5828\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.5219 - kl_loss: 67.4856 - recon_loss: 0.5219 - val_loss: 0.6184 - val_kl_loss: 80.2733 - val_recon_loss: 0.6184\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.5145 - kl_loss: 66.4476 - recon_loss: 0.5145 - val_loss: 0.5899 - val_kl_loss: 81.0966 - val_recon_loss: 0.5899\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.5115 - kl_loss: 65.5690 - recon_loss: 0.5115 - val_loss: 0.5744 - val_kl_loss: 79.0768 - val_recon_loss: 0.5744\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.5091 - kl_loss: 64.8130 - recon_loss: 0.5091 - val_loss: 0.6017 - val_kl_loss: 76.9886 - val_recon_loss: 0.6017\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.5060 - kl_loss: 64.2174 - recon_loss: 0.5060 - val_loss: 0.7862 - val_kl_loss: 72.9092 - val_recon_loss: 0.7862\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.5009 - kl_loss: 63.4389 - recon_loss: 0.5009 - val_loss: 0.4921 - val_kl_loss: 74.9521 - val_recon_loss: 0.4921\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.4954 - kl_loss: 62.7467 - recon_loss: 0.4954 - val_loss: 0.5663 - val_kl_loss: 72.2479 - val_recon_loss: 0.5663\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.4906 - kl_loss: 61.9488 - recon_loss: 0.4906 - val_loss: 0.7853 - val_kl_loss: 71.1142 - val_recon_loss: 0.7853\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.4926 - kl_loss: 61.3065 - recon_loss: 0.4926 - val_loss: 0.7546 - val_kl_loss: 66.3829 - val_recon_loss: 0.7546\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.4847 - kl_loss: 60.0355 - recon_loss: 0.4847 - val_loss: 0.7018 - val_kl_loss: 64.9370 - val_recon_loss: 0.7018\n",
      "Epoch 43/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.4823 - kl_loss: 59.2750 - recon_loss: 0.4823 - val_loss: 0.4743 - val_kl_loss: 71.0530 - val_recon_loss: 0.4743\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.4802 - kl_loss: 58.8174 - recon_loss: 0.4802 - val_loss: 0.5403 - val_kl_loss: 71.8037 - val_recon_loss: 0.5403\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.4813 - kl_loss: 57.8707 - recon_loss: 0.4813 - val_loss: 0.5255 - val_kl_loss: 66.6695 - val_recon_loss: 0.5255\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.4651 - kl_loss: 57.2592 - recon_loss: 0.4651 - val_loss: 0.5453 - val_kl_loss: 70.7605 - val_recon_loss: 0.5453\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.4702 - kl_loss: 56.7466 - recon_loss: 0.4702 - val_loss: 0.5546 - val_kl_loss: 69.3748 - val_recon_loss: 0.5546\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.4659 - kl_loss: 56.1059 - recon_loss: 0.4659 - val_loss: 0.5697 - val_kl_loss: 68.4202 - val_recon_loss: 0.5697\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.4626 - kl_loss: 55.1827 - recon_loss: 0.4626 - val_loss: 0.4785 - val_kl_loss: 68.3391 - val_recon_loss: 0.4785\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.4560 - kl_loss: 54.7904 - recon_loss: 0.4560 - val_loss: 0.5122 - val_kl_loss: 63.9769 - val_recon_loss: 0.5122\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.4547 - kl_loss: 53.7321 - recon_loss: 0.4547 - val_loss: 0.5229 - val_kl_loss: 67.5081 - val_recon_loss: 0.5229\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.4582 - kl_loss: 53.7492 - recon_loss: 0.4582 - val_loss: 0.6101 - val_kl_loss: 64.4054 - val_recon_loss: 0.6101\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.4442 - kl_loss: 54.0641 - recon_loss: 0.4442 - val_loss: 0.5840 - val_kl_loss: 63.0942 - val_recon_loss: 0.5840\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.4487 - kl_loss: 54.2644 - recon_loss: 0.4487 - val_loss: 0.4919 - val_kl_loss: 61.6769 - val_recon_loss: 0.4919\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.4491 - kl_loss: 53.6895 - recon_loss: 0.4491 - val_loss: 0.4913 - val_kl_loss: 62.9910 - val_recon_loss: 0.4913\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.4394 - kl_loss: 53.1812 - recon_loss: 0.4394 - val_loss: 0.4529 - val_kl_loss: 63.6464 - val_recon_loss: 0.4529\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.4398 - kl_loss: 52.7122 - recon_loss: 0.4398 - val_loss: 0.4685 - val_kl_loss: 63.2922 - val_recon_loss: 0.4685\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.4403 - kl_loss: 52.5216 - recon_loss: 0.4403 - val_loss: 0.4430 - val_kl_loss: 63.3045 - val_recon_loss: 0.4430\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.4316 - kl_loss: 52.1511 - recon_loss: 0.4316 - val_loss: 0.4955 - val_kl_loss: 60.2971 - val_recon_loss: 0.4955\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.4286 - kl_loss: 52.6526 - recon_loss: 0.4286 - val_loss: 0.5399 - val_kl_loss: 62.8234 - val_recon_loss: 0.5399\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.4314 - kl_loss: 52.4792 - recon_loss: 0.4314 - val_loss: 0.4004 - val_kl_loss: 62.0334 - val_recon_loss: 0.4004\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.4215 - kl_loss: 52.3868 - recon_loss: 0.4215 - val_loss: 0.6142 - val_kl_loss: 66.6047 - val_recon_loss: 0.6142\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.4223 - kl_loss: 52.5161 - recon_loss: 0.4223 - val_loss: 0.4489 - val_kl_loss: 63.8081 - val_recon_loss: 0.4489\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.4149 - kl_loss: 52.0509 - recon_loss: 0.4149 - val_loss: 0.5277 - val_kl_loss: 65.6570 - val_recon_loss: 0.5277\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.4150 - kl_loss: 51.9507 - recon_loss: 0.4150 - val_loss: 0.4158 - val_kl_loss: 61.7190 - val_recon_loss: 0.4158\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.4095 - kl_loss: 51.1508 - recon_loss: 0.4095 - val_loss: 0.4717 - val_kl_loss: 63.9858 - val_recon_loss: 0.4717\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.4112 - kl_loss: 51.0274 - recon_loss: 0.4112 - val_loss: 0.4069 - val_kl_loss: 60.5197 - val_recon_loss: 0.4069\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.4030 - kl_loss: 50.9506 - recon_loss: 0.4030 - val_loss: 0.5068 - val_kl_loss: 64.2554 - val_recon_loss: 0.5068\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.4047 - kl_loss: 50.9695 - recon_loss: 0.4047 - val_loss: 0.3647 - val_kl_loss: 60.7019 - val_recon_loss: 0.3647\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3987 - kl_loss: 50.3944 - recon_loss: 0.3987 - val_loss: 0.4600 - val_kl_loss: 57.7719 - val_recon_loss: 0.4600\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3953 - kl_loss: 49.8502 - recon_loss: 0.3953 - val_loss: 0.7092 - val_kl_loss: 64.3165 - val_recon_loss: 0.7092\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3930 - kl_loss: 49.5113 - recon_loss: 0.3930 - val_loss: 0.4309 - val_kl_loss: 59.6420 - val_recon_loss: 0.4309\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3928 - kl_loss: 49.8054 - recon_loss: 0.3928 - val_loss: 0.4682 - val_kl_loss: 57.5798 - val_recon_loss: 0.4682\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3848 - kl_loss: 49.8279 - recon_loss: 0.3848 - val_loss: 0.4748 - val_kl_loss: 56.4191 - val_recon_loss: 0.4748\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3823 - kl_loss: 48.9703 - recon_loss: 0.3823 - val_loss: 0.3839 - val_kl_loss: 57.1980 - val_recon_loss: 0.3839\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.3858 - kl_loss: 48.5022 - recon_loss: 0.3858 - val_loss: 0.3659 - val_kl_loss: 58.7517 - val_recon_loss: 0.3659\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3795 - kl_loss: 48.7191 - recon_loss: 0.3795 - val_loss: 0.5634 - val_kl_loss: 55.3289 - val_recon_loss: 0.5634\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3808 - kl_loss: 48.5177 - recon_loss: 0.3808 - val_loss: 0.4125 - val_kl_loss: 57.3305 - val_recon_loss: 0.4125\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.3742 - kl_loss: 47.8044 - recon_loss: 0.3742 - val_loss: 0.8772 - val_kl_loss: 61.9002 - val_recon_loss: 0.8772\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3753 - kl_loss: 48.1061 - recon_loss: 0.3753 - val_loss: 0.3638 - val_kl_loss: 58.4021 - val_recon_loss: 0.3638\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3648 - kl_loss: 47.7637 - recon_loss: 0.3648 - val_loss: 0.3571 - val_kl_loss: 56.8360 - val_recon_loss: 0.3571\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.3669 - kl_loss: 47.6562 - recon_loss: 0.3669 - val_loss: 0.4500 - val_kl_loss: 56.4232 - val_recon_loss: 0.4500\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3691 - kl_loss: 47.5306 - recon_loss: 0.3691 - val_loss: 0.3924 - val_kl_loss: 57.1029 - val_recon_loss: 0.3924\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3629 - kl_loss: 47.1597 - recon_loss: 0.3629 - val_loss: 0.3859 - val_kl_loss: 55.0839 - val_recon_loss: 0.3859\n",
      "Epoch 85/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3570 - kl_loss: 46.5488 - recon_loss: 0.3570 - val_loss: 0.3722 - val_kl_loss: 55.8262 - val_recon_loss: 0.3722\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.3611 - kl_loss: 46.0708 - recon_loss: 0.3611 - val_loss: 0.3532 - val_kl_loss: 55.2909 - val_recon_loss: 0.3532\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3563 - kl_loss: 46.0110 - recon_loss: 0.3563 - val_loss: 0.3679 - val_kl_loss: 53.9798 - val_recon_loss: 0.3679\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3599 - kl_loss: 45.4467 - recon_loss: 0.3599 - val_loss: 0.4402 - val_kl_loss: 55.7116 - val_recon_loss: 0.4402\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3535 - kl_loss: 44.9876 - recon_loss: 0.3535 - val_loss: 0.3841 - val_kl_loss: 53.6767 - val_recon_loss: 0.3841\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3623 - kl_loss: 44.8525 - recon_loss: 0.3623 - val_loss: 0.3466 - val_kl_loss: 53.3453 - val_recon_loss: 0.3466\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3522 - kl_loss: 44.8020 - recon_loss: 0.3522 - val_loss: 0.3795 - val_kl_loss: 53.5499 - val_recon_loss: 0.3795\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3518 - kl_loss: 43.9439 - recon_loss: 0.3518 - val_loss: 0.4353 - val_kl_loss: 51.6222 - val_recon_loss: 0.4353\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3545 - kl_loss: 43.8617 - recon_loss: 0.3545 - val_loss: 0.3823 - val_kl_loss: 51.5045 - val_recon_loss: 0.3823\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3478 - kl_loss: 43.4110 - recon_loss: 0.3478 - val_loss: 0.3324 - val_kl_loss: 51.5841 - val_recon_loss: 0.3324\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3469 - kl_loss: 43.7640 - recon_loss: 0.3469 - val_loss: 0.3249 - val_kl_loss: 51.2701 - val_recon_loss: 0.3249\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3420 - kl_loss: 43.6172 - recon_loss: 0.3420 - val_loss: 0.3526 - val_kl_loss: 52.0862 - val_recon_loss: 0.3526\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3470 - kl_loss: 43.8060 - recon_loss: 0.3470 - val_loss: 0.3408 - val_kl_loss: 52.3400 - val_recon_loss: 0.3408\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3447 - kl_loss: 43.6038 - recon_loss: 0.3447 - val_loss: 0.5484 - val_kl_loss: 55.5956 - val_recon_loss: 0.5484\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3441 - kl_loss: 43.6068 - recon_loss: 0.3441 - val_loss: 0.3248 - val_kl_loss: 51.7764 - val_recon_loss: 0.3248\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3424 - kl_loss: 43.4135 - recon_loss: 0.3424 - val_loss: 0.3503 - val_kl_loss: 50.5715 - val_recon_loss: 0.3503\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3455 - kl_loss: 43.1848 - recon_loss: 0.3455 - val_loss: 0.3625 - val_kl_loss: 51.4773 - val_recon_loss: 0.3625\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3448 - kl_loss: 42.9144 - recon_loss: 0.3448 - val_loss: 0.4113 - val_kl_loss: 49.3767 - val_recon_loss: 0.4113\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3365 - kl_loss: 42.5714 - recon_loss: 0.3365 - val_loss: 0.4021 - val_kl_loss: 50.9392 - val_recon_loss: 0.4021\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3436 - kl_loss: 42.4800 - recon_loss: 0.3436 - val_loss: 0.3654 - val_kl_loss: 50.3474 - val_recon_loss: 0.3654\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3396 - kl_loss: 42.5509 - recon_loss: 0.3396 - val_loss: 0.3479 - val_kl_loss: 51.5934 - val_recon_loss: 0.3479\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3386 - kl_loss: 42.6013 - recon_loss: 0.3386 - val_loss: 0.4250 - val_kl_loss: 53.0942 - val_recon_loss: 0.4250\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3396 - kl_loss: 42.7950 - recon_loss: 0.3396 - val_loss: 0.3073 - val_kl_loss: 50.7073 - val_recon_loss: 0.3073\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3363 - kl_loss: 42.5145 - recon_loss: 0.3363 - val_loss: 0.3403 - val_kl_loss: 51.4812 - val_recon_loss: 0.3403\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3387 - kl_loss: 42.0499 - recon_loss: 0.3387 - val_loss: 0.3513 - val_kl_loss: 48.3945 - val_recon_loss: 0.3513\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3302 - kl_loss: 41.3460 - recon_loss: 0.3302 - val_loss: 0.4660 - val_kl_loss: 49.9435 - val_recon_loss: 0.4660\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3396 - kl_loss: 41.1147 - recon_loss: 0.3396 - val_loss: 0.3773 - val_kl_loss: 46.6047 - val_recon_loss: 0.3773\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3367 - kl_loss: 40.6299 - recon_loss: 0.3367 - val_loss: 0.3458 - val_kl_loss: 46.4883 - val_recon_loss: 0.3458\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3314 - kl_loss: 39.9217 - recon_loss: 0.3314 - val_loss: 0.4192 - val_kl_loss: 45.3404 - val_recon_loss: 0.4192\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3314 - kl_loss: 39.8440 - recon_loss: 0.3314 - val_loss: 0.4948 - val_kl_loss: 45.0508 - val_recon_loss: 0.4948\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3311 - kl_loss: 38.7981 - recon_loss: 0.3311 - val_loss: 0.4853 - val_kl_loss: 47.4830 - val_recon_loss: 0.4853\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3345 - kl_loss: 38.5503 - recon_loss: 0.3345 - val_loss: 0.3587 - val_kl_loss: 46.5287 - val_recon_loss: 0.3587\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.3244 - kl_loss: 38.3268 - recon_loss: 0.3244 - val_loss: 0.3670 - val_kl_loss: 43.9771 - val_recon_loss: 0.3670\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3291 - kl_loss: 38.2322 - recon_loss: 0.3291 - val_loss: 0.3979 - val_kl_loss: 42.7057 - val_recon_loss: 0.3979\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3283 - kl_loss: 38.1564 - recon_loss: 0.3283 - val_loss: 0.3531 - val_kl_loss: 44.9961 - val_recon_loss: 0.3531\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3286 - kl_loss: 38.1219 - recon_loss: 0.3286 - val_loss: 0.3550 - val_kl_loss: 45.5643 - val_recon_loss: 0.3550\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3301 - kl_loss: 37.9042 - recon_loss: 0.3301 - val_loss: 0.3138 - val_kl_loss: 44.6906 - val_recon_loss: 0.3138\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3293 - kl_loss: 37.5040 - recon_loss: 0.3293 - val_loss: 0.3139 - val_kl_loss: 44.5285 - val_recon_loss: 0.3139\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3252 - kl_loss: 37.4127 - recon_loss: 0.3252 - val_loss: 0.5233 - val_kl_loss: 44.0258 - val_recon_loss: 0.5233\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3291 - kl_loss: 37.4114 - recon_loss: 0.3291 - val_loss: 0.3325 - val_kl_loss: 44.1812 - val_recon_loss: 0.3325\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3261 - kl_loss: 37.1318 - recon_loss: 0.3261 - val_loss: 0.3512 - val_kl_loss: 44.0164 - val_recon_loss: 0.3512\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3275 - kl_loss: 36.8309 - recon_loss: 0.3275 - val_loss: 0.3533 - val_kl_loss: 41.9630 - val_recon_loss: 0.3533\n",
      "Epoch 127/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.3281 - kl_loss: 36.2424 - recon_loss: 0.3281 - val_loss: 0.3335 - val_kl_loss: 42.0295 - val_recon_loss: 0.3335\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3299 - kl_loss: 36.2272 - recon_loss: 0.3299 - val_loss: 0.3757 - val_kl_loss: 44.2833 - val_recon_loss: 0.3757\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3229 - kl_loss: 36.2707 - recon_loss: 0.3229 - val_loss: 0.3691 - val_kl_loss: 41.2042 - val_recon_loss: 0.3691\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3223 - kl_loss: 36.3640 - recon_loss: 0.3223 - val_loss: 0.4029 - val_kl_loss: 42.1909 - val_recon_loss: 0.4029\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3222 - kl_loss: 36.3281 - recon_loss: 0.3222 - val_loss: 0.3501 - val_kl_loss: 43.3687 - val_recon_loss: 0.3501\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3221 - kl_loss: 36.3981 - recon_loss: 0.3221 - val_loss: 0.3229 - val_kl_loss: 42.3384 - val_recon_loss: 0.3229\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.3227 - kl_loss: 36.2067 - recon_loss: 0.3227 - val_loss: 0.3533 - val_kl_loss: 41.8547 - val_recon_loss: 0.3533\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3187 - kl_loss: 36.1573 - recon_loss: 0.3187 - val_loss: 0.3419 - val_kl_loss: 41.9017 - val_recon_loss: 0.3419\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3203 - kl_loss: 36.0552 - recon_loss: 0.3203 - val_loss: 0.3495 - val_kl_loss: 43.2809 - val_recon_loss: 0.3495\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3182 - kl_loss: 36.1405 - recon_loss: 0.3182 - val_loss: 0.3627 - val_kl_loss: 42.3379 - val_recon_loss: 0.3627\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3164 - kl_loss: 36.2364 - recon_loss: 0.3164 - val_loss: 0.3377 - val_kl_loss: 42.2565 - val_recon_loss: 0.3377\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3185 - kl_loss: 35.8789 - recon_loss: 0.3185 - val_loss: 0.3335 - val_kl_loss: 42.3606 - val_recon_loss: 0.3335\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3192 - kl_loss: 35.7541 - recon_loss: 0.3192 - val_loss: 0.5169 - val_kl_loss: 39.8949 - val_recon_loss: 0.5169\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3173 - kl_loss: 35.6263 - recon_loss: 0.3173 - val_loss: 0.3357 - val_kl_loss: 40.4912 - val_recon_loss: 0.3357\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3185 - kl_loss: 35.2884 - recon_loss: 0.3185 - val_loss: 0.4438 - val_kl_loss: 41.2865 - val_recon_loss: 0.4438\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3206 - kl_loss: 35.1215 - recon_loss: 0.3206 - val_loss: 0.3863 - val_kl_loss: 41.4303 - val_recon_loss: 0.3863\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3170 - kl_loss: 34.8977 - recon_loss: 0.3170 - val_loss: 0.3578 - val_kl_loss: 42.0034 - val_recon_loss: 0.3578\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3208 - kl_loss: 34.8847 - recon_loss: 0.3208 - val_loss: 0.3974 - val_kl_loss: 41.6082 - val_recon_loss: 0.3974\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3102 - kl_loss: 34.8342 - recon_loss: 0.3102 - val_loss: 0.3307 - val_kl_loss: 40.4716 - val_recon_loss: 0.3307\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.3144 - kl_loss: 34.8461 - recon_loss: 0.3144 - val_loss: 0.3784 - val_kl_loss: 40.2653 - val_recon_loss: 0.3784\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3115 - kl_loss: 35.2788 - recon_loss: 0.3115 - val_loss: 0.3523 - val_kl_loss: 41.3214 - val_recon_loss: 0.3523\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.3153 - kl_loss: 35.4016 - recon_loss: 0.3153 - val_loss: 0.2834 - val_kl_loss: 41.9142 - val_recon_loss: 0.2834\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3135 - kl_loss: 35.2493 - recon_loss: 0.3135 - val_loss: 0.3508 - val_kl_loss: 41.4519 - val_recon_loss: 0.3508\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3111 - kl_loss: 35.2636 - recon_loss: 0.3111 - val_loss: 0.2945 - val_kl_loss: 40.9532 - val_recon_loss: 0.2945\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3136 - kl_loss: 35.1614 - recon_loss: 0.3136 - val_loss: 0.3422 - val_kl_loss: 41.4490 - val_recon_loss: 0.3422\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3111 - kl_loss: 35.0988 - recon_loss: 0.3111 - val_loss: 0.3300 - val_kl_loss: 41.3288 - val_recon_loss: 0.3300\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3159 - kl_loss: 34.9573 - recon_loss: 0.3159 - val_loss: 0.2967 - val_kl_loss: 40.2326 - val_recon_loss: 0.2967\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3117 - kl_loss: 34.7227 - recon_loss: 0.3117 - val_loss: 0.3467 - val_kl_loss: 40.2808 - val_recon_loss: 0.3467\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3125 - kl_loss: 34.5359 - recon_loss: 0.3125 - val_loss: 0.2839 - val_kl_loss: 39.8635 - val_recon_loss: 0.2839\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3057 - kl_loss: 34.5312 - recon_loss: 0.3057 - val_loss: 0.3230 - val_kl_loss: 39.6250 - val_recon_loss: 0.3230\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3110 - kl_loss: 34.5008 - recon_loss: 0.3110 - val_loss: 0.3035 - val_kl_loss: 39.9350 - val_recon_loss: 0.3035\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3090 - kl_loss: 34.3017 - recon_loss: 0.3090 - val_loss: 0.3123 - val_kl_loss: 38.6705 - val_recon_loss: 0.3123\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.3095 - kl_loss: 34.1919 - recon_loss: 0.3095 - val_loss: 0.4227 - val_kl_loss: 40.2667 - val_recon_loss: 0.4227\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3092 - kl_loss: 34.2056 - recon_loss: 0.3092 - val_loss: 0.3709 - val_kl_loss: 39.3723 - val_recon_loss: 0.3709\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.3056 - kl_loss: 34.1718 - recon_loss: 0.3056 - val_loss: 0.3875 - val_kl_loss: 41.0241 - val_recon_loss: 0.3875\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 63us/step - loss: 0.3068 - kl_loss: 34.1568 - recon_loss: 0.3068 - val_loss: 0.4002 - val_kl_loss: 39.5253 - val_recon_loss: 0.4002\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3046 - kl_loss: 34.2391 - recon_loss: 0.3046 - val_loss: 0.4912 - val_kl_loss: 40.6152 - val_recon_loss: 0.4912\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3083 - kl_loss: 33.9660 - recon_loss: 0.3083 - val_loss: 0.3627 - val_kl_loss: 39.3656 - val_recon_loss: 0.3627\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3065 - kl_loss: 33.7468 - recon_loss: 0.3065 - val_loss: 0.4997 - val_kl_loss: 36.6523 - val_recon_loss: 0.4997\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3075 - kl_loss: 33.7709 - recon_loss: 0.3075 - val_loss: 0.3066 - val_kl_loss: 39.2458 - val_recon_loss: 0.3066\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3033 - kl_loss: 33.7100 - recon_loss: 0.3033 - val_loss: 0.3987 - val_kl_loss: 41.1499 - val_recon_loss: 0.3987\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3041 - kl_loss: 33.7023 - recon_loss: 0.3041 - val_loss: 0.3571 - val_kl_loss: 38.2520 - val_recon_loss: 0.3571\n",
      "Epoch 169/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.3052 - kl_loss: 33.5625 - recon_loss: 0.3052 - val_loss: 0.4453 - val_kl_loss: 41.0156 - val_recon_loss: 0.4453\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3014 - kl_loss: 33.7754 - recon_loss: 0.3014 - val_loss: 0.3459 - val_kl_loss: 38.7548 - val_recon_loss: 0.3459\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3056 - kl_loss: 33.5550 - recon_loss: 0.3056 - val_loss: 0.3454 - val_kl_loss: 38.7410 - val_recon_loss: 0.3454\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 61us/step - loss: 0.3069 - kl_loss: 33.4947 - recon_loss: 0.3069 - val_loss: 0.3128 - val_kl_loss: 39.0715 - val_recon_loss: 0.3128\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.2999 - kl_loss: 33.6455 - recon_loss: 0.2999 - val_loss: 0.3176 - val_kl_loss: 38.0142 - val_recon_loss: 0.3176\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3013 - kl_loss: 33.5723 - recon_loss: 0.3013 - val_loss: 0.2972 - val_kl_loss: 38.7386 - val_recon_loss: 0.2972\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3011 - kl_loss: 33.5722 - recon_loss: 0.3011 - val_loss: 0.3070 - val_kl_loss: 39.1207 - val_recon_loss: 0.3070\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3029 - kl_loss: 33.8316 - recon_loss: 0.3029 - val_loss: 0.2719 - val_kl_loss: 38.8722 - val_recon_loss: 0.2719\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3039 - kl_loss: 33.7406 - recon_loss: 0.3039 - val_loss: 0.4506 - val_kl_loss: 36.5449 - val_recon_loss: 0.4506\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2980 - kl_loss: 33.3379 - recon_loss: 0.2980 - val_loss: 0.3759 - val_kl_loss: 40.0920 - val_recon_loss: 0.3759\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3027 - kl_loss: 33.4642 - recon_loss: 0.3027 - val_loss: 0.4078 - val_kl_loss: 37.9886 - val_recon_loss: 0.4078\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2960 - kl_loss: 33.2442 - recon_loss: 0.2960 - val_loss: 0.4350 - val_kl_loss: 38.2742 - val_recon_loss: 0.4350\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3048 - kl_loss: 33.4381 - recon_loss: 0.3048 - val_loss: 0.3367 - val_kl_loss: 38.8244 - val_recon_loss: 0.3367\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2966 - kl_loss: 33.2582 - recon_loss: 0.2966 - val_loss: 0.4352 - val_kl_loss: 37.8536 - val_recon_loss: 0.4352\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.3003 - kl_loss: 33.2511 - recon_loss: 0.3003 - val_loss: 0.3461 - val_kl_loss: 38.7216 - val_recon_loss: 0.3461\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3006 - kl_loss: 33.4660 - recon_loss: 0.3006 - val_loss: 0.2803 - val_kl_loss: 38.7212 - val_recon_loss: 0.2803\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.2979 - kl_loss: 33.5127 - recon_loss: 0.2979 - val_loss: 0.3378 - val_kl_loss: 38.7685 - val_recon_loss: 0.3378\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.3008 - kl_loss: 33.4591 - recon_loss: 0.3008 - val_loss: 0.3006 - val_kl_loss: 38.3423 - val_recon_loss: 0.3006\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2959 - kl_loss: 33.5977 - recon_loss: 0.2959 - val_loss: 0.3107 - val_kl_loss: 38.9339 - val_recon_loss: 0.3107\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.2959 - kl_loss: 33.8030 - recon_loss: 0.2959 - val_loss: 0.2900 - val_kl_loss: 39.0125 - val_recon_loss: 0.2900\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.2974 - kl_loss: 33.8621 - recon_loss: 0.2974 - val_loss: 0.3632 - val_kl_loss: 39.0859 - val_recon_loss: 0.3632\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2966 - kl_loss: 34.0150 - recon_loss: 0.2966 - val_loss: 0.3526 - val_kl_loss: 38.6356 - val_recon_loss: 0.3526\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2939 - kl_loss: 33.6297 - recon_loss: 0.2939 - val_loss: 0.3722 - val_kl_loss: 39.6887 - val_recon_loss: 0.3722\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2998 - kl_loss: 33.6913 - recon_loss: 0.2998 - val_loss: 0.3722 - val_kl_loss: 40.3806 - val_recon_loss: 0.3722\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2915 - kl_loss: 33.7384 - recon_loss: 0.2915 - val_loss: 0.4478 - val_kl_loss: 37.2739 - val_recon_loss: 0.4478\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3010 - kl_loss: 33.3110 - recon_loss: 0.3010 - val_loss: 0.3818 - val_kl_loss: 39.7908 - val_recon_loss: 0.3818\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2957 - kl_loss: 33.5406 - recon_loss: 0.2957 - val_loss: 0.3080 - val_kl_loss: 38.6320 - val_recon_loss: 0.3080\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2947 - kl_loss: 33.4729 - recon_loss: 0.2947 - val_loss: 0.3046 - val_kl_loss: 39.1662 - val_recon_loss: 0.3046\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2929 - kl_loss: 33.2946 - recon_loss: 0.2929 - val_loss: 0.2890 - val_kl_loss: 38.4216 - val_recon_loss: 0.2890\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2974 - kl_loss: 33.4881 - recon_loss: 0.2974 - val_loss: 0.3200 - val_kl_loss: 38.6955 - val_recon_loss: 0.3200\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2946 - kl_loss: 33.2839 - recon_loss: 0.2946 - val_loss: 0.3397 - val_kl_loss: 38.6286 - val_recon_loss: 0.3397\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2947 - kl_loss: 33.2117 - recon_loss: 0.2947 - val_loss: 0.2741 - val_kl_loss: 38.7835 - val_recon_loss: 0.2741\n",
      "========================= Model2=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 2), (None, 2 1912        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 2)            0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1740        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,750\n",
      "Trainable params: 3,750\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 2)            26          enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 2)            26          enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,912\n",
      "Trainable params: 1,912\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 18)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           228         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,740\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 132us/step - loss: 38.5154 - kl_loss: 1.3477 - recon_loss: 38.5154 - val_loss: 33.7733 - val_kl_loss: 2.5526 - val_recon_loss: 33.7733\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 86us/step - loss: 18.4056 - kl_loss: 8.1304 - recon_loss: 18.4056 - val_loss: 9.3867 - val_kl_loss: 18.3196 - val_recon_loss: 9.3867\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 4.3619 - kl_loss: 22.2742 - recon_loss: 4.3619 - val_loss: 2.2373 - val_kl_loss: 30.3304 - val_recon_loss: 2.2373\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 1.8219 - kl_loss: 28.7643 - recon_loss: 1.8219 - val_loss: 1.6372 - val_kl_loss: 32.0982 - val_recon_loss: 1.6372\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 1.2927 - kl_loss: 31.5512 - recon_loss: 1.2927 - val_loss: 1.1563 - val_kl_loss: 35.6580 - val_recon_loss: 1.1563\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 1.0342 - kl_loss: 33.4701 - recon_loss: 1.0342 - val_loss: 0.8690 - val_kl_loss: 37.4547 - val_recon_loss: 0.8690\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.8872 - kl_loss: 35.1814 - recon_loss: 0.8872 - val_loss: 0.8919 - val_kl_loss: 40.4421 - val_recon_loss: 0.8919\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.8054 - kl_loss: 36.2402 - recon_loss: 0.8054 - val_loss: 0.7562 - val_kl_loss: 40.3254 - val_recon_loss: 0.7562\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.7407 - kl_loss: 36.9776 - recon_loss: 0.7407 - val_loss: 0.7484 - val_kl_loss: 40.3519 - val_recon_loss: 0.7484\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.6910 - kl_loss: 38.1031 - recon_loss: 0.6910 - val_loss: 0.6268 - val_kl_loss: 42.0984 - val_recon_loss: 0.6268\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.6388 - kl_loss: 38.8131 - recon_loss: 0.6388 - val_loss: 0.6208 - val_kl_loss: 42.2367 - val_recon_loss: 0.6208\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.5909 - kl_loss: 40.0182 - recon_loss: 0.5909 - val_loss: 0.6257 - val_kl_loss: 43.6130 - val_recon_loss: 0.6257\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.5467 - kl_loss: 40.6476 - recon_loss: 0.5467 - val_loss: 0.5365 - val_kl_loss: 45.8730 - val_recon_loss: 0.5365\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.5130 - kl_loss: 41.9640 - recon_loss: 0.5130 - val_loss: 0.5083 - val_kl_loss: 45.6683 - val_recon_loss: 0.5083\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.4855 - kl_loss: 42.6707 - recon_loss: 0.4855 - val_loss: 0.4207 - val_kl_loss: 45.9280 - val_recon_loss: 0.4207\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.4503 - kl_loss: 43.4648 - recon_loss: 0.4503 - val_loss: 0.4419 - val_kl_loss: 46.6282 - val_recon_loss: 0.4419\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.4308 - kl_loss: 44.2740 - recon_loss: 0.4308 - val_loss: 0.5971 - val_kl_loss: 48.1482 - val_recon_loss: 0.5971\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.4141 - kl_loss: 45.3913 - recon_loss: 0.4141 - val_loss: 0.3967 - val_kl_loss: 47.7508 - val_recon_loss: 0.3967\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3825 - kl_loss: 45.9163 - recon_loss: 0.3825 - val_loss: 0.5063 - val_kl_loss: 47.9232 - val_recon_loss: 0.5063\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3788 - kl_loss: 46.5186 - recon_loss: 0.3788 - val_loss: 0.4083 - val_kl_loss: 51.0136 - val_recon_loss: 0.4083\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3647 - kl_loss: 47.1014 - recon_loss: 0.3647 - val_loss: 0.3429 - val_kl_loss: 51.0920 - val_recon_loss: 0.3429\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3614 - kl_loss: 47.4123 - recon_loss: 0.3614 - val_loss: 0.3479 - val_kl_loss: 50.6763 - val_recon_loss: 0.3479\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3432 - kl_loss: 47.5566 - recon_loss: 0.3432 - val_loss: 0.3255 - val_kl_loss: 50.8808 - val_recon_loss: 0.3255\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3463 - kl_loss: 47.9604 - recon_loss: 0.3463 - val_loss: 0.3287 - val_kl_loss: 51.4057 - val_recon_loss: 0.3287\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3406 - kl_loss: 48.2319 - recon_loss: 0.3406 - val_loss: 0.4003 - val_kl_loss: 51.5659 - val_recon_loss: 0.4003\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3334 - kl_loss: 48.5446 - recon_loss: 0.3334 - val_loss: 0.3566 - val_kl_loss: 52.8115 - val_recon_loss: 0.3566\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.3263 - kl_loss: 48.6008 - recon_loss: 0.3263 - val_loss: 0.2719 - val_kl_loss: 51.7295 - val_recon_loss: 0.2719\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3160 - kl_loss: 48.2806 - recon_loss: 0.3160 - val_loss: 0.3293 - val_kl_loss: 51.8226 - val_recon_loss: 0.3293\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3135 - kl_loss: 48.6622 - recon_loss: 0.3135 - val_loss: 0.3658 - val_kl_loss: 52.1532 - val_recon_loss: 0.3658\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3134 - kl_loss: 48.8920 - recon_loss: 0.3134 - val_loss: 0.3700 - val_kl_loss: 51.3907 - val_recon_loss: 0.3700\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3090 - kl_loss: 49.2409 - recon_loss: 0.3090 - val_loss: 0.3057 - val_kl_loss: 52.3948 - val_recon_loss: 0.3057\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3031 - kl_loss: 49.1936 - recon_loss: 0.3031 - val_loss: 0.3070 - val_kl_loss: 52.4722 - val_recon_loss: 0.3070\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2988 - kl_loss: 49.3280 - recon_loss: 0.2988 - val_loss: 0.3098 - val_kl_loss: 52.8412 - val_recon_loss: 0.3098\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2986 - kl_loss: 49.2318 - recon_loss: 0.2986 - val_loss: 0.3822 - val_kl_loss: 51.9538 - val_recon_loss: 0.3822\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2986 - kl_loss: 49.3042 - recon_loss: 0.2986 - val_loss: 0.3679 - val_kl_loss: 52.4800 - val_recon_loss: 0.3679\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2974 - kl_loss: 49.1910 - recon_loss: 0.2974 - val_loss: 0.2753 - val_kl_loss: 53.1748 - val_recon_loss: 0.2753\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2860 - kl_loss: 49.1605 - recon_loss: 0.2860 - val_loss: 0.3737 - val_kl_loss: 51.3482 - val_recon_loss: 0.3737\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2853 - kl_loss: 48.7266 - recon_loss: 0.2853 - val_loss: 0.3113 - val_kl_loss: 52.1654 - val_recon_loss: 0.3113\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.2883 - kl_loss: 48.8514 - recon_loss: 0.2883 - val_loss: 0.2721 - val_kl_loss: 52.2396 - val_recon_loss: 0.2721\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2859 - kl_loss: 48.7704 - recon_loss: 0.2859 - val_loss: 0.2996 - val_kl_loss: 51.0895 - val_recon_loss: 0.2996\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2793 - kl_loss: 48.8653 - recon_loss: 0.2793 - val_loss: 0.4012 - val_kl_loss: 51.1740 - val_recon_loss: 0.4012\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2795 - kl_loss: 48.7612 - recon_loss: 0.2795 - val_loss: 0.3029 - val_kl_loss: 52.2608 - val_recon_loss: 0.3029\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.2723 - kl_loss: 48.3395 - recon_loss: 0.2723 - val_loss: 0.2867 - val_kl_loss: 51.5414 - val_recon_loss: 0.2867\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.2641 - kl_loss: 48.2925 - recon_loss: 0.2641 - val_loss: 0.2688 - val_kl_loss: 51.6015 - val_recon_loss: 0.2688\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2721 - kl_loss: 48.3593 - recon_loss: 0.2721 - val_loss: 0.2510 - val_kl_loss: 51.4022 - val_recon_loss: 0.2510\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2633 - kl_loss: 48.3491 - recon_loss: 0.2633 - val_loss: 0.4192 - val_kl_loss: 51.4569 - val_recon_loss: 0.4192\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2641 - kl_loss: 48.4910 - recon_loss: 0.2641 - val_loss: 0.2321 - val_kl_loss: 51.1007 - val_recon_loss: 0.2321\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2548 - kl_loss: 48.3920 - recon_loss: 0.2548 - val_loss: 0.2623 - val_kl_loss: 51.2727 - val_recon_loss: 0.2623\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2542 - kl_loss: 48.1021 - recon_loss: 0.2542 - val_loss: 0.2834 - val_kl_loss: 50.4674 - val_recon_loss: 0.2834\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2662 - kl_loss: 47.9899 - recon_loss: 0.2662 - val_loss: 0.2553 - val_kl_loss: 51.0218 - val_recon_loss: 0.2553\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2498 - kl_loss: 47.9620 - recon_loss: 0.2498 - val_loss: 0.3296 - val_kl_loss: 51.9303 - val_recon_loss: 0.3296\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2509 - kl_loss: 48.0699 - recon_loss: 0.2509 - val_loss: 0.3893 - val_kl_loss: 51.0222 - val_recon_loss: 0.3893\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2531 - kl_loss: 48.1120 - recon_loss: 0.2531 - val_loss: 0.3495 - val_kl_loss: 49.9970 - val_recon_loss: 0.3495\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2484 - kl_loss: 47.4164 - recon_loss: 0.2484 - val_loss: 0.3770 - val_kl_loss: 50.0980 - val_recon_loss: 0.3770\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2494 - kl_loss: 47.0595 - recon_loss: 0.2494 - val_loss: 0.2919 - val_kl_loss: 49.9367 - val_recon_loss: 0.2919\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2442 - kl_loss: 47.2480 - recon_loss: 0.2442 - val_loss: 0.3592 - val_kl_loss: 49.6617 - val_recon_loss: 0.3592\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2414 - kl_loss: 47.1575 - recon_loss: 0.2414 - val_loss: 0.2463 - val_kl_loss: 50.1889 - val_recon_loss: 0.2463\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2359 - kl_loss: 47.0341 - recon_loss: 0.2359 - val_loss: 0.2289 - val_kl_loss: 50.2716 - val_recon_loss: 0.2289\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2435 - kl_loss: 47.0348 - recon_loss: 0.2435 - val_loss: 0.2476 - val_kl_loss: 49.6688 - val_recon_loss: 0.2476\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2366 - kl_loss: 46.9998 - recon_loss: 0.2366 - val_loss: 0.3547 - val_kl_loss: 48.8457 - val_recon_loss: 0.3547\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2352 - kl_loss: 46.8473 - recon_loss: 0.2352 - val_loss: 0.4490 - val_kl_loss: 48.2564 - val_recon_loss: 0.4490\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2368 - kl_loss: 46.8901 - recon_loss: 0.2368 - val_loss: 0.3193 - val_kl_loss: 48.5162 - val_recon_loss: 0.3193\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2338 - kl_loss: 46.8677 - recon_loss: 0.2338 - val_loss: 0.3843 - val_kl_loss: 48.9598 - val_recon_loss: 0.3843\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2325 - kl_loss: 46.9430 - recon_loss: 0.2325 - val_loss: 0.3866 - val_kl_loss: 49.7324 - val_recon_loss: 0.3866\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2270 - kl_loss: 46.8893 - recon_loss: 0.2270 - val_loss: 0.3241 - val_kl_loss: 50.1612 - val_recon_loss: 0.3241\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2308 - kl_loss: 46.9263 - recon_loss: 0.2308 - val_loss: 0.2621 - val_kl_loss: 49.0264 - val_recon_loss: 0.2621\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2319 - kl_loss: 46.8515 - recon_loss: 0.2319 - val_loss: 0.4149 - val_kl_loss: 49.6092 - val_recon_loss: 0.4149\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.2261 - kl_loss: 46.8227 - recon_loss: 0.2261 - val_loss: 0.2497 - val_kl_loss: 49.5546 - val_recon_loss: 0.2497\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.2229 - kl_loss: 46.6353 - recon_loss: 0.2229 - val_loss: 0.4088 - val_kl_loss: 48.9726 - val_recon_loss: 0.4088\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2238 - kl_loss: 46.5943 - recon_loss: 0.2238 - val_loss: 0.3248 - val_kl_loss: 49.0012 - val_recon_loss: 0.3248\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2215 - kl_loss: 46.4597 - recon_loss: 0.2215 - val_loss: 0.2375 - val_kl_loss: 49.5608 - val_recon_loss: 0.2375\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2265 - kl_loss: 46.6809 - recon_loss: 0.2265 - val_loss: 0.3202 - val_kl_loss: 48.6925 - val_recon_loss: 0.3202\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2213 - kl_loss: 46.9729 - recon_loss: 0.2213 - val_loss: 0.2853 - val_kl_loss: 49.0639 - val_recon_loss: 0.2853\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2161 - kl_loss: 46.5954 - recon_loss: 0.2161 - val_loss: 0.2307 - val_kl_loss: 49.5451 - val_recon_loss: 0.2307\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2206 - kl_loss: 46.3622 - recon_loss: 0.2206 - val_loss: 0.2494 - val_kl_loss: 49.1263 - val_recon_loss: 0.2494\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2155 - kl_loss: 46.2229 - recon_loss: 0.2155 - val_loss: 0.2816 - val_kl_loss: 48.1335 - val_recon_loss: 0.2816\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2185 - kl_loss: 46.4958 - recon_loss: 0.2185 - val_loss: 0.6658 - val_kl_loss: 48.8335 - val_recon_loss: 0.6658\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2137 - kl_loss: 46.8054 - recon_loss: 0.2137 - val_loss: 0.3850 - val_kl_loss: 49.1893 - val_recon_loss: 0.3850\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2139 - kl_loss: 46.6304 - recon_loss: 0.2139 - val_loss: 0.5639 - val_kl_loss: 49.2838 - val_recon_loss: 0.5639\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2131 - kl_loss: 46.4863 - recon_loss: 0.2131 - val_loss: 0.2038 - val_kl_loss: 48.9053 - val_recon_loss: 0.2038\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2083 - kl_loss: 46.5864 - recon_loss: 0.2083 - val_loss: 0.2174 - val_kl_loss: 48.8791 - val_recon_loss: 0.2174\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2129 - kl_loss: 46.6501 - recon_loss: 0.2129 - val_loss: 0.2386 - val_kl_loss: 49.5257 - val_recon_loss: 0.2386\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2085 - kl_loss: 46.4827 - recon_loss: 0.2085 - val_loss: 0.2133 - val_kl_loss: 49.1784 - val_recon_loss: 0.2133\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.2125 - kl_loss: 46.6388 - recon_loss: 0.2125 - val_loss: 0.2034 - val_kl_loss: 49.1876 - val_recon_loss: 0.2034\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2097 - kl_loss: 46.6560 - recon_loss: 0.2097 - val_loss: 0.3856 - val_kl_loss: 49.3852 - val_recon_loss: 0.3856\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2057 - kl_loss: 46.3347 - recon_loss: 0.2057 - val_loss: 0.2116 - val_kl_loss: 49.2185 - val_recon_loss: 0.2116\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2062 - kl_loss: 46.2834 - recon_loss: 0.2062 - val_loss: 0.2462 - val_kl_loss: 48.9459 - val_recon_loss: 0.2462\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2075 - kl_loss: 46.3167 - recon_loss: 0.2075 - val_loss: 0.2378 - val_kl_loss: 49.0011 - val_recon_loss: 0.2378\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2084 - kl_loss: 46.4156 - recon_loss: 0.2084 - val_loss: 0.2576 - val_kl_loss: 50.2507 - val_recon_loss: 0.2576\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2035 - kl_loss: 46.4868 - recon_loss: 0.2035 - val_loss: 0.3680 - val_kl_loss: 49.0288 - val_recon_loss: 0.3680\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2023 - kl_loss: 46.5967 - recon_loss: 0.2023 - val_loss: 0.2843 - val_kl_loss: 48.9104 - val_recon_loss: 0.2843\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2030 - kl_loss: 46.4716 - recon_loss: 0.2030 - val_loss: 0.3402 - val_kl_loss: 50.7333 - val_recon_loss: 0.3402\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2021 - kl_loss: 46.5284 - recon_loss: 0.2021 - val_loss: 0.2164 - val_kl_loss: 49.3169 - val_recon_loss: 0.2164\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2058 - kl_loss: 46.7050 - recon_loss: 0.2058 - val_loss: 0.2308 - val_kl_loss: 48.6895 - val_recon_loss: 0.2308\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2019 - kl_loss: 46.7196 - recon_loss: 0.2019 - val_loss: 0.2478 - val_kl_loss: 49.5900 - val_recon_loss: 0.2478\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1967 - kl_loss: 46.6625 - recon_loss: 0.1967 - val_loss: 0.2349 - val_kl_loss: 49.3671 - val_recon_loss: 0.2349\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1987 - kl_loss: 46.6361 - recon_loss: 0.1987 - val_loss: 0.2769 - val_kl_loss: 49.5078 - val_recon_loss: 0.2769\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2011 - kl_loss: 46.4221 - recon_loss: 0.2011 - val_loss: 0.2235 - val_kl_loss: 47.9756 - val_recon_loss: 0.2235\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1968 - kl_loss: 46.3746 - recon_loss: 0.1968 - val_loss: 0.2390 - val_kl_loss: 48.2995 - val_recon_loss: 0.2390\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1979 - kl_loss: 46.3388 - recon_loss: 0.1979 - val_loss: 0.3660 - val_kl_loss: 47.2080 - val_recon_loss: 0.3660\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1977 - kl_loss: 46.5517 - recon_loss: 0.1977 - val_loss: 0.2320 - val_kl_loss: 49.4225 - val_recon_loss: 0.2320\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1936 - kl_loss: 46.8061 - recon_loss: 0.1936 - val_loss: 0.2117 - val_kl_loss: 49.7696 - val_recon_loss: 0.2117\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1983 - kl_loss: 46.7185 - recon_loss: 0.1983 - val_loss: 0.2944 - val_kl_loss: 49.0177 - val_recon_loss: 0.2944\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1909 - kl_loss: 46.7279 - recon_loss: 0.1909 - val_loss: 0.2522 - val_kl_loss: 48.4000 - val_recon_loss: 0.2522\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1926 - kl_loss: 46.5375 - recon_loss: 0.1926 - val_loss: 0.1873 - val_kl_loss: 49.2973 - val_recon_loss: 0.1873\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1939 - kl_loss: 46.7331 - recon_loss: 0.1939 - val_loss: 0.2079 - val_kl_loss: 49.5371 - val_recon_loss: 0.2079\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 63us/step - loss: 0.1954 - kl_loss: 46.6521 - recon_loss: 0.1954 - val_loss: 0.1913 - val_kl_loss: 49.3819 - val_recon_loss: 0.1913\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1938 - kl_loss: 46.8266 - recon_loss: 0.1938 - val_loss: 0.3397 - val_kl_loss: 49.2632 - val_recon_loss: 0.3397\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1872 - kl_loss: 46.9071 - recon_loss: 0.1872 - val_loss: 0.3351 - val_kl_loss: 48.9330 - val_recon_loss: 0.3351\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1908 - kl_loss: 46.8941 - recon_loss: 0.1908 - val_loss: 0.3035 - val_kl_loss: 48.1454 - val_recon_loss: 0.3035\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1905 - kl_loss: 46.6569 - recon_loss: 0.1905 - val_loss: 0.2494 - val_kl_loss: 48.7747 - val_recon_loss: 0.2494\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1944 - kl_loss: 46.7982 - recon_loss: 0.1944 - val_loss: 0.1885 - val_kl_loss: 49.7523 - val_recon_loss: 0.1885\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1879 - kl_loss: 46.8310 - recon_loss: 0.1879 - val_loss: 0.2335 - val_kl_loss: 49.9782 - val_recon_loss: 0.2335\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1879 - kl_loss: 46.9178 - recon_loss: 0.1879 - val_loss: 0.3579 - val_kl_loss: 48.7916 - val_recon_loss: 0.3579\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1881 - kl_loss: 46.8494 - recon_loss: 0.1881 - val_loss: 0.2475 - val_kl_loss: 49.0096 - val_recon_loss: 0.2475\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1891 - kl_loss: 46.9082 - recon_loss: 0.1891 - val_loss: 0.2210 - val_kl_loss: 49.2174 - val_recon_loss: 0.2210\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1885 - kl_loss: 46.8482 - recon_loss: 0.1885 - val_loss: 0.2285 - val_kl_loss: 48.8615 - val_recon_loss: 0.2285\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1850 - kl_loss: 46.6604 - recon_loss: 0.1850 - val_loss: 0.2533 - val_kl_loss: 49.5535 - val_recon_loss: 0.2533\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1862 - kl_loss: 46.6753 - recon_loss: 0.1862 - val_loss: 0.2036 - val_kl_loss: 49.3557 - val_recon_loss: 0.2036\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1881 - kl_loss: 46.5892 - recon_loss: 0.1881 - val_loss: 0.3983 - val_kl_loss: 47.5276 - val_recon_loss: 0.3983\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1862 - kl_loss: 46.4203 - recon_loss: 0.1862 - val_loss: 0.2003 - val_kl_loss: 48.3544 - val_recon_loss: 0.2003\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1838 - kl_loss: 46.4779 - recon_loss: 0.1838 - val_loss: 0.2305 - val_kl_loss: 48.8772 - val_recon_loss: 0.2305\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1874 - kl_loss: 46.6625 - recon_loss: 0.1874 - val_loss: 0.2292 - val_kl_loss: 48.7673 - val_recon_loss: 0.2292\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1831 - kl_loss: 46.5289 - recon_loss: 0.1831 - val_loss: 0.2536 - val_kl_loss: 49.8457 - val_recon_loss: 0.2536\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1832 - kl_loss: 46.4212 - recon_loss: 0.1832 - val_loss: 0.3306 - val_kl_loss: 48.2706 - val_recon_loss: 0.3306\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1853 - kl_loss: 46.3474 - recon_loss: 0.1853 - val_loss: 0.1926 - val_kl_loss: 49.0047 - val_recon_loss: 0.1926\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1816 - kl_loss: 46.3604 - recon_loss: 0.1816 - val_loss: 0.3992 - val_kl_loss: 49.6768 - val_recon_loss: 0.3992\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1860 - kl_loss: 46.4700 - recon_loss: 0.1860 - val_loss: 0.2243 - val_kl_loss: 48.2522 - val_recon_loss: 0.2243\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1790 - kl_loss: 46.4733 - recon_loss: 0.1790 - val_loss: 0.4223 - val_kl_loss: 49.3813 - val_recon_loss: 0.4223\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1782 - kl_loss: 46.6274 - recon_loss: 0.1782 - val_loss: 0.1804 - val_kl_loss: 48.9506 - val_recon_loss: 0.1804\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1847 - kl_loss: 46.4351 - recon_loss: 0.1847 - val_loss: 0.1861 - val_kl_loss: 48.7064 - val_recon_loss: 0.1861\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1799 - kl_loss: 46.3777 - recon_loss: 0.1799 - val_loss: 0.1934 - val_kl_loss: 49.1637 - val_recon_loss: 0.1934\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1814 - kl_loss: 46.4837 - recon_loss: 0.1814 - val_loss: 0.1964 - val_kl_loss: 48.8938 - val_recon_loss: 0.1964\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1799 - kl_loss: 46.5121 - recon_loss: 0.1799 - val_loss: 0.4285 - val_kl_loss: 47.1549 - val_recon_loss: 0.4285\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1834 - kl_loss: 46.4526 - recon_loss: 0.1834 - val_loss: 0.2156 - val_kl_loss: 49.2254 - val_recon_loss: 0.2156\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1811 - kl_loss: 46.3932 - recon_loss: 0.1811 - val_loss: 0.1930 - val_kl_loss: 49.1472 - val_recon_loss: 0.1930\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1826 - kl_loss: 46.3988 - recon_loss: 0.1826 - val_loss: 0.1762 - val_kl_loss: 48.5518 - val_recon_loss: 0.1762\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1792 - kl_loss: 46.2008 - recon_loss: 0.1792 - val_loss: 0.2280 - val_kl_loss: 48.3230 - val_recon_loss: 0.2280\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1782 - kl_loss: 45.9039 - recon_loss: 0.1782 - val_loss: 0.1923 - val_kl_loss: 48.3111 - val_recon_loss: 0.1923\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1786 - kl_loss: 46.0743 - recon_loss: 0.1786 - val_loss: 0.4320 - val_kl_loss: 48.6708 - val_recon_loss: 0.4320\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1771 - kl_loss: 45.9694 - recon_loss: 0.1771 - val_loss: 0.2787 - val_kl_loss: 47.9436 - val_recon_loss: 0.2787\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1807 - kl_loss: 45.7320 - recon_loss: 0.1807 - val_loss: 0.1762 - val_kl_loss: 47.6851 - val_recon_loss: 0.1762\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1786 - kl_loss: 45.6555 - recon_loss: 0.1786 - val_loss: 0.1895 - val_kl_loss: 48.4074 - val_recon_loss: 0.1895\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1777 - kl_loss: 45.7122 - recon_loss: 0.1777 - val_loss: 0.4684 - val_kl_loss: 47.8619 - val_recon_loss: 0.4684\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1776 - kl_loss: 45.5717 - recon_loss: 0.1776 - val_loss: 0.2699 - val_kl_loss: 48.4065 - val_recon_loss: 0.2699\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1769 - kl_loss: 45.7765 - recon_loss: 0.1769 - val_loss: 0.2981 - val_kl_loss: 48.2224 - val_recon_loss: 0.2981\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1788 - kl_loss: 45.9935 - recon_loss: 0.1788 - val_loss: 0.2367 - val_kl_loss: 48.1851 - val_recon_loss: 0.2367\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1759 - kl_loss: 45.7937 - recon_loss: 0.1759 - val_loss: 0.1947 - val_kl_loss: 47.8314 - val_recon_loss: 0.1947\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1753 - kl_loss: 45.8579 - recon_loss: 0.1753 - val_loss: 0.2312 - val_kl_loss: 48.2641 - val_recon_loss: 0.2312\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1774 - kl_loss: 46.0601 - recon_loss: 0.1774 - val_loss: 0.2019 - val_kl_loss: 48.2688 - val_recon_loss: 0.2019\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1783 - kl_loss: 46.1253 - recon_loss: 0.1783 - val_loss: 0.2747 - val_kl_loss: 48.7251 - val_recon_loss: 0.2747\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1760 - kl_loss: 46.1058 - recon_loss: 0.1760 - val_loss: 0.2169 - val_kl_loss: 48.8586 - val_recon_loss: 0.2169\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1765 - kl_loss: 45.9976 - recon_loss: 0.1765 - val_loss: 0.1735 - val_kl_loss: 48.2091 - val_recon_loss: 0.1735\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1737 - kl_loss: 45.9440 - recon_loss: 0.1737 - val_loss: 0.3811 - val_kl_loss: 48.2924 - val_recon_loss: 0.3811\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1742 - kl_loss: 45.7707 - recon_loss: 0.1742 - val_loss: 0.1741 - val_kl_loss: 48.0226 - val_recon_loss: 0.1741\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1735 - kl_loss: 45.6743 - recon_loss: 0.1735 - val_loss: 0.2610 - val_kl_loss: 46.7408 - val_recon_loss: 0.2610\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1747 - kl_loss: 45.3604 - recon_loss: 0.1747 - val_loss: 0.2871 - val_kl_loss: 47.2817 - val_recon_loss: 0.2871\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1767 - kl_loss: 45.5687 - recon_loss: 0.1767 - val_loss: 0.2197 - val_kl_loss: 47.6004 - val_recon_loss: 0.2197\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1772 - kl_loss: 45.6689 - recon_loss: 0.1772 - val_loss: 0.1777 - val_kl_loss: 47.5272 - val_recon_loss: 0.1777\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1715 - kl_loss: 45.5035 - recon_loss: 0.1715 - val_loss: 0.1789 - val_kl_loss: 47.4507 - val_recon_loss: 0.1789\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1734 - kl_loss: 45.2496 - recon_loss: 0.1734 - val_loss: 0.1812 - val_kl_loss: 47.6448 - val_recon_loss: 0.1812\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1736 - kl_loss: 45.4938 - recon_loss: 0.1736 - val_loss: 0.2302 - val_kl_loss: 47.4892 - val_recon_loss: 0.2302\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1733 - kl_loss: 45.3262 - recon_loss: 0.1733 - val_loss: 0.2618 - val_kl_loss: 47.6557 - val_recon_loss: 0.2618\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1715 - kl_loss: 45.4125 - recon_loss: 0.1715 - val_loss: 0.1554 - val_kl_loss: 47.6304 - val_recon_loss: 0.1554\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1778 - kl_loss: 45.3289 - recon_loss: 0.1778 - val_loss: 0.1914 - val_kl_loss: 47.6128 - val_recon_loss: 0.1914\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1741 - kl_loss: 45.2973 - recon_loss: 0.1741 - val_loss: 0.2303 - val_kl_loss: 47.4401 - val_recon_loss: 0.2303\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1727 - kl_loss: 45.2061 - recon_loss: 0.1727 - val_loss: 0.1872 - val_kl_loss: 47.0060 - val_recon_loss: 0.1872\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1703 - kl_loss: 45.3962 - recon_loss: 0.1703 - val_loss: 0.3823 - val_kl_loss: 46.9386 - val_recon_loss: 0.3823\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1737 - kl_loss: 45.2638 - recon_loss: 0.1737 - val_loss: 0.2110 - val_kl_loss: 47.5958 - val_recon_loss: 0.2110\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1712 - kl_loss: 45.2411 - recon_loss: 0.1712 - val_loss: 0.1800 - val_kl_loss: 47.7004 - val_recon_loss: 0.1800\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1720 - kl_loss: 45.2206 - recon_loss: 0.1720 - val_loss: 0.1677 - val_kl_loss: 47.0186 - val_recon_loss: 0.1677\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1723 - kl_loss: 44.9684 - recon_loss: 0.1723 - val_loss: 0.2391 - val_kl_loss: 47.7334 - val_recon_loss: 0.2391\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1706 - kl_loss: 45.0641 - recon_loss: 0.1706 - val_loss: 0.2151 - val_kl_loss: 46.6272 - val_recon_loss: 0.2151\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1739 - kl_loss: 44.7668 - recon_loss: 0.1739 - val_loss: 0.2049 - val_kl_loss: 47.1448 - val_recon_loss: 0.2049\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1699 - kl_loss: 44.7168 - recon_loss: 0.1699 - val_loss: 0.1650 - val_kl_loss: 47.1696 - val_recon_loss: 0.1650\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1735 - kl_loss: 44.7539 - recon_loss: 0.1735 - val_loss: 0.1758 - val_kl_loss: 47.0344 - val_recon_loss: 0.1758\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1683 - kl_loss: 44.8638 - recon_loss: 0.1683 - val_loss: 0.2715 - val_kl_loss: 46.4844 - val_recon_loss: 0.2715\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1688 - kl_loss: 44.6418 - recon_loss: 0.1688 - val_loss: 0.2318 - val_kl_loss: 46.7818 - val_recon_loss: 0.2318\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1683 - kl_loss: 44.7057 - recon_loss: 0.1683 - val_loss: 0.2871 - val_kl_loss: 46.6731 - val_recon_loss: 0.2871\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1704 - kl_loss: 44.7325 - recon_loss: 0.1704 - val_loss: 0.3978 - val_kl_loss: 46.4603 - val_recon_loss: 0.3978\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1735 - kl_loss: 44.7897 - recon_loss: 0.1735 - val_loss: 0.1941 - val_kl_loss: 45.9666 - val_recon_loss: 0.1941\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1691 - kl_loss: 44.5718 - recon_loss: 0.1691 - val_loss: 0.2134 - val_kl_loss: 45.8035 - val_recon_loss: 0.2134\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1683 - kl_loss: 44.6341 - recon_loss: 0.1683 - val_loss: 0.2277 - val_kl_loss: 47.3783 - val_recon_loss: 0.2277\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1697 - kl_loss: 44.7967 - recon_loss: 0.1697 - val_loss: 0.3204 - val_kl_loss: 46.7595 - val_recon_loss: 0.3204\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1691 - kl_loss: 44.7266 - recon_loss: 0.1691 - val_loss: 0.2721 - val_kl_loss: 46.5291 - val_recon_loss: 0.2721\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1693 - kl_loss: 44.8741 - recon_loss: 0.1693 - val_loss: 0.2104 - val_kl_loss: 46.7761 - val_recon_loss: 0.2104\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1711 - kl_loss: 44.5433 - recon_loss: 0.1711 - val_loss: 0.2535 - val_kl_loss: 46.6725 - val_recon_loss: 0.2535\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1710 - kl_loss: 44.3852 - recon_loss: 0.1710 - val_loss: 0.3208 - val_kl_loss: 45.4880 - val_recon_loss: 0.3208\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1686 - kl_loss: 44.4280 - recon_loss: 0.1686 - val_loss: 0.2291 - val_kl_loss: 46.3866 - val_recon_loss: 0.2291\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1672 - kl_loss: 44.4902 - recon_loss: 0.1672 - val_loss: 0.1591 - val_kl_loss: 46.5091 - val_recon_loss: 0.1591\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1684 - kl_loss: 44.4677 - recon_loss: 0.1684 - val_loss: 0.2031 - val_kl_loss: 46.5106 - val_recon_loss: 0.2031\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1695 - kl_loss: 44.1352 - recon_loss: 0.1695 - val_loss: 0.2257 - val_kl_loss: 46.0753 - val_recon_loss: 0.2257\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1669 - kl_loss: 44.0245 - recon_loss: 0.1669 - val_loss: 0.2297 - val_kl_loss: 46.2608 - val_recon_loss: 0.2297\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1652 - kl_loss: 44.0253 - recon_loss: 0.1652 - val_loss: 0.1994 - val_kl_loss: 45.8660 - val_recon_loss: 0.1994\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1679 - kl_loss: 44.2249 - recon_loss: 0.1679 - val_loss: 0.2098 - val_kl_loss: 45.9525 - val_recon_loss: 0.2098\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1673 - kl_loss: 44.1622 - recon_loss: 0.1673 - val_loss: 0.1869 - val_kl_loss: 46.3225 - val_recon_loss: 0.1869\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1688 - kl_loss: 44.3500 - recon_loss: 0.1688 - val_loss: 0.1618 - val_kl_loss: 46.5323 - val_recon_loss: 0.1618\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1673 - kl_loss: 44.1823 - recon_loss: 0.1673 - val_loss: 0.3181 - val_kl_loss: 47.2145 - val_recon_loss: 0.3181\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1658 - kl_loss: 44.3720 - recon_loss: 0.1658 - val_loss: 0.2292 - val_kl_loss: 45.8145 - val_recon_loss: 0.2292\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1663 - kl_loss: 44.2142 - recon_loss: 0.1663 - val_loss: 0.3000 - val_kl_loss: 47.2415 - val_recon_loss: 0.3000\n",
      "========================= Model3=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 3), (None, 3 1938        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 3)            0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1752        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,788\n",
      "Trainable params: 3,788\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 3)            39          enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 3)            39          enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,938\n",
      "Trainable params: 1,938\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 19)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           240         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,752\n",
      "Trainable params: 1,752\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 137us/step - loss: 29.1590 - kl_loss: 17.4094 - recon_loss: 29.1590 - val_loss: 10.2439 - val_kl_loss: 40.3556 - val_recon_loss: 10.2439\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 4.1447 - kl_loss: 46.5573 - recon_loss: 4.1447 - val_loss: 2.1761 - val_kl_loss: 60.0836 - val_recon_loss: 2.1761\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 1.9046 - kl_loss: 56.9918 - recon_loss: 1.9046 - val_loss: 1.5612 - val_kl_loss: 67.3384 - val_recon_loss: 1.5612\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 1.3543 - kl_loss: 60.2437 - recon_loss: 1.3543 - val_loss: 1.1411 - val_kl_loss: 70.2040 - val_recon_loss: 1.1411\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 1.0729 - kl_loss: 61.5938 - recon_loss: 1.0729 - val_loss: 0.9207 - val_kl_loss: 68.4178 - val_recon_loss: 0.9207\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.8785 - kl_loss: 63.2318 - recon_loss: 0.8785 - val_loss: 0.8828 - val_kl_loss: 71.4034 - val_recon_loss: 0.8828\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.7786 - kl_loss: 65.5758 - recon_loss: 0.7786 - val_loss: 0.8143 - val_kl_loss: 71.7694 - val_recon_loss: 0.8143\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.7071 - kl_loss: 66.5425 - recon_loss: 0.7071 - val_loss: 0.6978 - val_kl_loss: 73.9505 - val_recon_loss: 0.6978\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.6523 - kl_loss: 67.3789 - recon_loss: 0.6523 - val_loss: 0.8489 - val_kl_loss: 73.7985 - val_recon_loss: 0.8489\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.6169 - kl_loss: 68.0229 - recon_loss: 0.6169 - val_loss: 0.6584 - val_kl_loss: 76.4147 - val_recon_loss: 0.6584\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.5767 - kl_loss: 68.5745 - recon_loss: 0.5767 - val_loss: 0.7216 - val_kl_loss: 73.1479 - val_recon_loss: 0.7216\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.5501 - kl_loss: 68.6269 - recon_loss: 0.5501 - val_loss: 0.5973 - val_kl_loss: 76.2157 - val_recon_loss: 0.5973\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.5154 - kl_loss: 68.5893 - recon_loss: 0.5154 - val_loss: 0.5852 - val_kl_loss: 76.5295 - val_recon_loss: 0.5852\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.4918 - kl_loss: 69.0181 - recon_loss: 0.4918 - val_loss: 0.4676 - val_kl_loss: 75.5603 - val_recon_loss: 0.4676\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.4574 - kl_loss: 69.0867 - recon_loss: 0.4574 - val_loss: 0.7942 - val_kl_loss: 76.5046 - val_recon_loss: 0.7942\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.4402 - kl_loss: 68.7499 - recon_loss: 0.4402 - val_loss: 0.4275 - val_kl_loss: 75.2250 - val_recon_loss: 0.4275\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.4263 - kl_loss: 68.1610 - recon_loss: 0.4263 - val_loss: 0.4035 - val_kl_loss: 74.3306 - val_recon_loss: 0.4035\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.4033 - kl_loss: 68.4099 - recon_loss: 0.4033 - val_loss: 0.4014 - val_kl_loss: 75.9508 - val_recon_loss: 0.4014\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3877 - kl_loss: 68.4324 - recon_loss: 0.3877 - val_loss: 0.4473 - val_kl_loss: 75.2252 - val_recon_loss: 0.4473\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3787 - kl_loss: 68.1844 - recon_loss: 0.3787 - val_loss: 0.3878 - val_kl_loss: 74.9974 - val_recon_loss: 0.3878\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3606 - kl_loss: 68.0191 - recon_loss: 0.3606 - val_loss: 0.3331 - val_kl_loss: 74.1755 - val_recon_loss: 0.3331\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3494 - kl_loss: 67.3263 - recon_loss: 0.3494 - val_loss: 0.4876 - val_kl_loss: 74.7475 - val_recon_loss: 0.4876\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3460 - kl_loss: 66.9386 - recon_loss: 0.3460 - val_loss: 0.6938 - val_kl_loss: 70.3331 - val_recon_loss: 0.6938\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3306 - kl_loss: 66.6617 - recon_loss: 0.3306 - val_loss: 0.6892 - val_kl_loss: 69.2119 - val_recon_loss: 0.6892\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3342 - kl_loss: 66.7989 - recon_loss: 0.3342 - val_loss: 0.3101 - val_kl_loss: 73.8004 - val_recon_loss: 0.3101\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3189 - kl_loss: 66.6805 - recon_loss: 0.3189 - val_loss: 0.3341 - val_kl_loss: 72.9407 - val_recon_loss: 0.3341\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3157 - kl_loss: 67.1478 - recon_loss: 0.3157 - val_loss: 0.3205 - val_kl_loss: 75.0879 - val_recon_loss: 0.3205\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3061 - kl_loss: 67.3225 - recon_loss: 0.3061 - val_loss: 0.3894 - val_kl_loss: 72.6303 - val_recon_loss: 0.3894\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3058 - kl_loss: 67.3978 - recon_loss: 0.3058 - val_loss: 0.6700 - val_kl_loss: 77.3017 - val_recon_loss: 0.6700\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2952 - kl_loss: 67.0942 - recon_loss: 0.2952 - val_loss: 0.4513 - val_kl_loss: 71.1124 - val_recon_loss: 0.4513\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2912 - kl_loss: 66.6762 - recon_loss: 0.2912 - val_loss: 0.2560 - val_kl_loss: 73.4803 - val_recon_loss: 0.2560\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2880 - kl_loss: 66.8265 - recon_loss: 0.2880 - val_loss: 0.3123 - val_kl_loss: 73.7337 - val_recon_loss: 0.3123\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2816 - kl_loss: 66.5981 - recon_loss: 0.2816 - val_loss: 0.5659 - val_kl_loss: 68.5291 - val_recon_loss: 0.5659\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2765 - kl_loss: 66.3292 - recon_loss: 0.2765 - val_loss: 0.5890 - val_kl_loss: 72.7706 - val_recon_loss: 0.5890\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.2760 - kl_loss: 66.0341 - recon_loss: 0.2760 - val_loss: 0.3701 - val_kl_loss: 73.4432 - val_recon_loss: 0.3701\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.2712 - kl_loss: 65.9365 - recon_loss: 0.2712 - val_loss: 0.3492 - val_kl_loss: 73.2862 - val_recon_loss: 0.3492\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2670 - kl_loss: 65.9135 - recon_loss: 0.2670 - val_loss: 0.2406 - val_kl_loss: 71.8650 - val_recon_loss: 0.2406\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2590 - kl_loss: 65.5843 - recon_loss: 0.2590 - val_loss: 0.2834 - val_kl_loss: 72.4371 - val_recon_loss: 0.2834\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2634 - kl_loss: 65.6856 - recon_loss: 0.2634 - val_loss: 0.2600 - val_kl_loss: 72.1956 - val_recon_loss: 0.2600\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2575 - kl_loss: 65.6997 - recon_loss: 0.2575 - val_loss: 0.4388 - val_kl_loss: 75.1910 - val_recon_loss: 0.4388\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2542 - kl_loss: 65.9142 - recon_loss: 0.2542 - val_loss: 0.3264 - val_kl_loss: 70.2759 - val_recon_loss: 0.3264\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2475 - kl_loss: 65.9465 - recon_loss: 0.2475 - val_loss: 0.4185 - val_kl_loss: 72.7612 - val_recon_loss: 0.4185\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2471 - kl_loss: 65.5460 - recon_loss: 0.2471 - val_loss: 0.2801 - val_kl_loss: 71.7076 - val_recon_loss: 0.2801\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2429 - kl_loss: 64.9744 - recon_loss: 0.2429 - val_loss: 0.2738 - val_kl_loss: 70.7012 - val_recon_loss: 0.2738\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2414 - kl_loss: 64.7342 - recon_loss: 0.2414 - val_loss: 0.4290 - val_kl_loss: 72.1935 - val_recon_loss: 0.4290\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.2410 - kl_loss: 64.4098 - recon_loss: 0.2410 - val_loss: 0.2525 - val_kl_loss: 70.7910 - val_recon_loss: 0.2525\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2355 - kl_loss: 64.3443 - recon_loss: 0.2355 - val_loss: 0.2080 - val_kl_loss: 69.9731 - val_recon_loss: 0.2080\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2289 - kl_loss: 64.2013 - recon_loss: 0.2289 - val_loss: 0.3577 - val_kl_loss: 68.2963 - val_recon_loss: 0.3577\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2249 - kl_loss: 64.2838 - recon_loss: 0.2249 - val_loss: 0.2170 - val_kl_loss: 69.7905 - val_recon_loss: 0.2170\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2272 - kl_loss: 64.1197 - recon_loss: 0.2272 - val_loss: 0.2092 - val_kl_loss: 68.9909 - val_recon_loss: 0.2092\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2198 - kl_loss: 63.9780 - recon_loss: 0.2198 - val_loss: 0.3208 - val_kl_loss: 68.4557 - val_recon_loss: 0.3208\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2185 - kl_loss: 63.6947 - recon_loss: 0.2185 - val_loss: 0.1700 - val_kl_loss: 69.3338 - val_recon_loss: 0.1700\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2129 - kl_loss: 63.8408 - recon_loss: 0.2129 - val_loss: 0.1853 - val_kl_loss: 69.1248 - val_recon_loss: 0.1853\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2059 - kl_loss: 63.5100 - recon_loss: 0.2059 - val_loss: 0.2335 - val_kl_loss: 69.0917 - val_recon_loss: 0.2335\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2069 - kl_loss: 63.5291 - recon_loss: 0.2069 - val_loss: 0.4309 - val_kl_loss: 67.8927 - val_recon_loss: 0.4309\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2054 - kl_loss: 63.8040 - recon_loss: 0.2054 - val_loss: 0.2064 - val_kl_loss: 69.1441 - val_recon_loss: 0.2064\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1976 - kl_loss: 63.8377 - recon_loss: 0.1976 - val_loss: 0.2085 - val_kl_loss: 68.9875 - val_recon_loss: 0.2085\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1997 - kl_loss: 63.5238 - recon_loss: 0.1997 - val_loss: 0.2161 - val_kl_loss: 69.1110 - val_recon_loss: 0.2161\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1955 - kl_loss: 64.0825 - recon_loss: 0.1955 - val_loss: 0.1796 - val_kl_loss: 68.9080 - val_recon_loss: 0.1796\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1896 - kl_loss: 64.0391 - recon_loss: 0.1896 - val_loss: 0.1960 - val_kl_loss: 69.1923 - val_recon_loss: 0.1960\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1914 - kl_loss: 63.8288 - recon_loss: 0.1914 - val_loss: 0.2214 - val_kl_loss: 68.7550 - val_recon_loss: 0.2214\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1828 - kl_loss: 63.5884 - recon_loss: 0.1828 - val_loss: 0.2210 - val_kl_loss: 69.3373 - val_recon_loss: 0.2210\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1888 - kl_loss: 63.7115 - recon_loss: 0.1888 - val_loss: 0.1670 - val_kl_loss: 69.3473 - val_recon_loss: 0.1670\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1834 - kl_loss: 63.9487 - recon_loss: 0.1834 - val_loss: 0.3128 - val_kl_loss: 67.5885 - val_recon_loss: 0.3128\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1817 - kl_loss: 63.9413 - recon_loss: 0.1817 - val_loss: 0.1565 - val_kl_loss: 70.0176 - val_recon_loss: 0.1565\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1830 - kl_loss: 64.2304 - recon_loss: 0.1830 - val_loss: 0.1485 - val_kl_loss: 70.0737 - val_recon_loss: 0.1485\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1793 - kl_loss: 64.3189 - recon_loss: 0.1793 - val_loss: 0.2319 - val_kl_loss: 68.6806 - val_recon_loss: 0.2319\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1782 - kl_loss: 64.1592 - recon_loss: 0.1782 - val_loss: 0.1867 - val_kl_loss: 69.4680 - val_recon_loss: 0.1867\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1763 - kl_loss: 64.1970 - recon_loss: 0.1763 - val_loss: 0.2305 - val_kl_loss: 70.2667 - val_recon_loss: 0.2305\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1703 - kl_loss: 64.2552 - recon_loss: 0.1703 - val_loss: 0.1909 - val_kl_loss: 70.4828 - val_recon_loss: 0.1909\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1730 - kl_loss: 64.1520 - recon_loss: 0.1730 - val_loss: 0.3487 - val_kl_loss: 70.2465 - val_recon_loss: 0.3487\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1699 - kl_loss: 63.9559 - recon_loss: 0.1699 - val_loss: 0.1984 - val_kl_loss: 69.1862 - val_recon_loss: 0.1984\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1708 - kl_loss: 63.7688 - recon_loss: 0.1708 - val_loss: 0.1858 - val_kl_loss: 68.6725 - val_recon_loss: 0.1858\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1692 - kl_loss: 63.7923 - recon_loss: 0.1692 - val_loss: 0.1775 - val_kl_loss: 68.5059 - val_recon_loss: 0.1775\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1656 - kl_loss: 63.8304 - recon_loss: 0.1656 - val_loss: 0.3272 - val_kl_loss: 68.7561 - val_recon_loss: 0.3272\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1669 - kl_loss: 64.1787 - recon_loss: 0.1669 - val_loss: 0.1380 - val_kl_loss: 69.0303 - val_recon_loss: 0.1380\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1635 - kl_loss: 64.1462 - recon_loss: 0.1635 - val_loss: 0.3803 - val_kl_loss: 68.4545 - val_recon_loss: 0.3803\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1624 - kl_loss: 64.2610 - recon_loss: 0.1624 - val_loss: 0.1680 - val_kl_loss: 68.9561 - val_recon_loss: 0.1680\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1655 - kl_loss: 64.2765 - recon_loss: 0.1655 - val_loss: 0.2882 - val_kl_loss: 70.2218 - val_recon_loss: 0.2882\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1650 - kl_loss: 64.4624 - recon_loss: 0.1650 - val_loss: 0.1292 - val_kl_loss: 69.4798 - val_recon_loss: 0.1292\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1611 - kl_loss: 64.3404 - recon_loss: 0.1611 - val_loss: 0.1485 - val_kl_loss: 69.4563 - val_recon_loss: 0.1485\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1608 - kl_loss: 64.3653 - recon_loss: 0.1608 - val_loss: 0.1359 - val_kl_loss: 69.4011 - val_recon_loss: 0.1359\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1627 - kl_loss: 64.1325 - recon_loss: 0.1627 - val_loss: 0.1656 - val_kl_loss: 68.6400 - val_recon_loss: 0.1656\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1592 - kl_loss: 63.9641 - recon_loss: 0.1592 - val_loss: 0.1597 - val_kl_loss: 69.1537 - val_recon_loss: 0.1597\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1594 - kl_loss: 64.0075 - recon_loss: 0.1594 - val_loss: 0.1546 - val_kl_loss: 69.0839 - val_recon_loss: 0.1546\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1580 - kl_loss: 64.0695 - recon_loss: 0.1580 - val_loss: 0.1313 - val_kl_loss: 68.6516 - val_recon_loss: 0.1313\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1585 - kl_loss: 64.1801 - recon_loss: 0.1585 - val_loss: 0.3383 - val_kl_loss: 66.9435 - val_recon_loss: 0.3383\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1508 - kl_loss: 64.1306 - recon_loss: 0.1508 - val_loss: 0.1803 - val_kl_loss: 68.8488 - val_recon_loss: 0.1803\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1559 - kl_loss: 64.2480 - recon_loss: 0.1559 - val_loss: 0.2397 - val_kl_loss: 70.3782 - val_recon_loss: 0.2397\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1552 - kl_loss: 64.4032 - recon_loss: 0.1552 - val_loss: 0.1299 - val_kl_loss: 68.8123 - val_recon_loss: 0.1299\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1541 - kl_loss: 64.1706 - recon_loss: 0.1541 - val_loss: 0.2340 - val_kl_loss: 71.4763 - val_recon_loss: 0.2340\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1522 - kl_loss: 64.5868 - recon_loss: 0.1522 - val_loss: 0.2584 - val_kl_loss: 68.5993 - val_recon_loss: 0.2584\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1561 - kl_loss: 64.3989 - recon_loss: 0.1561 - val_loss: 0.1381 - val_kl_loss: 69.6717 - val_recon_loss: 0.1381\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1497 - kl_loss: 64.4003 - recon_loss: 0.1497 - val_loss: 0.1322 - val_kl_loss: 69.3987 - val_recon_loss: 0.1322\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1522 - kl_loss: 64.4144 - recon_loss: 0.1522 - val_loss: 0.1249 - val_kl_loss: 68.6960 - val_recon_loss: 0.1249\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1488 - kl_loss: 64.2038 - recon_loss: 0.1488 - val_loss: 0.1834 - val_kl_loss: 70.0406 - val_recon_loss: 0.1834\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1504 - kl_loss: 64.4124 - recon_loss: 0.1504 - val_loss: 0.1502 - val_kl_loss: 69.2701 - val_recon_loss: 0.1502\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1519 - kl_loss: 64.4880 - recon_loss: 0.1519 - val_loss: 0.2524 - val_kl_loss: 69.4117 - val_recon_loss: 0.2524\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1448 - kl_loss: 64.5349 - recon_loss: 0.1448 - val_loss: 0.1937 - val_kl_loss: 68.6625 - val_recon_loss: 0.1937\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1467 - kl_loss: 64.4295 - recon_loss: 0.1467 - val_loss: 0.1651 - val_kl_loss: 69.3921 - val_recon_loss: 0.1651\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1473 - kl_loss: 64.2984 - recon_loss: 0.1473 - val_loss: 0.5897 - val_kl_loss: 71.3885 - val_recon_loss: 0.5897\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1424 - kl_loss: 64.3200 - recon_loss: 0.1424 - val_loss: 0.1571 - val_kl_loss: 69.4734 - val_recon_loss: 0.1571\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1532 - kl_loss: 64.3740 - recon_loss: 0.1532 - val_loss: 0.1312 - val_kl_loss: 69.2792 - val_recon_loss: 0.1312\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1397 - kl_loss: 64.1815 - recon_loss: 0.1397 - val_loss: 0.2257 - val_kl_loss: 69.0597 - val_recon_loss: 0.2257\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1500 - kl_loss: 63.9349 - recon_loss: 0.1500 - val_loss: 0.2566 - val_kl_loss: 66.7795 - val_recon_loss: 0.2566\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1451 - kl_loss: 63.9753 - recon_loss: 0.1451 - val_loss: 0.1187 - val_kl_loss: 69.2487 - val_recon_loss: 0.1187\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1410 - kl_loss: 64.1143 - recon_loss: 0.1410 - val_loss: 0.2498 - val_kl_loss: 67.6295 - val_recon_loss: 0.2498\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1447 - kl_loss: 63.7353 - recon_loss: 0.1447 - val_loss: 0.1240 - val_kl_loss: 68.4824 - val_recon_loss: 0.1240\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1440 - kl_loss: 63.7796 - recon_loss: 0.1440 - val_loss: 0.1464 - val_kl_loss: 68.9468 - val_recon_loss: 0.1464\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1427 - kl_loss: 64.1373 - recon_loss: 0.1427 - val_loss: 0.2999 - val_kl_loss: 70.1419 - val_recon_loss: 0.2999\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1412 - kl_loss: 64.3260 - recon_loss: 0.1412 - val_loss: 0.1573 - val_kl_loss: 69.9305 - val_recon_loss: 0.1573\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1430 - kl_loss: 64.2479 - recon_loss: 0.1430 - val_loss: 0.1176 - val_kl_loss: 68.4383 - val_recon_loss: 0.1176\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1441 - kl_loss: 64.0316 - recon_loss: 0.1441 - val_loss: 0.2011 - val_kl_loss: 68.1438 - val_recon_loss: 0.2011\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1377 - kl_loss: 64.0040 - recon_loss: 0.1377 - val_loss: 0.1895 - val_kl_loss: 69.0542 - val_recon_loss: 0.1895\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1435 - kl_loss: 64.0834 - recon_loss: 0.1435 - val_loss: 0.2131 - val_kl_loss: 70.0172 - val_recon_loss: 0.2131\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1359 - kl_loss: 64.1887 - recon_loss: 0.1359 - val_loss: 0.1119 - val_kl_loss: 68.2318 - val_recon_loss: 0.1119\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1410 - kl_loss: 63.8514 - recon_loss: 0.1410 - val_loss: 0.1554 - val_kl_loss: 68.6538 - val_recon_loss: 0.1554\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1386 - kl_loss: 63.9825 - recon_loss: 0.1386 - val_loss: 0.1287 - val_kl_loss: 69.0984 - val_recon_loss: 0.1287\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1358 - kl_loss: 64.0127 - recon_loss: 0.1358 - val_loss: 0.1984 - val_kl_loss: 68.9688 - val_recon_loss: 0.1984\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1341 - kl_loss: 64.0012 - recon_loss: 0.1341 - val_loss: 0.1640 - val_kl_loss: 68.3049 - val_recon_loss: 0.1640\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1388 - kl_loss: 64.0536 - recon_loss: 0.1388 - val_loss: 0.1318 - val_kl_loss: 68.5268 - val_recon_loss: 0.1318\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1370 - kl_loss: 63.9465 - recon_loss: 0.1370 - val_loss: 0.1292 - val_kl_loss: 67.5914 - val_recon_loss: 0.1292\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1333 - kl_loss: 63.7392 - recon_loss: 0.1333 - val_loss: 0.1270 - val_kl_loss: 68.2208 - val_recon_loss: 0.1270\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1344 - kl_loss: 63.7571 - recon_loss: 0.1344 - val_loss: 0.1490 - val_kl_loss: 67.7290 - val_recon_loss: 0.1490\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1337 - kl_loss: 63.7597 - recon_loss: 0.1337 - val_loss: 0.2323 - val_kl_loss: 69.0606 - val_recon_loss: 0.2323\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1327 - kl_loss: 63.5564 - recon_loss: 0.1327 - val_loss: 0.1248 - val_kl_loss: 67.9630 - val_recon_loss: 0.1248\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1319 - kl_loss: 63.6652 - recon_loss: 0.1319 - val_loss: 0.1927 - val_kl_loss: 67.1014 - val_recon_loss: 0.1927\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1342 - kl_loss: 63.5587 - recon_loss: 0.1342 - val_loss: 0.1073 - val_kl_loss: 67.9048 - val_recon_loss: 0.1073\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1340 - kl_loss: 63.7154 - recon_loss: 0.1340 - val_loss: 0.1345 - val_kl_loss: 69.2303 - val_recon_loss: 0.1345\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1311 - kl_loss: 64.1508 - recon_loss: 0.1311 - val_loss: 0.1195 - val_kl_loss: 68.8128 - val_recon_loss: 0.1195\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1341 - kl_loss: 64.2332 - recon_loss: 0.1341 - val_loss: 0.2500 - val_kl_loss: 67.9330 - val_recon_loss: 0.2500\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1304 - kl_loss: 64.0486 - recon_loss: 0.1304 - val_loss: 0.1937 - val_kl_loss: 69.2481 - val_recon_loss: 0.1937\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1333 - kl_loss: 64.0793 - recon_loss: 0.1333 - val_loss: 0.1516 - val_kl_loss: 67.8985 - val_recon_loss: 0.1516\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1313 - kl_loss: 64.1430 - recon_loss: 0.1313 - val_loss: 0.2737 - val_kl_loss: 69.9352 - val_recon_loss: 0.2737\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1287 - kl_loss: 64.2679 - recon_loss: 0.1287 - val_loss: 0.1599 - val_kl_loss: 69.1932 - val_recon_loss: 0.1599\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1299 - kl_loss: 64.1312 - recon_loss: 0.1299 - val_loss: 0.1518 - val_kl_loss: 68.9217 - val_recon_loss: 0.1518\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1306 - kl_loss: 64.1599 - recon_loss: 0.1306 - val_loss: 0.1280 - val_kl_loss: 67.8854 - val_recon_loss: 0.1280\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1285 - kl_loss: 64.0144 - recon_loss: 0.1285 - val_loss: 0.1338 - val_kl_loss: 67.7967 - val_recon_loss: 0.1338\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1265 - kl_loss: 63.8939 - recon_loss: 0.1265 - val_loss: 0.1396 - val_kl_loss: 68.1682 - val_recon_loss: 0.1396\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1312 - kl_loss: 64.1608 - recon_loss: 0.1312 - val_loss: 0.3064 - val_kl_loss: 69.8802 - val_recon_loss: 0.3064\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1309 - kl_loss: 64.0850 - recon_loss: 0.1309 - val_loss: 0.1726 - val_kl_loss: 67.9831 - val_recon_loss: 0.1726\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1273 - kl_loss: 64.1135 - recon_loss: 0.1273 - val_loss: 0.1442 - val_kl_loss: 69.8365 - val_recon_loss: 0.1442\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1250 - kl_loss: 64.1963 - recon_loss: 0.1250 - val_loss: 0.3165 - val_kl_loss: 68.5766 - val_recon_loss: 0.3165\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1311 - kl_loss: 63.9597 - recon_loss: 0.1311 - val_loss: 0.1187 - val_kl_loss: 68.7534 - val_recon_loss: 0.1187\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1203 - kl_loss: 63.8784 - recon_loss: 0.1203 - val_loss: 0.2331 - val_kl_loss: 66.8166 - val_recon_loss: 0.2331\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1231 - kl_loss: 63.7645 - recon_loss: 0.1231 - val_loss: 0.3659 - val_kl_loss: 66.0711 - val_recon_loss: 0.3659\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1273 - kl_loss: 63.7080 - recon_loss: 0.1273 - val_loss: 0.1582 - val_kl_loss: 68.1643 - val_recon_loss: 0.1582\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1243 - kl_loss: 63.6914 - recon_loss: 0.1243 - val_loss: 0.1280 - val_kl_loss: 67.5837 - val_recon_loss: 0.1280\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1253 - kl_loss: 63.5096 - recon_loss: 0.1253 - val_loss: 0.2689 - val_kl_loss: 66.1812 - val_recon_loss: 0.2689\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1322 - kl_loss: 63.4852 - recon_loss: 0.1322 - val_loss: 0.1275 - val_kl_loss: 67.9662 - val_recon_loss: 0.1275\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1204 - kl_loss: 63.4731 - recon_loss: 0.1204 - val_loss: 0.1296 - val_kl_loss: 67.9780 - val_recon_loss: 0.1296\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1241 - kl_loss: 63.6266 - recon_loss: 0.1241 - val_loss: 0.1200 - val_kl_loss: 68.3503 - val_recon_loss: 0.1200\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1237 - kl_loss: 63.8313 - recon_loss: 0.1237 - val_loss: 0.1133 - val_kl_loss: 67.7419 - val_recon_loss: 0.1133\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1256 - kl_loss: 63.6023 - recon_loss: 0.1256 - val_loss: 0.1146 - val_kl_loss: 67.7781 - val_recon_loss: 0.1146\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1246 - kl_loss: 63.7922 - recon_loss: 0.1246 - val_loss: 0.1328 - val_kl_loss: 68.2119 - val_recon_loss: 0.1328\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1190 - kl_loss: 63.7986 - recon_loss: 0.1190 - val_loss: 0.1455 - val_kl_loss: 68.0298 - val_recon_loss: 0.1455\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1248 - kl_loss: 63.8770 - recon_loss: 0.1248 - val_loss: 0.1780 - val_kl_loss: 67.0858 - val_recon_loss: 0.1780\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1230 - kl_loss: 63.8627 - recon_loss: 0.1230 - val_loss: 0.1483 - val_kl_loss: 68.8094 - val_recon_loss: 0.1483\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1246 - kl_loss: 63.8501 - recon_loss: 0.1246 - val_loss: 0.1134 - val_kl_loss: 68.3876 - val_recon_loss: 0.1134\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1206 - kl_loss: 63.8197 - recon_loss: 0.1206 - val_loss: 0.1151 - val_kl_loss: 68.5736 - val_recon_loss: 0.1151\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1222 - kl_loss: 63.8473 - recon_loss: 0.1222 - val_loss: 0.1291 - val_kl_loss: 67.6250 - val_recon_loss: 0.1291\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1191 - kl_loss: 64.1208 - recon_loss: 0.1191 - val_loss: 0.1155 - val_kl_loss: 68.8088 - val_recon_loss: 0.1155\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1179 - kl_loss: 64.0320 - recon_loss: 0.1179 - val_loss: 0.1210 - val_kl_loss: 67.7433 - val_recon_loss: 0.1210\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1259 - kl_loss: 63.9957 - recon_loss: 0.1259 - val_loss: 0.1223 - val_kl_loss: 67.5539 - val_recon_loss: 0.1223\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1215 - kl_loss: 64.0654 - recon_loss: 0.1215 - val_loss: 0.1099 - val_kl_loss: 67.8382 - val_recon_loss: 0.1099\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1197 - kl_loss: 64.1758 - recon_loss: 0.1197 - val_loss: 0.1250 - val_kl_loss: 68.8929 - val_recon_loss: 0.1250\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1213 - kl_loss: 64.2609 - recon_loss: 0.1213 - val_loss: 0.1605 - val_kl_loss: 67.8810 - val_recon_loss: 0.1605\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1225 - kl_loss: 64.3372 - recon_loss: 0.1225 - val_loss: 0.2252 - val_kl_loss: 67.4794 - val_recon_loss: 0.2252\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1181 - kl_loss: 64.2500 - recon_loss: 0.1181 - val_loss: 0.1493 - val_kl_loss: 68.8568 - val_recon_loss: 0.1493\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1168 - kl_loss: 64.1841 - recon_loss: 0.1168 - val_loss: 0.1682 - val_kl_loss: 67.9023 - val_recon_loss: 0.1682\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1184 - kl_loss: 64.3104 - recon_loss: 0.1184 - val_loss: 0.1781 - val_kl_loss: 69.4009 - val_recon_loss: 0.1781\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1262 - kl_loss: 64.4321 - recon_loss: 0.1262 - val_loss: 0.2066 - val_kl_loss: 67.2684 - val_recon_loss: 0.2066\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1162 - kl_loss: 64.5050 - recon_loss: 0.1162 - val_loss: 0.1597 - val_kl_loss: 69.5705 - val_recon_loss: 0.1597\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1163 - kl_loss: 64.4911 - recon_loss: 0.1163 - val_loss: 0.1227 - val_kl_loss: 69.3315 - val_recon_loss: 0.1227\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1205 - kl_loss: 64.6503 - recon_loss: 0.1205 - val_loss: 0.1053 - val_kl_loss: 68.2505 - val_recon_loss: 0.1053\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1171 - kl_loss: 64.6960 - recon_loss: 0.1171 - val_loss: 0.1595 - val_kl_loss: 68.4260 - val_recon_loss: 0.1595\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1179 - kl_loss: 64.8722 - recon_loss: 0.1179 - val_loss: 0.1018 - val_kl_loss: 68.8032 - val_recon_loss: 0.1018\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1187 - kl_loss: 64.8246 - recon_loss: 0.1187 - val_loss: 0.1268 - val_kl_loss: 68.0064 - val_recon_loss: 0.1268\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1149 - kl_loss: 64.9063 - recon_loss: 0.1149 - val_loss: 0.1226 - val_kl_loss: 69.5202 - val_recon_loss: 0.1226\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1151 - kl_loss: 65.0464 - recon_loss: 0.1151 - val_loss: 0.1215 - val_kl_loss: 69.6906 - val_recon_loss: 0.1215\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1182 - kl_loss: 65.1286 - recon_loss: 0.1182 - val_loss: 0.0970 - val_kl_loss: 69.0534 - val_recon_loss: 0.0970\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1193 - kl_loss: 65.0310 - recon_loss: 0.1193 - val_loss: 0.1234 - val_kl_loss: 69.5706 - val_recon_loss: 0.1234\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1155 - kl_loss: 65.0667 - recon_loss: 0.1155 - val_loss: 0.1653 - val_kl_loss: 69.7381 - val_recon_loss: 0.1653\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1167 - kl_loss: 64.9362 - recon_loss: 0.1167 - val_loss: 0.1111 - val_kl_loss: 68.7355 - val_recon_loss: 0.1111\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1175 - kl_loss: 65.0201 - recon_loss: 0.1175 - val_loss: 0.1512 - val_kl_loss: 68.4443 - val_recon_loss: 0.1512\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1154 - kl_loss: 64.8712 - recon_loss: 0.1154 - val_loss: 0.1508 - val_kl_loss: 69.3441 - val_recon_loss: 0.1508\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1162 - kl_loss: 64.7362 - recon_loss: 0.1162 - val_loss: 0.1181 - val_kl_loss: 68.3638 - val_recon_loss: 0.1181\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1158 - kl_loss: 64.8704 - recon_loss: 0.1158 - val_loss: 0.1572 - val_kl_loss: 68.7693 - val_recon_loss: 0.1572\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1137 - kl_loss: 64.7400 - recon_loss: 0.1137 - val_loss: 0.1727 - val_kl_loss: 69.7187 - val_recon_loss: 0.1727\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1136 - kl_loss: 64.9703 - recon_loss: 0.1136 - val_loss: 0.2059 - val_kl_loss: 68.0226 - val_recon_loss: 0.2059\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1178 - kl_loss: 65.0597 - recon_loss: 0.1178 - val_loss: 0.1257 - val_kl_loss: 69.6290 - val_recon_loss: 0.1257\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1132 - kl_loss: 65.1106 - recon_loss: 0.1132 - val_loss: 0.1671 - val_kl_loss: 69.7700 - val_recon_loss: 0.1671\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1140 - kl_loss: 64.9274 - recon_loss: 0.1140 - val_loss: 0.1585 - val_kl_loss: 70.4895 - val_recon_loss: 0.1585\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1180 - kl_loss: 65.2263 - recon_loss: 0.1180 - val_loss: 0.1008 - val_kl_loss: 69.2242 - val_recon_loss: 0.1008\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1119 - kl_loss: 65.3314 - recon_loss: 0.1119 - val_loss: 0.2885 - val_kl_loss: 67.8983 - val_recon_loss: 0.2885\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1130 - kl_loss: 65.3659 - recon_loss: 0.1130 - val_loss: 0.1076 - val_kl_loss: 68.9741 - val_recon_loss: 0.1076\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1125 - kl_loss: 65.4537 - recon_loss: 0.1125 - val_loss: 0.1550 - val_kl_loss: 68.3965 - val_recon_loss: 0.1550\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1127 - kl_loss: 65.2781 - recon_loss: 0.1127 - val_loss: 0.1153 - val_kl_loss: 69.1805 - val_recon_loss: 0.1153\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1129 - kl_loss: 65.3298 - recon_loss: 0.1129 - val_loss: 0.1525 - val_kl_loss: 69.8851 - val_recon_loss: 0.1525\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1150 - kl_loss: 65.6225 - recon_loss: 0.1150 - val_loss: 0.2129 - val_kl_loss: 68.7050 - val_recon_loss: 0.2129\n",
      "========================= Model4=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 4), (None, 4 1964        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 4)            0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1764        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,826\n",
      "Trainable params: 3,826\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 4)            52          enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 4)            52          enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,964\n",
      "Trainable params: 1,964\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 20)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           252         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,764\n",
      "Trainable params: 1,764\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 127us/step - loss: 33.4124 - kl_loss: 9.1807 - recon_loss: 33.4124 - val_loss: 15.9500 - val_kl_loss: 25.0049 - val_recon_loss: 15.9500\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 7.8377 - kl_loss: 34.6681 - recon_loss: 7.8377 - val_loss: 4.1196 - val_kl_loss: 51.7134 - val_recon_loss: 4.1196\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 2.6208 - kl_loss: 54.1228 - recon_loss: 2.6208 - val_loss: 1.7205 - val_kl_loss: 69.7935 - val_recon_loss: 1.7205\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 1.4129 - kl_loss: 68.7581 - recon_loss: 1.4129 - val_loss: 1.2006 - val_kl_loss: 82.8510 - val_recon_loss: 1.2006\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 1.0584 - kl_loss: 81.7238 - recon_loss: 1.0584 - val_loss: 1.0704 - val_kl_loss: 92.4927 - val_recon_loss: 1.0704\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.8660 - kl_loss: 90.4711 - recon_loss: 0.8660 - val_loss: 0.8343 - val_kl_loss: 103.9058 - val_recon_loss: 0.8343\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.7607 - kl_loss: 96.8243 - recon_loss: 0.7607 - val_loss: 0.7417 - val_kl_loss: 105.9897 - val_recon_loss: 0.7417\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.6914 - kl_loss: 101.2817 - recon_loss: 0.6914 - val_loss: 0.6800 - val_kl_loss: 111.4134 - val_recon_loss: 0.6800\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.6433 - kl_loss: 104.4056 - recon_loss: 0.6433 - val_loss: 0.6917 - val_kl_loss: 113.3802 - val_recon_loss: 0.6917\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.5992 - kl_loss: 106.4954 - recon_loss: 0.5992 - val_loss: 0.6210 - val_kl_loss: 114.6650 - val_recon_loss: 0.6210\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.5598 - kl_loss: 107.4465 - recon_loss: 0.5598 - val_loss: 0.5374 - val_kl_loss: 118.1924 - val_recon_loss: 0.5374\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.5167 - kl_loss: 108.4445 - recon_loss: 0.5167 - val_loss: 0.6406 - val_kl_loss: 120.4808 - val_recon_loss: 0.6406\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.4884 - kl_loss: 109.8912 - recon_loss: 0.4884 - val_loss: 0.5094 - val_kl_loss: 116.8477 - val_recon_loss: 0.5094\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.4527 - kl_loss: 110.7779 - recon_loss: 0.4527 - val_loss: 0.5489 - val_kl_loss: 120.1085 - val_recon_loss: 0.5489\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.4373 - kl_loss: 111.3184 - recon_loss: 0.4373 - val_loss: 0.5602 - val_kl_loss: 118.9034 - val_recon_loss: 0.5602\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.4090 - kl_loss: 111.0256 - recon_loss: 0.4090 - val_loss: 0.4856 - val_kl_loss: 123.0055 - val_recon_loss: 0.4856\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.4001 - kl_loss: 111.4087 - recon_loss: 0.4001 - val_loss: 0.3826 - val_kl_loss: 119.1618 - val_recon_loss: 0.3826\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3750 - kl_loss: 111.1011 - recon_loss: 0.3750 - val_loss: 0.5175 - val_kl_loss: 120.5728 - val_recon_loss: 0.5175\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.3722 - kl_loss: 110.7064 - recon_loss: 0.3722 - val_loss: 0.4789 - val_kl_loss: 119.0378 - val_recon_loss: 0.4789\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3538 - kl_loss: 110.5949 - recon_loss: 0.3538 - val_loss: 0.4571 - val_kl_loss: 118.9206 - val_recon_loss: 0.4571\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3449 - kl_loss: 109.9538 - recon_loss: 0.3449 - val_loss: 0.4735 - val_kl_loss: 115.1128 - val_recon_loss: 0.4735\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3386 - kl_loss: 109.1043 - recon_loss: 0.3386 - val_loss: 0.3365 - val_kl_loss: 117.1580 - val_recon_loss: 0.3365\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3271 - kl_loss: 108.3232 - recon_loss: 0.3271 - val_loss: 0.4275 - val_kl_loss: 119.8513 - val_recon_loss: 0.4275\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.3263 - kl_loss: 107.7755 - recon_loss: 0.3263 - val_loss: 0.3430 - val_kl_loss: 115.6563 - val_recon_loss: 0.3430\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3109 - kl_loss: 107.0691 - recon_loss: 0.3109 - val_loss: 0.6638 - val_kl_loss: 112.1247 - val_recon_loss: 0.6638\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3072 - kl_loss: 106.3720 - recon_loss: 0.3072 - val_loss: 0.3315 - val_kl_loss: 114.5515 - val_recon_loss: 0.3315\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.3020 - kl_loss: 105.6773 - recon_loss: 0.3020 - val_loss: 0.3179 - val_kl_loss: 114.2236 - val_recon_loss: 0.3179\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2936 - kl_loss: 105.1429 - recon_loss: 0.2936 - val_loss: 0.2915 - val_kl_loss: 112.7344 - val_recon_loss: 0.2915\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2869 - kl_loss: 104.8888 - recon_loss: 0.2869 - val_loss: 0.4730 - val_kl_loss: 111.2012 - val_recon_loss: 0.4730\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2822 - kl_loss: 104.7147 - recon_loss: 0.2822 - val_loss: 0.2817 - val_kl_loss: 112.1518 - val_recon_loss: 0.2817\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2779 - kl_loss: 103.9740 - recon_loss: 0.2779 - val_loss: 0.2778 - val_kl_loss: 111.4119 - val_recon_loss: 0.2778\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2789 - kl_loss: 103.4258 - recon_loss: 0.2789 - val_loss: 0.3035 - val_kl_loss: 111.5989 - val_recon_loss: 0.3035\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2679 - kl_loss: 103.2663 - recon_loss: 0.2679 - val_loss: 0.3814 - val_kl_loss: 112.8941 - val_recon_loss: 0.3814\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2667 - kl_loss: 102.6804 - recon_loss: 0.2667 - val_loss: 0.2692 - val_kl_loss: 110.6352 - val_recon_loss: 0.2692\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2565 - kl_loss: 102.9258 - recon_loss: 0.2565 - val_loss: 0.2579 - val_kl_loss: 109.2871 - val_recon_loss: 0.2579\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2580 - kl_loss: 102.8285 - recon_loss: 0.2580 - val_loss: 0.3264 - val_kl_loss: 110.5240 - val_recon_loss: 0.3264\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2513 - kl_loss: 102.4664 - recon_loss: 0.2513 - val_loss: 0.6794 - val_kl_loss: 113.0044 - val_recon_loss: 0.6794\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2482 - kl_loss: 102.9770 - recon_loss: 0.2482 - val_loss: 0.2488 - val_kl_loss: 110.2677 - val_recon_loss: 0.2488\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2495 - kl_loss: 102.9757 - recon_loss: 0.2495 - val_loss: 0.2620 - val_kl_loss: 108.0020 - val_recon_loss: 0.2620\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2416 - kl_loss: 102.6253 - recon_loss: 0.2416 - val_loss: 0.3191 - val_kl_loss: 108.4922 - val_recon_loss: 0.3191\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2373 - kl_loss: 102.0870 - recon_loss: 0.2373 - val_loss: 0.2457 - val_kl_loss: 110.0017 - val_recon_loss: 0.2457\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.2351 - kl_loss: 102.5508 - recon_loss: 0.2351 - val_loss: 0.3038 - val_kl_loss: 112.5578 - val_recon_loss: 0.3038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.2337 - kl_loss: 102.2250 - recon_loss: 0.2337 - val_loss: 0.2493 - val_kl_loss: 109.0251 - val_recon_loss: 0.2493\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2260 - kl_loss: 101.5950 - recon_loss: 0.2260 - val_loss: 0.2365 - val_kl_loss: 107.7117 - val_recon_loss: 0.2365\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.2272 - kl_loss: 101.4009 - recon_loss: 0.2272 - val_loss: 0.2242 - val_kl_loss: 108.1437 - val_recon_loss: 0.2242\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2223 - kl_loss: 101.3963 - recon_loss: 0.2223 - val_loss: 0.2281 - val_kl_loss: 108.0296 - val_recon_loss: 0.2281\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2223 - kl_loss: 101.3861 - recon_loss: 0.2223 - val_loss: 0.5262 - val_kl_loss: 105.4014 - val_recon_loss: 0.5262\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2188 - kl_loss: 101.3723 - recon_loss: 0.2188 - val_loss: 0.3564 - val_kl_loss: 110.3104 - val_recon_loss: 0.3564\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2140 - kl_loss: 101.4394 - recon_loss: 0.2140 - val_loss: 0.2508 - val_kl_loss: 107.4872 - val_recon_loss: 0.2508\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2132 - kl_loss: 101.1486 - recon_loss: 0.2132 - val_loss: 0.2291 - val_kl_loss: 106.7269 - val_recon_loss: 0.2291\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2098 - kl_loss: 100.7702 - recon_loss: 0.2098 - val_loss: 0.2935 - val_kl_loss: 108.4639 - val_recon_loss: 0.2935\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2098 - kl_loss: 100.7140 - recon_loss: 0.2098 - val_loss: 0.2708 - val_kl_loss: 107.2508 - val_recon_loss: 0.2708\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2034 - kl_loss: 100.4560 - recon_loss: 0.2034 - val_loss: 0.1884 - val_kl_loss: 106.5639 - val_recon_loss: 0.1884\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2018 - kl_loss: 100.4424 - recon_loss: 0.2018 - val_loss: 0.2110 - val_kl_loss: 107.2234 - val_recon_loss: 0.2110\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1973 - kl_loss: 100.5259 - recon_loss: 0.1973 - val_loss: 0.2144 - val_kl_loss: 105.0679 - val_recon_loss: 0.2144\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1983 - kl_loss: 100.4567 - recon_loss: 0.1983 - val_loss: 0.2982 - val_kl_loss: 108.8523 - val_recon_loss: 0.2982\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1942 - kl_loss: 100.4125 - recon_loss: 0.1942 - val_loss: 0.1918 - val_kl_loss: 106.9421 - val_recon_loss: 0.1918\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1929 - kl_loss: 100.0085 - recon_loss: 0.1929 - val_loss: 0.2930 - val_kl_loss: 103.3756 - val_recon_loss: 0.2930\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1887 - kl_loss: 99.8860 - recon_loss: 0.1887 - val_loss: 0.2748 - val_kl_loss: 103.5915 - val_recon_loss: 0.2748\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1881 - kl_loss: 99.4447 - recon_loss: 0.1881 - val_loss: 0.2074 - val_kl_loss: 105.9728 - val_recon_loss: 0.2074\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1864 - kl_loss: 99.5440 - recon_loss: 0.1864 - val_loss: 0.2330 - val_kl_loss: 104.3934 - val_recon_loss: 0.2330\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1812 - kl_loss: 99.7218 - recon_loss: 0.1812 - val_loss: 0.2723 - val_kl_loss: 108.0381 - val_recon_loss: 0.2723\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1864 - kl_loss: 100.2113 - recon_loss: 0.1864 - val_loss: 0.1831 - val_kl_loss: 106.2052 - val_recon_loss: 0.1831\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1791 - kl_loss: 100.2604 - recon_loss: 0.1791 - val_loss: 0.2838 - val_kl_loss: 104.8823 - val_recon_loss: 0.2838\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1760 - kl_loss: 100.2597 - recon_loss: 0.1760 - val_loss: 0.4130 - val_kl_loss: 107.6736 - val_recon_loss: 0.4130\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1759 - kl_loss: 99.9780 - recon_loss: 0.1759 - val_loss: 0.1618 - val_kl_loss: 105.5778 - val_recon_loss: 0.1618\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1742 - kl_loss: 99.6506 - recon_loss: 0.1742 - val_loss: 0.3041 - val_kl_loss: 108.3695 - val_recon_loss: 0.3041\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1720 - kl_loss: 99.8205 - recon_loss: 0.1720 - val_loss: 0.1490 - val_kl_loss: 107.2008 - val_recon_loss: 0.1490\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1731 - kl_loss: 100.2605 - recon_loss: 0.1731 - val_loss: 0.1853 - val_kl_loss: 105.0848 - val_recon_loss: 0.1853\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1624 - kl_loss: 100.3292 - recon_loss: 0.1624 - val_loss: 0.1751 - val_kl_loss: 107.4764 - val_recon_loss: 0.1751\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1687 - kl_loss: 100.2543 - recon_loss: 0.1687 - val_loss: 0.1728 - val_kl_loss: 105.4863 - val_recon_loss: 0.1728\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1621 - kl_loss: 100.0845 - recon_loss: 0.1621 - val_loss: 0.2367 - val_kl_loss: 105.5336 - val_recon_loss: 0.2367\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1660 - kl_loss: 100.0204 - recon_loss: 0.1660 - val_loss: 0.1505 - val_kl_loss: 106.5228 - val_recon_loss: 0.1505\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1582 - kl_loss: 100.1896 - recon_loss: 0.1582 - val_loss: 0.1693 - val_kl_loss: 107.1972 - val_recon_loss: 0.1693\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1608 - kl_loss: 100.1728 - recon_loss: 0.1608 - val_loss: 0.2023 - val_kl_loss: 104.5133 - val_recon_loss: 0.2023\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1624 - kl_loss: 99.9452 - recon_loss: 0.1624 - val_loss: 0.1731 - val_kl_loss: 105.4708 - val_recon_loss: 0.1731\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1545 - kl_loss: 99.7026 - recon_loss: 0.1545 - val_loss: 0.2952 - val_kl_loss: 105.2045 - val_recon_loss: 0.2952\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1569 - kl_loss: 99.2914 - recon_loss: 0.1569 - val_loss: 0.2043 - val_kl_loss: 106.3040 - val_recon_loss: 0.2043\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1575 - kl_loss: 99.4597 - recon_loss: 0.1575 - val_loss: 0.1745 - val_kl_loss: 106.7465 - val_recon_loss: 0.1745\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1525 - kl_loss: 99.1903 - recon_loss: 0.1525 - val_loss: 0.1569 - val_kl_loss: 105.1825 - val_recon_loss: 0.1569\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1572 - kl_loss: 98.9792 - recon_loss: 0.1572 - val_loss: 0.1222 - val_kl_loss: 104.6503 - val_recon_loss: 0.1222\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1473 - kl_loss: 99.2885 - recon_loss: 0.1473 - val_loss: 0.1930 - val_kl_loss: 106.6383 - val_recon_loss: 0.1930\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1544 - kl_loss: 99.0135 - recon_loss: 0.1544 - val_loss: 0.1407 - val_kl_loss: 106.2838 - val_recon_loss: 0.1407\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1493 - kl_loss: 98.6447 - recon_loss: 0.1493 - val_loss: 0.1742 - val_kl_loss: 102.2806 - val_recon_loss: 0.1742\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1444 - kl_loss: 98.6412 - recon_loss: 0.1444 - val_loss: 0.1274 - val_kl_loss: 105.0728 - val_recon_loss: 0.1274\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1466 - kl_loss: 98.7324 - recon_loss: 0.1466 - val_loss: 0.2729 - val_kl_loss: 107.0547 - val_recon_loss: 0.2729\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1478 - kl_loss: 99.0255 - recon_loss: 0.1478 - val_loss: 0.2308 - val_kl_loss: 107.4142 - val_recon_loss: 0.2308\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1474 - kl_loss: 99.0734 - recon_loss: 0.1474 - val_loss: 0.1521 - val_kl_loss: 105.2492 - val_recon_loss: 0.1521\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1442 - kl_loss: 98.8465 - recon_loss: 0.1442 - val_loss: 0.3925 - val_kl_loss: 103.9228 - val_recon_loss: 0.3925\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1422 - kl_loss: 98.4698 - recon_loss: 0.1422 - val_loss: 0.1173 - val_kl_loss: 104.1238 - val_recon_loss: 0.1173\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1433 - kl_loss: 98.4038 - recon_loss: 0.1433 - val_loss: 0.1377 - val_kl_loss: 104.2823 - val_recon_loss: 0.1377\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1431 - kl_loss: 98.9110 - recon_loss: 0.1431 - val_loss: 0.1349 - val_kl_loss: 104.1660 - val_recon_loss: 0.1349\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1409 - kl_loss: 98.8213 - recon_loss: 0.1409 - val_loss: 0.1695 - val_kl_loss: 104.0803 - val_recon_loss: 0.1695\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1399 - kl_loss: 98.6438 - recon_loss: 0.1399 - val_loss: 0.1648 - val_kl_loss: 101.8561 - val_recon_loss: 0.1648\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1427 - kl_loss: 98.5020 - recon_loss: 0.1427 - val_loss: 0.1361 - val_kl_loss: 105.7046 - val_recon_loss: 0.1361\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1351 - kl_loss: 98.5615 - recon_loss: 0.1351 - val_loss: 0.2536 - val_kl_loss: 104.9604 - val_recon_loss: 0.2536\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1397 - kl_loss: 98.3329 - recon_loss: 0.1397 - val_loss: 0.1187 - val_kl_loss: 103.5903 - val_recon_loss: 0.1187\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1369 - kl_loss: 98.3786 - recon_loss: 0.1369 - val_loss: 0.1259 - val_kl_loss: 104.4059 - val_recon_loss: 0.1259\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1366 - kl_loss: 98.3984 - recon_loss: 0.1366 - val_loss: 0.1593 - val_kl_loss: 103.8091 - val_recon_loss: 0.1593\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1309 - kl_loss: 98.4207 - recon_loss: 0.1309 - val_loss: 0.1558 - val_kl_loss: 105.0313 - val_recon_loss: 0.1558\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1345 - kl_loss: 98.5002 - recon_loss: 0.1345 - val_loss: 0.1848 - val_kl_loss: 105.1082 - val_recon_loss: 0.1848\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1355 - kl_loss: 98.4774 - recon_loss: 0.1355 - val_loss: 0.1686 - val_kl_loss: 104.5453 - val_recon_loss: 0.1686\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1318 - kl_loss: 98.2090 - recon_loss: 0.1318 - val_loss: 0.1700 - val_kl_loss: 104.0248 - val_recon_loss: 0.1700\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1302 - kl_loss: 98.1733 - recon_loss: 0.1302 - val_loss: 0.1432 - val_kl_loss: 103.9095 - val_recon_loss: 0.1432\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1312 - kl_loss: 98.1880 - recon_loss: 0.1312 - val_loss: 0.1270 - val_kl_loss: 103.9839 - val_recon_loss: 0.1270\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 63us/step - loss: 0.1290 - kl_loss: 98.0983 - recon_loss: 0.1290 - val_loss: 0.1132 - val_kl_loss: 103.4575 - val_recon_loss: 0.1132\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1299 - kl_loss: 98.1896 - recon_loss: 0.1299 - val_loss: 0.1948 - val_kl_loss: 102.9556 - val_recon_loss: 0.1948\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1300 - kl_loss: 98.2490 - recon_loss: 0.1300 - val_loss: 0.1309 - val_kl_loss: 105.2675 - val_recon_loss: 0.1309\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1285 - kl_loss: 98.2285 - recon_loss: 0.1285 - val_loss: 0.1787 - val_kl_loss: 104.8814 - val_recon_loss: 0.1787\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1282 - kl_loss: 97.7723 - recon_loss: 0.1282 - val_loss: 0.2357 - val_kl_loss: 102.0791 - val_recon_loss: 0.2357\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1282 - kl_loss: 98.0016 - recon_loss: 0.1282 - val_loss: 0.1584 - val_kl_loss: 102.5457 - val_recon_loss: 0.1584\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1255 - kl_loss: 97.8114 - recon_loss: 0.1255 - val_loss: 0.2723 - val_kl_loss: 103.0203 - val_recon_loss: 0.2723\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1278 - kl_loss: 97.9168 - recon_loss: 0.1278 - val_loss: 0.1453 - val_kl_loss: 103.7186 - val_recon_loss: 0.1453\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1273 - kl_loss: 97.9452 - recon_loss: 0.1273 - val_loss: 0.1071 - val_kl_loss: 102.6418 - val_recon_loss: 0.1071\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1206 - kl_loss: 97.7537 - recon_loss: 0.1206 - val_loss: 0.2580 - val_kl_loss: 105.5755 - val_recon_loss: 0.2580\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1320 - kl_loss: 97.6358 - recon_loss: 0.1320 - val_loss: 0.2896 - val_kl_loss: 100.8490 - val_recon_loss: 0.2896\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1233 - kl_loss: 97.7669 - recon_loss: 0.1233 - val_loss: 0.2471 - val_kl_loss: 105.1273 - val_recon_loss: 0.2471\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1248 - kl_loss: 97.9986 - recon_loss: 0.1248 - val_loss: 0.1037 - val_kl_loss: 103.0837 - val_recon_loss: 0.1037\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1158 - kl_loss: 97.9582 - recon_loss: 0.1158 - val_loss: 0.2817 - val_kl_loss: 104.2555 - val_recon_loss: 0.2817\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1257 - kl_loss: 97.7226 - recon_loss: 0.1257 - val_loss: 0.1097 - val_kl_loss: 103.4713 - val_recon_loss: 0.1097\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1229 - kl_loss: 97.6722 - recon_loss: 0.1229 - val_loss: 0.2173 - val_kl_loss: 103.0634 - val_recon_loss: 0.2173\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1249 - kl_loss: 97.6494 - recon_loss: 0.1249 - val_loss: 0.1321 - val_kl_loss: 104.7664 - val_recon_loss: 0.1321\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1215 - kl_loss: 97.6049 - recon_loss: 0.1215 - val_loss: 0.1080 - val_kl_loss: 104.2559 - val_recon_loss: 0.1080\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1207 - kl_loss: 98.1392 - recon_loss: 0.1207 - val_loss: 0.0908 - val_kl_loss: 103.7603 - val_recon_loss: 0.0908\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1219 - kl_loss: 98.4762 - recon_loss: 0.1219 - val_loss: 0.1132 - val_kl_loss: 103.7201 - val_recon_loss: 0.1132\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1204 - kl_loss: 98.4257 - recon_loss: 0.1204 - val_loss: 0.3388 - val_kl_loss: 104.4101 - val_recon_loss: 0.3388\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1171 - kl_loss: 98.5617 - recon_loss: 0.1171 - val_loss: 0.2691 - val_kl_loss: 101.3952 - val_recon_loss: 0.2691\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1193 - kl_loss: 98.3939 - recon_loss: 0.1193 - val_loss: 0.1554 - val_kl_loss: 105.2293 - val_recon_loss: 0.1554\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1195 - kl_loss: 98.3093 - recon_loss: 0.1195 - val_loss: 0.1144 - val_kl_loss: 103.5429 - val_recon_loss: 0.1144\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1172 - kl_loss: 98.0407 - recon_loss: 0.1172 - val_loss: 0.1240 - val_kl_loss: 103.4687 - val_recon_loss: 0.1240\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1187 - kl_loss: 97.6953 - recon_loss: 0.1187 - val_loss: 0.1568 - val_kl_loss: 103.3851 - val_recon_loss: 0.1568\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1192 - kl_loss: 97.5311 - recon_loss: 0.1192 - val_loss: 0.1041 - val_kl_loss: 103.3701 - val_recon_loss: 0.1041\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1142 - kl_loss: 97.5950 - recon_loss: 0.1142 - val_loss: 0.1069 - val_kl_loss: 103.7415 - val_recon_loss: 0.1069\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1188 - kl_loss: 97.8559 - recon_loss: 0.1188 - val_loss: 0.3355 - val_kl_loss: 100.8358 - val_recon_loss: 0.3355\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1194 - kl_loss: 98.0961 - recon_loss: 0.1194 - val_loss: 0.1081 - val_kl_loss: 103.5369 - val_recon_loss: 0.1081\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1140 - kl_loss: 97.9463 - recon_loss: 0.1140 - val_loss: 0.2254 - val_kl_loss: 103.1778 - val_recon_loss: 0.2254\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1162 - kl_loss: 97.8213 - recon_loss: 0.1162 - val_loss: 0.1202 - val_kl_loss: 102.9575 - val_recon_loss: 0.1202\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1168 - kl_loss: 97.7291 - recon_loss: 0.1168 - val_loss: 0.1027 - val_kl_loss: 102.9832 - val_recon_loss: 0.1027\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1133 - kl_loss: 97.7316 - recon_loss: 0.1133 - val_loss: 0.3210 - val_kl_loss: 103.6780 - val_recon_loss: 0.3210\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1164 - kl_loss: 97.4473 - recon_loss: 0.1164 - val_loss: 0.0989 - val_kl_loss: 103.4541 - val_recon_loss: 0.0989\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1151 - kl_loss: 97.6282 - recon_loss: 0.1151 - val_loss: 0.1024 - val_kl_loss: 102.9662 - val_recon_loss: 0.1024\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1115 - kl_loss: 97.7510 - recon_loss: 0.1115 - val_loss: 0.1707 - val_kl_loss: 104.3972 - val_recon_loss: 0.1707\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1134 - kl_loss: 98.0441 - recon_loss: 0.1134 - val_loss: 0.1844 - val_kl_loss: 104.0718 - val_recon_loss: 0.1844\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1134 - kl_loss: 98.0991 - recon_loss: 0.1134 - val_loss: 0.4167 - val_kl_loss: 100.7478 - val_recon_loss: 0.4167\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1123 - kl_loss: 98.1180 - recon_loss: 0.1123 - val_loss: 0.1829 - val_kl_loss: 103.3145 - val_recon_loss: 0.1829\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 90us/step - loss: 0.1128 - kl_loss: 98.2351 - recon_loss: 0.1128 - val_loss: 0.1763 - val_kl_loss: 103.2189 - val_recon_loss: 0.1763\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1124 - kl_loss: 97.8563 - recon_loss: 0.1124 - val_loss: 0.1811 - val_kl_loss: 100.9725 - val_recon_loss: 0.1811\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1166 - kl_loss: 97.6846 - recon_loss: 0.1166 - val_loss: 0.0825 - val_kl_loss: 103.0409 - val_recon_loss: 0.0825\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 101us/step - loss: 0.1111 - kl_loss: 97.8105 - recon_loss: 0.1111 - val_loss: 0.1046 - val_kl_loss: 104.1876 - val_recon_loss: 0.1046\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 103us/step - loss: 0.1093 - kl_loss: 97.9601 - recon_loss: 0.1093 - val_loss: 0.1252 - val_kl_loss: 103.6005 - val_recon_loss: 0.1252\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1089 - kl_loss: 97.8764 - recon_loss: 0.1089 - val_loss: 0.3843 - val_kl_loss: 101.6304 - val_recon_loss: 0.3843\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.1111 - kl_loss: 98.3278 - recon_loss: 0.1111 - val_loss: 0.1240 - val_kl_loss: 103.7368 - val_recon_loss: 0.1240\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1115 - kl_loss: 98.1871 - recon_loss: 0.1115 - val_loss: 0.1093 - val_kl_loss: 102.0584 - val_recon_loss: 0.1093\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1111 - kl_loss: 97.9504 - recon_loss: 0.1111 - val_loss: 0.1308 - val_kl_loss: 103.2843 - val_recon_loss: 0.1308\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1070 - kl_loss: 98.1867 - recon_loss: 0.1070 - val_loss: 0.1422 - val_kl_loss: 102.2792 - val_recon_loss: 0.1422\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1130 - kl_loss: 98.3525 - recon_loss: 0.1130 - val_loss: 0.0878 - val_kl_loss: 103.0654 - val_recon_loss: 0.0878\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1123 - kl_loss: 98.4877 - recon_loss: 0.1123 - val_loss: 0.1393 - val_kl_loss: 105.3517 - val_recon_loss: 0.1393\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1077 - kl_loss: 98.4656 - recon_loss: 0.1077 - val_loss: 0.1606 - val_kl_loss: 101.3464 - val_recon_loss: 0.1606\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1059 - kl_loss: 98.3638 - recon_loss: 0.1059 - val_loss: 0.0946 - val_kl_loss: 103.1479 - val_recon_loss: 0.0946\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1133 - kl_loss: 98.3198 - recon_loss: 0.1133 - val_loss: 0.1157 - val_kl_loss: 102.7081 - val_recon_loss: 0.1157\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1044 - kl_loss: 98.3602 - recon_loss: 0.1044 - val_loss: 0.1115 - val_kl_loss: 103.8531 - val_recon_loss: 0.1115\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1115 - kl_loss: 98.3563 - recon_loss: 0.1115 - val_loss: 0.1986 - val_kl_loss: 102.4139 - val_recon_loss: 0.1986\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1080 - kl_loss: 98.4463 - recon_loss: 0.1080 - val_loss: 0.0873 - val_kl_loss: 103.1703 - val_recon_loss: 0.0873\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1061 - kl_loss: 98.6064 - recon_loss: 0.1061 - val_loss: 0.1019 - val_kl_loss: 103.9237 - val_recon_loss: 0.1019\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1091 - kl_loss: 98.9480 - recon_loss: 0.1091 - val_loss: 0.2027 - val_kl_loss: 104.3482 - val_recon_loss: 0.2027\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1071 - kl_loss: 99.2113 - recon_loss: 0.1071 - val_loss: 0.1502 - val_kl_loss: 105.0474 - val_recon_loss: 0.1502\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1078 - kl_loss: 99.2069 - recon_loss: 0.1078 - val_loss: 0.1746 - val_kl_loss: 104.9814 - val_recon_loss: 0.1746\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1056 - kl_loss: 99.4190 - recon_loss: 0.1056 - val_loss: 0.1032 - val_kl_loss: 103.7449 - val_recon_loss: 0.1032\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1084 - kl_loss: 99.0332 - recon_loss: 0.1084 - val_loss: 0.0948 - val_kl_loss: 104.6057 - val_recon_loss: 0.0948\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1026 - kl_loss: 98.9653 - recon_loss: 0.1026 - val_loss: 0.2452 - val_kl_loss: 105.7464 - val_recon_loss: 0.2452\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1079 - kl_loss: 98.5520 - recon_loss: 0.1079 - val_loss: 0.1954 - val_kl_loss: 103.7799 - val_recon_loss: 0.1954\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1079 - kl_loss: 98.3014 - recon_loss: 0.1079 - val_loss: 0.1201 - val_kl_loss: 104.6762 - val_recon_loss: 0.1201\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1069 - kl_loss: 98.4760 - recon_loss: 0.1069 - val_loss: 0.1279 - val_kl_loss: 103.2456 - val_recon_loss: 0.1279\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1014 - kl_loss: 98.7136 - recon_loss: 0.1014 - val_loss: 0.3694 - val_kl_loss: 103.6418 - val_recon_loss: 0.3694\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1056 - kl_loss: 98.4032 - recon_loss: 0.1056 - val_loss: 0.0995 - val_kl_loss: 103.9219 - val_recon_loss: 0.0995\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1050 - kl_loss: 98.4593 - recon_loss: 0.1050 - val_loss: 0.1300 - val_kl_loss: 101.7484 - val_recon_loss: 0.1300\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1029 - kl_loss: 98.4210 - recon_loss: 0.1029 - val_loss: 0.5114 - val_kl_loss: 107.7830 - val_recon_loss: 0.5114\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1065 - kl_loss: 98.7324 - recon_loss: 0.1065 - val_loss: 0.2417 - val_kl_loss: 105.4020 - val_recon_loss: 0.2417\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1052 - kl_loss: 98.7634 - recon_loss: 0.1052 - val_loss: 0.1078 - val_kl_loss: 103.7036 - val_recon_loss: 0.1078\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1068 - kl_loss: 98.7986 - recon_loss: 0.1068 - val_loss: 0.0843 - val_kl_loss: 103.6151 - val_recon_loss: 0.0843\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1028 - kl_loss: 98.6446 - recon_loss: 0.1028 - val_loss: 0.0957 - val_kl_loss: 104.7482 - val_recon_loss: 0.0957\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1059 - kl_loss: 98.6050 - recon_loss: 0.1059 - val_loss: 0.1051 - val_kl_loss: 104.0170 - val_recon_loss: 0.1051\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1038 - kl_loss: 98.6512 - recon_loss: 0.1038 - val_loss: 0.0985 - val_kl_loss: 103.5574 - val_recon_loss: 0.0985\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1051 - kl_loss: 98.5114 - recon_loss: 0.1051 - val_loss: 0.0888 - val_kl_loss: 103.2008 - val_recon_loss: 0.0888\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1018 - kl_loss: 98.6294 - recon_loss: 0.1018 - val_loss: 0.2850 - val_kl_loss: 99.6060 - val_recon_loss: 0.2850\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1000 - kl_loss: 98.7485 - recon_loss: 0.1000 - val_loss: 0.0913 - val_kl_loss: 103.7629 - val_recon_loss: 0.0913\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1088 - kl_loss: 99.2432 - recon_loss: 0.1088 - val_loss: 0.0898 - val_kl_loss: 104.6864 - val_recon_loss: 0.0898\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0992 - kl_loss: 99.1223 - recon_loss: 0.0992 - val_loss: 0.1034 - val_kl_loss: 103.3499 - val_recon_loss: 0.1034\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1023 - kl_loss: 99.1864 - recon_loss: 0.1023 - val_loss: 0.1644 - val_kl_loss: 105.6473 - val_recon_loss: 0.1644\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1027 - kl_loss: 99.0854 - recon_loss: 0.1027 - val_loss: 0.5183 - val_kl_loss: 102.1701 - val_recon_loss: 0.5183\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1021 - kl_loss: 98.9295 - recon_loss: 0.1021 - val_loss: 0.0834 - val_kl_loss: 104.0689 - val_recon_loss: 0.0834\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1033 - kl_loss: 99.0559 - recon_loss: 0.1033 - val_loss: 0.1125 - val_kl_loss: 103.8551 - val_recon_loss: 0.1125\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1001 - kl_loss: 98.9588 - recon_loss: 0.1001 - val_loss: 0.0893 - val_kl_loss: 103.5415 - val_recon_loss: 0.0893\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1075 - kl_loss: 98.6520 - recon_loss: 0.1075 - val_loss: 0.0775 - val_kl_loss: 103.9622 - val_recon_loss: 0.0775\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.0978 - kl_loss: 98.5390 - recon_loss: 0.0978 - val_loss: 0.3480 - val_kl_loss: 104.2007 - val_recon_loss: 0.3480\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1043 - kl_loss: 98.7733 - recon_loss: 0.1043 - val_loss: 0.0847 - val_kl_loss: 104.6001 - val_recon_loss: 0.0847\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1010 - kl_loss: 98.8306 - recon_loss: 0.1010 - val_loss: 0.0846 - val_kl_loss: 103.4434 - val_recon_loss: 0.0846\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1023 - kl_loss: 98.7192 - recon_loss: 0.1023 - val_loss: 0.1812 - val_kl_loss: 102.1683 - val_recon_loss: 0.1812\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1002 - kl_loss: 98.7090 - recon_loss: 0.1002 - val_loss: 0.1214 - val_kl_loss: 104.2812 - val_recon_loss: 0.1214\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0994 - kl_loss: 98.9241 - recon_loss: 0.0994 - val_loss: 0.1172 - val_kl_loss: 104.1351 - val_recon_loss: 0.1172\n",
      "========================= Model5=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 5), (None, 5 1990        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 5)            0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1776        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,864\n",
      "Trainable params: 3,864\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 5)            65          enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 5)            65          enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,990\n",
      "Trainable params: 1,990\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 21)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           264         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,776\n",
      "Trainable params: 1,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 156us/step - loss: 31.5968 - kl_loss: 13.1149 - recon_loss: 31.5968 - val_loss: 13.5897 - val_kl_loss: 33.9761 - val_recon_loss: 13.5897\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 5.7435 - kl_loss: 38.9775 - recon_loss: 5.7435 - val_loss: 2.7508 - val_kl_loss: 49.0083 - val_recon_loss: 2.7508\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 1.9118 - kl_loss: 49.7173 - recon_loss: 1.9118 - val_loss: 1.5170 - val_kl_loss: 61.2423 - val_recon_loss: 1.5170\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 1.2455 - kl_loss: 56.8907 - recon_loss: 1.2455 - val_loss: 1.0239 - val_kl_loss: 67.0189 - val_recon_loss: 1.0239\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 63us/step - loss: 0.9484 - kl_loss: 62.9909 - recon_loss: 0.9484 - val_loss: 0.9097 - val_kl_loss: 71.5011 - val_recon_loss: 0.9097\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 89us/step - loss: 0.7569 - kl_loss: 67.9081 - recon_loss: 0.7569 - val_loss: 0.7187 - val_kl_loss: 76.8969 - val_recon_loss: 0.7187\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.6190 - kl_loss: 71.9687 - recon_loss: 0.6190 - val_loss: 0.6929 - val_kl_loss: 81.4809 - val_recon_loss: 0.6929\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.5380 - kl_loss: 75.3929 - recon_loss: 0.5380 - val_loss: 0.6414 - val_kl_loss: 85.3150 - val_recon_loss: 0.6414\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.4846 - kl_loss: 78.1578 - recon_loss: 0.4846 - val_loss: 0.5730 - val_kl_loss: 85.2078 - val_recon_loss: 0.5730\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.4395 - kl_loss: 80.4414 - recon_loss: 0.4395 - val_loss: 0.4827 - val_kl_loss: 90.4369 - val_recon_loss: 0.4827\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.4119 - kl_loss: 82.6513 - recon_loss: 0.4119 - val_loss: 0.5714 - val_kl_loss: 90.1610 - val_recon_loss: 0.5714\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.3879 - kl_loss: 83.7909 - recon_loss: 0.3879 - val_loss: 0.3775 - val_kl_loss: 93.4799 - val_recon_loss: 0.3775\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3686 - kl_loss: 84.5669 - recon_loss: 0.3686 - val_loss: 0.3764 - val_kl_loss: 92.9467 - val_recon_loss: 0.3764\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3545 - kl_loss: 85.3245 - recon_loss: 0.3545 - val_loss: 0.3422 - val_kl_loss: 93.4213 - val_recon_loss: 0.3422\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3383 - kl_loss: 85.8252 - recon_loss: 0.3383 - val_loss: 0.4028 - val_kl_loss: 92.3236 - val_recon_loss: 0.4028\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3313 - kl_loss: 86.1238 - recon_loss: 0.3313 - val_loss: 0.3745 - val_kl_loss: 94.5182 - val_recon_loss: 0.3745\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 86us/step - loss: 0.3168 - kl_loss: 86.2122 - recon_loss: 0.3168 - val_loss: 0.2911 - val_kl_loss: 93.2892 - val_recon_loss: 0.2911\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.3079 - kl_loss: 86.3783 - recon_loss: 0.3079 - val_loss: 0.3223 - val_kl_loss: 93.0940 - val_recon_loss: 0.3223\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.3064 - kl_loss: 86.5170 - recon_loss: 0.3064 - val_loss: 0.3071 - val_kl_loss: 93.9610 - val_recon_loss: 0.3071\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2957 - kl_loss: 86.5914 - recon_loss: 0.2957 - val_loss: 0.3381 - val_kl_loss: 94.5424 - val_recon_loss: 0.3381\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.2906 - kl_loss: 86.9351 - recon_loss: 0.2906 - val_loss: 0.5788 - val_kl_loss: 96.1057 - val_recon_loss: 0.5788\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2849 - kl_loss: 87.2109 - recon_loss: 0.2849 - val_loss: 0.3168 - val_kl_loss: 95.0578 - val_recon_loss: 0.3168\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2862 - kl_loss: 87.0480 - recon_loss: 0.2862 - val_loss: 0.3081 - val_kl_loss: 94.1878 - val_recon_loss: 0.3081\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2661 - kl_loss: 87.1599 - recon_loss: 0.2661 - val_loss: 0.3336 - val_kl_loss: 94.7883 - val_recon_loss: 0.3336\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2640 - kl_loss: 86.8062 - recon_loss: 0.2640 - val_loss: 0.3131 - val_kl_loss: 95.3777 - val_recon_loss: 0.3131\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2689 - kl_loss: 86.7086 - recon_loss: 0.2689 - val_loss: 0.2414 - val_kl_loss: 93.4300 - val_recon_loss: 0.2414\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2558 - kl_loss: 86.5387 - recon_loss: 0.2558 - val_loss: 0.4985 - val_kl_loss: 90.1345 - val_recon_loss: 0.4985\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2566 - kl_loss: 86.7572 - recon_loss: 0.2566 - val_loss: 0.2727 - val_kl_loss: 93.2768 - val_recon_loss: 0.2727\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.2442 - kl_loss: 86.7616 - recon_loss: 0.2442 - val_loss: 0.2506 - val_kl_loss: 94.3796 - val_recon_loss: 0.2506\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2455 - kl_loss: 86.7738 - recon_loss: 0.2455 - val_loss: 0.3000 - val_kl_loss: 93.6680 - val_recon_loss: 0.3000\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.2398 - kl_loss: 87.0556 - recon_loss: 0.2398 - val_loss: 0.3552 - val_kl_loss: 91.4928 - val_recon_loss: 0.3552\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2375 - kl_loss: 87.0688 - recon_loss: 0.2375 - val_loss: 0.3859 - val_kl_loss: 94.0218 - val_recon_loss: 0.3859\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.2334 - kl_loss: 86.9229 - recon_loss: 0.2334 - val_loss: 0.6525 - val_kl_loss: 96.2698 - val_recon_loss: 0.6525\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2342 - kl_loss: 86.7197 - recon_loss: 0.2342 - val_loss: 0.2294 - val_kl_loss: 93.0655 - val_recon_loss: 0.2294\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2205 - kl_loss: 86.9942 - recon_loss: 0.2205 - val_loss: 0.2620 - val_kl_loss: 93.7503 - val_recon_loss: 0.2620\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2237 - kl_loss: 87.4006 - recon_loss: 0.2237 - val_loss: 0.2644 - val_kl_loss: 93.7546 - val_recon_loss: 0.2644\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2190 - kl_loss: 87.3590 - recon_loss: 0.2190 - val_loss: 0.2254 - val_kl_loss: 93.9555 - val_recon_loss: 0.2254\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2164 - kl_loss: 87.1591 - recon_loss: 0.2164 - val_loss: 0.2766 - val_kl_loss: 93.2694 - val_recon_loss: 0.2766\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 87us/step - loss: 0.2178 - kl_loss: 87.2358 - recon_loss: 0.2178 - val_loss: 0.2237 - val_kl_loss: 94.4289 - val_recon_loss: 0.2237\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2111 - kl_loss: 87.1731 - recon_loss: 0.2111 - val_loss: 0.2750 - val_kl_loss: 93.1422 - val_recon_loss: 0.2750\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2093 - kl_loss: 87.0175 - recon_loss: 0.2093 - val_loss: 0.2394 - val_kl_loss: 93.0309 - val_recon_loss: 0.2394\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2078 - kl_loss: 87.0477 - recon_loss: 0.2078 - val_loss: 0.2596 - val_kl_loss: 92.2402 - val_recon_loss: 0.2596\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2023 - kl_loss: 87.1084 - recon_loss: 0.2023 - val_loss: 0.3751 - val_kl_loss: 94.0348 - val_recon_loss: 0.3751\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2053 - kl_loss: 87.1022 - recon_loss: 0.2053 - val_loss: 0.2263 - val_kl_loss: 93.3906 - val_recon_loss: 0.2263\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1997 - kl_loss: 86.9621 - recon_loss: 0.1997 - val_loss: 0.2517 - val_kl_loss: 93.9613 - val_recon_loss: 0.2517\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1985 - kl_loss: 86.7938 - recon_loss: 0.1985 - val_loss: 0.1983 - val_kl_loss: 92.3810 - val_recon_loss: 0.1983\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1974 - kl_loss: 86.9606 - recon_loss: 0.1974 - val_loss: 0.2014 - val_kl_loss: 92.4693 - val_recon_loss: 0.2014\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1926 - kl_loss: 86.8947 - recon_loss: 0.1926 - val_loss: 0.2653 - val_kl_loss: 92.4480 - val_recon_loss: 0.2653\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1908 - kl_loss: 87.2403 - recon_loss: 0.1908 - val_loss: 0.1779 - val_kl_loss: 93.6050 - val_recon_loss: 0.1779\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1867 - kl_loss: 87.3639 - recon_loss: 0.1867 - val_loss: 0.2875 - val_kl_loss: 95.7578 - val_recon_loss: 0.2875\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.1880 - kl_loss: 87.1123 - recon_loss: 0.1880 - val_loss: 0.2144 - val_kl_loss: 94.2587 - val_recon_loss: 0.2144\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1872 - kl_loss: 87.2276 - recon_loss: 0.1872 - val_loss: 0.1896 - val_kl_loss: 93.3176 - val_recon_loss: 0.1896\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1837 - kl_loss: 87.3053 - recon_loss: 0.1837 - val_loss: 0.2427 - val_kl_loss: 93.4130 - val_recon_loss: 0.2427\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1830 - kl_loss: 87.3517 - recon_loss: 0.1830 - val_loss: 0.1988 - val_kl_loss: 93.4261 - val_recon_loss: 0.1988\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1787 - kl_loss: 87.0007 - recon_loss: 0.1787 - val_loss: 0.2049 - val_kl_loss: 92.1714 - val_recon_loss: 0.2049\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1800 - kl_loss: 86.9967 - recon_loss: 0.1800 - val_loss: 0.2361 - val_kl_loss: 93.9405 - val_recon_loss: 0.2361\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1756 - kl_loss: 86.9905 - recon_loss: 0.1756 - val_loss: 0.1592 - val_kl_loss: 92.7211 - val_recon_loss: 0.1592\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1717 - kl_loss: 86.9425 - recon_loss: 0.1717 - val_loss: 0.1769 - val_kl_loss: 92.3107 - val_recon_loss: 0.1769\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1752 - kl_loss: 86.7182 - recon_loss: 0.1752 - val_loss: 0.1611 - val_kl_loss: 92.4783 - val_recon_loss: 0.1611\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1685 - kl_loss: 86.5142 - recon_loss: 0.1685 - val_loss: 0.1847 - val_kl_loss: 93.0191 - val_recon_loss: 0.1847\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1665 - kl_loss: 86.6649 - recon_loss: 0.1665 - val_loss: 0.1558 - val_kl_loss: 93.2535 - val_recon_loss: 0.1558\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1658 - kl_loss: 86.5673 - recon_loss: 0.1658 - val_loss: 0.2923 - val_kl_loss: 90.8932 - val_recon_loss: 0.2923\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1698 - kl_loss: 86.5212 - recon_loss: 0.1698 - val_loss: 0.2493 - val_kl_loss: 89.8574 - val_recon_loss: 0.2493\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1618 - kl_loss: 86.6593 - recon_loss: 0.1618 - val_loss: 0.1677 - val_kl_loss: 92.0981 - val_recon_loss: 0.1677\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1615 - kl_loss: 86.5832 - recon_loss: 0.1615 - val_loss: 0.1791 - val_kl_loss: 92.7684 - val_recon_loss: 0.1791\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1582 - kl_loss: 86.6265 - recon_loss: 0.1582 - val_loss: 0.3379 - val_kl_loss: 91.2912 - val_recon_loss: 0.3379\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1581 - kl_loss: 86.7013 - recon_loss: 0.1581 - val_loss: 0.1661 - val_kl_loss: 92.8102 - val_recon_loss: 0.1661\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1537 - kl_loss: 86.6587 - recon_loss: 0.1537 - val_loss: 0.2039 - val_kl_loss: 93.5310 - val_recon_loss: 0.2039\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1545 - kl_loss: 86.9772 - recon_loss: 0.1545 - val_loss: 0.2542 - val_kl_loss: 92.9150 - val_recon_loss: 0.2542\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1547 - kl_loss: 86.8318 - recon_loss: 0.1547 - val_loss: 0.2763 - val_kl_loss: 94.1644 - val_recon_loss: 0.2763\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1500 - kl_loss: 86.8718 - recon_loss: 0.1500 - val_loss: 0.2186 - val_kl_loss: 93.4288 - val_recon_loss: 0.2186\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1523 - kl_loss: 86.8271 - recon_loss: 0.1523 - val_loss: 0.1507 - val_kl_loss: 91.9629 - val_recon_loss: 0.1507\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1492 - kl_loss: 86.6937 - recon_loss: 0.1492 - val_loss: 0.1525 - val_kl_loss: 91.3309 - val_recon_loss: 0.1525\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1464 - kl_loss: 86.4156 - recon_loss: 0.1464 - val_loss: 0.1594 - val_kl_loss: 91.4026 - val_recon_loss: 0.1594\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1493 - kl_loss: 86.2369 - recon_loss: 0.1493 - val_loss: 0.3121 - val_kl_loss: 91.0139 - val_recon_loss: 0.3121\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1442 - kl_loss: 86.3240 - recon_loss: 0.1442 - val_loss: 0.2679 - val_kl_loss: 92.0169 - val_recon_loss: 0.2679\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1461 - kl_loss: 86.1617 - recon_loss: 0.1461 - val_loss: 0.1678 - val_kl_loss: 90.7882 - val_recon_loss: 0.1678\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1442 - kl_loss: 86.2596 - recon_loss: 0.1442 - val_loss: 0.1217 - val_kl_loss: 91.6503 - val_recon_loss: 0.1217\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1411 - kl_loss: 86.3803 - recon_loss: 0.1411 - val_loss: 0.3619 - val_kl_loss: 90.2297 - val_recon_loss: 0.3619\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1430 - kl_loss: 86.2264 - recon_loss: 0.1430 - val_loss: 0.2097 - val_kl_loss: 92.3631 - val_recon_loss: 0.2097\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1386 - kl_loss: 86.1591 - recon_loss: 0.1386 - val_loss: 0.1282 - val_kl_loss: 91.4413 - val_recon_loss: 0.1282\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1428 - kl_loss: 86.0331 - recon_loss: 0.1428 - val_loss: 0.1952 - val_kl_loss: 90.7105 - val_recon_loss: 0.1952\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1381 - kl_loss: 86.1656 - recon_loss: 0.1381 - val_loss: 0.1523 - val_kl_loss: 91.2389 - val_recon_loss: 0.1523\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1379 - kl_loss: 86.0087 - recon_loss: 0.1379 - val_loss: 0.1647 - val_kl_loss: 92.3024 - val_recon_loss: 0.1647\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1388 - kl_loss: 85.7922 - recon_loss: 0.1388 - val_loss: 0.1492 - val_kl_loss: 91.2771 - val_recon_loss: 0.1492\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1326 - kl_loss: 85.6688 - recon_loss: 0.1326 - val_loss: 0.1313 - val_kl_loss: 90.4355 - val_recon_loss: 0.1313\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.1418 - kl_loss: 85.6114 - recon_loss: 0.1418 - val_loss: 0.1155 - val_kl_loss: 91.1540 - val_recon_loss: 0.1155\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1307 - kl_loss: 85.7031 - recon_loss: 0.1307 - val_loss: 0.1323 - val_kl_loss: 90.8710 - val_recon_loss: 0.1323\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1337 - kl_loss: 85.9397 - recon_loss: 0.1337 - val_loss: 0.1380 - val_kl_loss: 90.4723 - val_recon_loss: 0.1380\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1294 - kl_loss: 85.8865 - recon_loss: 0.1294 - val_loss: 0.1841 - val_kl_loss: 93.3044 - val_recon_loss: 0.1841\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1315 - kl_loss: 86.0096 - recon_loss: 0.1315 - val_loss: 0.1842 - val_kl_loss: 92.1614 - val_recon_loss: 0.1842\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1349 - kl_loss: 85.8846 - recon_loss: 0.1349 - val_loss: 0.1240 - val_kl_loss: 91.0337 - val_recon_loss: 0.1240\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1284 - kl_loss: 85.8630 - recon_loss: 0.1284 - val_loss: 0.1296 - val_kl_loss: 91.7035 - val_recon_loss: 0.1296\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1289 - kl_loss: 86.2045 - recon_loss: 0.1289 - val_loss: 0.1472 - val_kl_loss: 92.1399 - val_recon_loss: 0.1472\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1333 - kl_loss: 86.1440 - recon_loss: 0.1333 - val_loss: 0.1856 - val_kl_loss: 91.9354 - val_recon_loss: 0.1856\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1253 - kl_loss: 85.8829 - recon_loss: 0.1253 - val_loss: 0.1379 - val_kl_loss: 91.1090 - val_recon_loss: 0.1379\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1261 - kl_loss: 85.5550 - recon_loss: 0.1261 - val_loss: 0.2531 - val_kl_loss: 92.1199 - val_recon_loss: 0.2531\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1296 - kl_loss: 85.4460 - recon_loss: 0.1296 - val_loss: 0.1113 - val_kl_loss: 90.2925 - val_recon_loss: 0.1113\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1256 - kl_loss: 85.1291 - recon_loss: 0.1256 - val_loss: 0.1369 - val_kl_loss: 90.0851 - val_recon_loss: 0.1369\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1243 - kl_loss: 84.5620 - recon_loss: 0.1243 - val_loss: 0.1777 - val_kl_loss: 90.4058 - val_recon_loss: 0.1777\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1255 - kl_loss: 84.2862 - recon_loss: 0.1255 - val_loss: 0.1329 - val_kl_loss: 89.2460 - val_recon_loss: 0.1329\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1238 - kl_loss: 84.5113 - recon_loss: 0.1238 - val_loss: 0.1318 - val_kl_loss: 90.2250 - val_recon_loss: 0.1318\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1250 - kl_loss: 84.5834 - recon_loss: 0.1250 - val_loss: 0.1873 - val_kl_loss: 91.0347 - val_recon_loss: 0.1873\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1289 - kl_loss: 84.3249 - recon_loss: 0.1289 - val_loss: 0.1448 - val_kl_loss: 89.2106 - val_recon_loss: 0.1448\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1224 - kl_loss: 84.1610 - recon_loss: 0.1224 - val_loss: 0.1637 - val_kl_loss: 88.8122 - val_recon_loss: 0.1637\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1259 - kl_loss: 83.7759 - recon_loss: 0.1259 - val_loss: 0.1726 - val_kl_loss: 90.2445 - val_recon_loss: 0.1726\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1209 - kl_loss: 83.7932 - recon_loss: 0.1209 - val_loss: 0.1518 - val_kl_loss: 88.9728 - val_recon_loss: 0.1518\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1260 - kl_loss: 83.9676 - recon_loss: 0.1260 - val_loss: 0.1248 - val_kl_loss: 88.7779 - val_recon_loss: 0.1248\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1217 - kl_loss: 83.7145 - recon_loss: 0.1217 - val_loss: 0.4003 - val_kl_loss: 86.4408 - val_recon_loss: 0.4003\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1221 - kl_loss: 83.4582 - recon_loss: 0.1221 - val_loss: 0.1462 - val_kl_loss: 89.0158 - val_recon_loss: 0.1462\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1212 - kl_loss: 83.6812 - recon_loss: 0.1212 - val_loss: 0.2332 - val_kl_loss: 87.6398 - val_recon_loss: 0.2332\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1203 - kl_loss: 83.7505 - recon_loss: 0.1203 - val_loss: 0.1352 - val_kl_loss: 89.7401 - val_recon_loss: 0.1352\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1216 - kl_loss: 83.9788 - recon_loss: 0.1216 - val_loss: 0.1781 - val_kl_loss: 89.6797 - val_recon_loss: 0.1781\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1207 - kl_loss: 84.1162 - recon_loss: 0.1207 - val_loss: 0.4181 - val_kl_loss: 90.8778 - val_recon_loss: 0.4181\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1208 - kl_loss: 84.0774 - recon_loss: 0.1208 - val_loss: 0.1309 - val_kl_loss: 89.5641 - val_recon_loss: 0.1309\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1196 - kl_loss: 84.3190 - recon_loss: 0.1196 - val_loss: 0.1378 - val_kl_loss: 90.3821 - val_recon_loss: 0.1378\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1198 - kl_loss: 84.1672 - recon_loss: 0.1198 - val_loss: 0.1670 - val_kl_loss: 88.2728 - val_recon_loss: 0.1670\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1151 - kl_loss: 84.3200 - recon_loss: 0.1151 - val_loss: 0.2140 - val_kl_loss: 87.8543 - val_recon_loss: 0.2140\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1213 - kl_loss: 84.3242 - recon_loss: 0.1213 - val_loss: 0.1187 - val_kl_loss: 89.6002 - val_recon_loss: 0.1187\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1156 - kl_loss: 84.6672 - recon_loss: 0.1156 - val_loss: 0.1515 - val_kl_loss: 90.6414 - val_recon_loss: 0.1515\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1188 - kl_loss: 84.7813 - recon_loss: 0.1188 - val_loss: 0.1762 - val_kl_loss: 91.0948 - val_recon_loss: 0.1762\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1177 - kl_loss: 84.8734 - recon_loss: 0.1177 - val_loss: 0.1052 - val_kl_loss: 90.1972 - val_recon_loss: 0.1052\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1196 - kl_loss: 85.0219 - recon_loss: 0.1196 - val_loss: 0.1319 - val_kl_loss: 90.2597 - val_recon_loss: 0.1319\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1196 - kl_loss: 85.0271 - recon_loss: 0.1196 - val_loss: 0.1080 - val_kl_loss: 89.7104 - val_recon_loss: 0.1080\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1155 - kl_loss: 85.1563 - recon_loss: 0.1155 - val_loss: 0.1630 - val_kl_loss: 88.3831 - val_recon_loss: 0.1630\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1128 - kl_loss: 85.2110 - recon_loss: 0.1128 - val_loss: 0.1154 - val_kl_loss: 90.1099 - val_recon_loss: 0.1154\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1174 - kl_loss: 85.1041 - recon_loss: 0.1174 - val_loss: 0.2369 - val_kl_loss: 88.6037 - val_recon_loss: 0.2369\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1160 - kl_loss: 85.1675 - recon_loss: 0.1160 - val_loss: 0.1093 - val_kl_loss: 90.0039 - val_recon_loss: 0.1093\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1140 - kl_loss: 85.4726 - recon_loss: 0.1140 - val_loss: 0.1427 - val_kl_loss: 89.2745 - val_recon_loss: 0.1427\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1126 - kl_loss: 85.4965 - recon_loss: 0.1126 - val_loss: 0.1282 - val_kl_loss: 90.4891 - val_recon_loss: 0.1282\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1155 - kl_loss: 85.6973 - recon_loss: 0.1155 - val_loss: 0.1197 - val_kl_loss: 89.4542 - val_recon_loss: 0.1197\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1144 - kl_loss: 85.6266 - recon_loss: 0.1144 - val_loss: 0.1257 - val_kl_loss: 89.2579 - val_recon_loss: 0.1257\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1144 - kl_loss: 85.5159 - recon_loss: 0.1144 - val_loss: 0.1151 - val_kl_loss: 90.2617 - val_recon_loss: 0.1151\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1121 - kl_loss: 85.6425 - recon_loss: 0.1121 - val_loss: 0.1120 - val_kl_loss: 89.7208 - val_recon_loss: 0.1120\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1125 - kl_loss: 85.5331 - recon_loss: 0.1125 - val_loss: 0.1143 - val_kl_loss: 90.7704 - val_recon_loss: 0.1143\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1113 - kl_loss: 85.3700 - recon_loss: 0.1113 - val_loss: 0.1745 - val_kl_loss: 90.4741 - val_recon_loss: 0.1745\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1108 - kl_loss: 85.5766 - recon_loss: 0.1108 - val_loss: 0.1136 - val_kl_loss: 89.1974 - val_recon_loss: 0.1136\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1085 - kl_loss: 85.3277 - recon_loss: 0.1085 - val_loss: 0.1890 - val_kl_loss: 89.9161 - val_recon_loss: 0.1890\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1118 - kl_loss: 85.4379 - recon_loss: 0.1118 - val_loss: 0.1321 - val_kl_loss: 91.0738 - val_recon_loss: 0.1321\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1080 - kl_loss: 85.4128 - recon_loss: 0.1080 - val_loss: 0.1351 - val_kl_loss: 90.7224 - val_recon_loss: 0.1351\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1154 - kl_loss: 85.5468 - recon_loss: 0.1154 - val_loss: 0.1570 - val_kl_loss: 90.4960 - val_recon_loss: 0.1570\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1112 - kl_loss: 85.4744 - recon_loss: 0.1112 - val_loss: 0.1132 - val_kl_loss: 89.6242 - val_recon_loss: 0.1132\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1067 - kl_loss: 85.3742 - recon_loss: 0.1067 - val_loss: 0.1613 - val_kl_loss: 90.9043 - val_recon_loss: 0.1613\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1113 - kl_loss: 85.2774 - recon_loss: 0.1113 - val_loss: 0.2104 - val_kl_loss: 89.6529 - val_recon_loss: 0.2104\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1105 - kl_loss: 85.5702 - recon_loss: 0.1105 - val_loss: 0.1092 - val_kl_loss: 89.9439 - val_recon_loss: 0.1092\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1104 - kl_loss: 85.8510 - recon_loss: 0.1104 - val_loss: 0.1409 - val_kl_loss: 90.0400 - val_recon_loss: 0.1409\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1102 - kl_loss: 85.6184 - recon_loss: 0.1102 - val_loss: 0.1521 - val_kl_loss: 89.5676 - val_recon_loss: 0.1521\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1087 - kl_loss: 85.8221 - recon_loss: 0.1087 - val_loss: 0.1383 - val_kl_loss: 89.8327 - val_recon_loss: 0.1383\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1114 - kl_loss: 85.9820 - recon_loss: 0.1114 - val_loss: 0.1460 - val_kl_loss: 90.1857 - val_recon_loss: 0.1460\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1073 - kl_loss: 86.1120 - recon_loss: 0.1073 - val_loss: 0.1096 - val_kl_loss: 90.3552 - val_recon_loss: 0.1096\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1089 - kl_loss: 85.9261 - recon_loss: 0.1089 - val_loss: 0.0962 - val_kl_loss: 90.9010 - val_recon_loss: 0.0962\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1088 - kl_loss: 85.8242 - recon_loss: 0.1088 - val_loss: 0.1577 - val_kl_loss: 90.8086 - val_recon_loss: 0.1577\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1083 - kl_loss: 86.0735 - recon_loss: 0.1083 - val_loss: 0.1458 - val_kl_loss: 91.7339 - val_recon_loss: 0.1458\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1030 - kl_loss: 86.3753 - recon_loss: 0.1030 - val_loss: 0.2245 - val_kl_loss: 89.0891 - val_recon_loss: 0.2245\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1066 - kl_loss: 86.2668 - recon_loss: 0.1066 - val_loss: 0.1193 - val_kl_loss: 90.2747 - val_recon_loss: 0.1193\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1061 - kl_loss: 86.1523 - recon_loss: 0.1061 - val_loss: 0.1616 - val_kl_loss: 91.3289 - val_recon_loss: 0.1616\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1099 - kl_loss: 86.2629 - recon_loss: 0.1099 - val_loss: 0.0956 - val_kl_loss: 91.1542 - val_recon_loss: 0.0956\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1035 - kl_loss: 86.4508 - recon_loss: 0.1035 - val_loss: 0.3819 - val_kl_loss: 93.2660 - val_recon_loss: 0.3819\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1072 - kl_loss: 86.6935 - recon_loss: 0.1072 - val_loss: 0.1198 - val_kl_loss: 91.9258 - val_recon_loss: 0.1198\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1090 - kl_loss: 86.7123 - recon_loss: 0.1090 - val_loss: 0.1003 - val_kl_loss: 91.3696 - val_recon_loss: 0.1003\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1066 - kl_loss: 86.8012 - recon_loss: 0.1066 - val_loss: 0.1100 - val_kl_loss: 91.9286 - val_recon_loss: 0.1100\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1020 - kl_loss: 86.5414 - recon_loss: 0.1020 - val_loss: 0.2242 - val_kl_loss: 92.7878 - val_recon_loss: 0.2242\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1062 - kl_loss: 86.5487 - recon_loss: 0.1062 - val_loss: 0.1849 - val_kl_loss: 91.1306 - val_recon_loss: 0.1849\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1045 - kl_loss: 86.5082 - recon_loss: 0.1045 - val_loss: 0.1476 - val_kl_loss: 91.6353 - val_recon_loss: 0.1476\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1063 - kl_loss: 86.5611 - recon_loss: 0.1063 - val_loss: 0.1303 - val_kl_loss: 90.5218 - val_recon_loss: 0.1303\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1055 - kl_loss: 86.7102 - recon_loss: 0.1055 - val_loss: 0.0945 - val_kl_loss: 91.5311 - val_recon_loss: 0.0945\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1027 - kl_loss: 86.8598 - recon_loss: 0.1027 - val_loss: 0.0922 - val_kl_loss: 91.7484 - val_recon_loss: 0.0922\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1041 - kl_loss: 87.0712 - recon_loss: 0.1041 - val_loss: 0.1042 - val_kl_loss: 91.0785 - val_recon_loss: 0.1042\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1032 - kl_loss: 87.3274 - recon_loss: 0.1032 - val_loss: 0.1285 - val_kl_loss: 93.0919 - val_recon_loss: 0.1285\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1044 - kl_loss: 87.2414 - recon_loss: 0.1044 - val_loss: 0.1004 - val_kl_loss: 91.7953 - val_recon_loss: 0.1004\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1011 - kl_loss: 87.1733 - recon_loss: 0.1011 - val_loss: 0.1389 - val_kl_loss: 90.6690 - val_recon_loss: 0.1389\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1075 - kl_loss: 87.0150 - recon_loss: 0.1075 - val_loss: 0.1106 - val_kl_loss: 91.6890 - val_recon_loss: 0.1106\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1026 - kl_loss: 87.2424 - recon_loss: 0.1026 - val_loss: 0.0968 - val_kl_loss: 91.6875 - val_recon_loss: 0.0968\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.0984 - kl_loss: 87.3971 - recon_loss: 0.0984 - val_loss: 0.1336 - val_kl_loss: 91.2107 - val_recon_loss: 0.1336\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1063 - kl_loss: 87.3842 - recon_loss: 0.1063 - val_loss: 0.0957 - val_kl_loss: 91.5164 - val_recon_loss: 0.0957\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0998 - kl_loss: 87.2227 - recon_loss: 0.0998 - val_loss: 0.2461 - val_kl_loss: 90.5018 - val_recon_loss: 0.2461\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1007 - kl_loss: 87.3245 - recon_loss: 0.1007 - val_loss: 0.1314 - val_kl_loss: 92.6007 - val_recon_loss: 0.1314\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1023 - kl_loss: 87.8161 - recon_loss: 0.1023 - val_loss: 0.1627 - val_kl_loss: 92.6977 - val_recon_loss: 0.1627\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0997 - kl_loss: 87.8496 - recon_loss: 0.0997 - val_loss: 0.2707 - val_kl_loss: 91.0946 - val_recon_loss: 0.2707\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1025 - kl_loss: 87.9002 - recon_loss: 0.1025 - val_loss: 0.1550 - val_kl_loss: 91.9647 - val_recon_loss: 0.1550\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1016 - kl_loss: 87.9134 - recon_loss: 0.1016 - val_loss: 0.1125 - val_kl_loss: 92.4205 - val_recon_loss: 0.1125\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1014 - kl_loss: 87.8532 - recon_loss: 0.1014 - val_loss: 0.0854 - val_kl_loss: 91.5772 - val_recon_loss: 0.0854\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1020 - kl_loss: 87.7392 - recon_loss: 0.1020 - val_loss: 0.1430 - val_kl_loss: 92.2411 - val_recon_loss: 0.1430\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1015 - kl_loss: 87.6903 - recon_loss: 0.1015 - val_loss: 0.1522 - val_kl_loss: 92.7158 - val_recon_loss: 0.1522\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0977 - kl_loss: 87.6415 - recon_loss: 0.0977 - val_loss: 0.2151 - val_kl_loss: 93.8707 - val_recon_loss: 0.2151\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0997 - kl_loss: 87.8892 - recon_loss: 0.0997 - val_loss: 0.3200 - val_kl_loss: 93.4358 - val_recon_loss: 0.3200\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1000 - kl_loss: 87.7530 - recon_loss: 0.1000 - val_loss: 0.1051 - val_kl_loss: 92.0487 - val_recon_loss: 0.1051\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1007 - kl_loss: 87.5802 - recon_loss: 0.1007 - val_loss: 0.2310 - val_kl_loss: 90.2101 - val_recon_loss: 0.2310\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1002 - kl_loss: 87.5382 - recon_loss: 0.1002 - val_loss: 0.1254 - val_kl_loss: 90.9677 - val_recon_loss: 0.1254\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0998 - kl_loss: 87.4253 - recon_loss: 0.0998 - val_loss: 0.1035 - val_kl_loss: 91.4597 - val_recon_loss: 0.1035\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0977 - kl_loss: 87.2562 - recon_loss: 0.0977 - val_loss: 0.1081 - val_kl_loss: 92.3094 - val_recon_loss: 0.1081\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1001 - kl_loss: 87.3866 - recon_loss: 0.1001 - val_loss: 0.0988 - val_kl_loss: 90.9981 - val_recon_loss: 0.0988\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0984 - kl_loss: 87.3567 - recon_loss: 0.0984 - val_loss: 0.0909 - val_kl_loss: 91.9222 - val_recon_loss: 0.0909\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0989 - kl_loss: 87.7177 - recon_loss: 0.0989 - val_loss: 0.2317 - val_kl_loss: 90.2150 - val_recon_loss: 0.2317\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.0985 - kl_loss: 87.7403 - recon_loss: 0.0985 - val_loss: 0.1583 - val_kl_loss: 92.0734 - val_recon_loss: 0.1583\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0977 - kl_loss: 87.8000 - recon_loss: 0.0977 - val_loss: 0.0918 - val_kl_loss: 91.7354 - val_recon_loss: 0.0918\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0974 - kl_loss: 87.6435 - recon_loss: 0.0974 - val_loss: 0.1130 - val_kl_loss: 92.8918 - val_recon_loss: 0.1130\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1008 - kl_loss: 87.5608 - recon_loss: 0.1008 - val_loss: 0.0971 - val_kl_loss: 92.2951 - val_recon_loss: 0.0971\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0952 - kl_loss: 87.6305 - recon_loss: 0.0952 - val_loss: 0.0946 - val_kl_loss: 91.7147 - val_recon_loss: 0.0946\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0999 - kl_loss: 87.6044 - recon_loss: 0.0999 - val_loss: 0.1073 - val_kl_loss: 92.2522 - val_recon_loss: 0.1073\n",
      "========================= Model6=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 6), (None, 6 2016        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 6)            0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1788        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,902\n",
      "Trainable params: 3,902\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 6)            78          enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 6)            78          enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,016\n",
      "Trainable params: 2,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 22)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           276         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,788\n",
      "Trainable params: 1,788\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 140us/step - loss: 24.6298 - kl_loss: 21.7587 - recon_loss: 24.6298 - val_loss: 4.8178 - val_kl_loss: 53.8385 - val_recon_loss: 4.8178\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 2.8809 - kl_loss: 61.3263 - recon_loss: 2.8809 - val_loss: 1.8310 - val_kl_loss: 77.6929 - val_recon_loss: 1.8310\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 1.4486 - kl_loss: 79.8897 - recon_loss: 1.4486 - val_loss: 1.2201 - val_kl_loss: 87.0345 - val_recon_loss: 1.2201\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 1.0273 - kl_loss: 88.9721 - recon_loss: 1.0273 - val_loss: 1.6168 - val_kl_loss: 95.1038 - val_recon_loss: 1.6168\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.8623 - kl_loss: 95.4533 - recon_loss: 0.8623 - val_loss: 0.8048 - val_kl_loss: 104.9825 - val_recon_loss: 0.8048\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.7502 - kl_loss: 99.9386 - recon_loss: 0.7502 - val_loss: 0.9378 - val_kl_loss: 103.3240 - val_recon_loss: 0.9378\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.6939 - kl_loss: 102.6734 - recon_loss: 0.6939 - val_loss: 0.9946 - val_kl_loss: 108.8644 - val_recon_loss: 0.9946\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.6244 - kl_loss: 105.1139 - recon_loss: 0.6244 - val_loss: 0.6266 - val_kl_loss: 113.6050 - val_recon_loss: 0.6266\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.5784 - kl_loss: 107.2287 - recon_loss: 0.5784 - val_loss: 0.5914 - val_kl_loss: 111.2733 - val_recon_loss: 0.5914\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.5315 - kl_loss: 108.5656 - recon_loss: 0.5315 - val_loss: 0.5628 - val_kl_loss: 114.7554 - val_recon_loss: 0.5628\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.4964 - kl_loss: 108.9574 - recon_loss: 0.4964 - val_loss: 0.7530 - val_kl_loss: 115.1332 - val_recon_loss: 0.7530\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.4643 - kl_loss: 109.2528 - recon_loss: 0.4643 - val_loss: 0.5347 - val_kl_loss: 113.3505 - val_recon_loss: 0.5347\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.4306 - kl_loss: 109.9680 - recon_loss: 0.4306 - val_loss: 0.5254 - val_kl_loss: 115.4522 - val_recon_loss: 0.5254\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.4033 - kl_loss: 109.2142 - recon_loss: 0.4033 - val_loss: 0.4441 - val_kl_loss: 111.7552 - val_recon_loss: 0.4441\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3874 - kl_loss: 108.4773 - recon_loss: 0.3874 - val_loss: 0.3667 - val_kl_loss: 114.0310 - val_recon_loss: 0.3667\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.3699 - kl_loss: 108.3164 - recon_loss: 0.3699 - val_loss: 0.4364 - val_kl_loss: 114.1336 - val_recon_loss: 0.4364\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.3517 - kl_loss: 108.3829 - recon_loss: 0.3517 - val_loss: 0.3562 - val_kl_loss: 113.0776 - val_recon_loss: 0.3562\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.3366 - kl_loss: 107.6646 - recon_loss: 0.3366 - val_loss: 0.3555 - val_kl_loss: 112.9875 - val_recon_loss: 0.3555\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.3312 - kl_loss: 107.8613 - recon_loss: 0.3312 - val_loss: 0.5575 - val_kl_loss: 112.6155 - val_recon_loss: 0.5575\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.3151 - kl_loss: 107.4061 - recon_loss: 0.3151 - val_loss: 0.3022 - val_kl_loss: 113.0696 - val_recon_loss: 0.3022\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.3018 - kl_loss: 106.8489 - recon_loss: 0.3018 - val_loss: 0.4535 - val_kl_loss: 110.7135 - val_recon_loss: 0.4535\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2891 - kl_loss: 105.7047 - recon_loss: 0.2891 - val_loss: 0.2838 - val_kl_loss: 111.8418 - val_recon_loss: 0.2838\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2826 - kl_loss: 105.3845 - recon_loss: 0.2826 - val_loss: 0.2950 - val_kl_loss: 108.5448 - val_recon_loss: 0.2950\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2620 - kl_loss: 104.4341 - recon_loss: 0.2620 - val_loss: 0.2858 - val_kl_loss: 109.0510 - val_recon_loss: 0.2858\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2639 - kl_loss: 104.1981 - recon_loss: 0.2639 - val_loss: 0.3345 - val_kl_loss: 106.4613 - val_recon_loss: 0.3345\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2551 - kl_loss: 104.1668 - recon_loss: 0.2551 - val_loss: 0.2456 - val_kl_loss: 109.5033 - val_recon_loss: 0.2456\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.2448 - kl_loss: 104.3736 - recon_loss: 0.2448 - val_loss: 0.4354 - val_kl_loss: 107.6190 - val_recon_loss: 0.4354\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2459 - kl_loss: 103.8983 - recon_loss: 0.2459 - val_loss: 0.2676 - val_kl_loss: 109.6443 - val_recon_loss: 0.2676\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2324 - kl_loss: 103.8497 - recon_loss: 0.2324 - val_loss: 0.4715 - val_kl_loss: 106.7440 - val_recon_loss: 0.4715\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.2344 - kl_loss: 103.7474 - recon_loss: 0.2344 - val_loss: 0.2341 - val_kl_loss: 107.3766 - val_recon_loss: 0.2341\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2271 - kl_loss: 103.4690 - recon_loss: 0.2271 - val_loss: 0.2249 - val_kl_loss: 106.6681 - val_recon_loss: 0.2249\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2230 - kl_loss: 103.0463 - recon_loss: 0.2230 - val_loss: 0.1528 - val_kl_loss: 107.1925 - val_recon_loss: 0.1528\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2231 - kl_loss: 102.7243 - recon_loss: 0.2231 - val_loss: 0.1755 - val_kl_loss: 107.3205 - val_recon_loss: 0.1755\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2086 - kl_loss: 102.6876 - recon_loss: 0.2086 - val_loss: 0.2540 - val_kl_loss: 106.4514 - val_recon_loss: 0.2540\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2142 - kl_loss: 102.8825 - recon_loss: 0.2142 - val_loss: 0.1648 - val_kl_loss: 106.6023 - val_recon_loss: 0.1648\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2094 - kl_loss: 102.8237 - recon_loss: 0.2094 - val_loss: 0.2386 - val_kl_loss: 106.8447 - val_recon_loss: 0.2386\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2010 - kl_loss: 102.7625 - recon_loss: 0.2010 - val_loss: 0.1665 - val_kl_loss: 107.8583 - val_recon_loss: 0.1665\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2045 - kl_loss: 102.6990 - recon_loss: 0.2045 - val_loss: 0.1845 - val_kl_loss: 107.5602 - val_recon_loss: 0.1845\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1909 - kl_loss: 102.4465 - recon_loss: 0.1909 - val_loss: 0.2222 - val_kl_loss: 106.7678 - val_recon_loss: 0.2222\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2012 - kl_loss: 102.2302 - recon_loss: 0.2012 - val_loss: 0.1769 - val_kl_loss: 106.6368 - val_recon_loss: 0.1769\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1925 - kl_loss: 101.6913 - recon_loss: 0.1925 - val_loss: 0.2716 - val_kl_loss: 103.0665 - val_recon_loss: 0.2716\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.2002 - kl_loss: 101.3189 - recon_loss: 0.2002 - val_loss: 0.2021 - val_kl_loss: 107.4147 - val_recon_loss: 0.2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1822 - kl_loss: 101.3532 - recon_loss: 0.1822 - val_loss: 0.1525 - val_kl_loss: 104.8578 - val_recon_loss: 0.1525\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1861 - kl_loss: 101.2643 - recon_loss: 0.1861 - val_loss: 0.2634 - val_kl_loss: 104.8258 - val_recon_loss: 0.2634\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1828 - kl_loss: 101.5072 - recon_loss: 0.1828 - val_loss: 0.6286 - val_kl_loss: 108.4757 - val_recon_loss: 0.6286\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1826 - kl_loss: 101.3806 - recon_loss: 0.1826 - val_loss: 0.1422 - val_kl_loss: 106.0369 - val_recon_loss: 0.1422\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 87us/step - loss: 0.1866 - kl_loss: 100.9738 - recon_loss: 0.1866 - val_loss: 0.1284 - val_kl_loss: 105.2762 - val_recon_loss: 0.1284\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1782 - kl_loss: 100.6841 - recon_loss: 0.1782 - val_loss: 0.1714 - val_kl_loss: 105.2679 - val_recon_loss: 0.1714\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1826 - kl_loss: 100.6344 - recon_loss: 0.1826 - val_loss: 0.1528 - val_kl_loss: 105.1608 - val_recon_loss: 0.1528\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1770 - kl_loss: 100.2328 - recon_loss: 0.1770 - val_loss: 0.1336 - val_kl_loss: 104.5989 - val_recon_loss: 0.1336\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1816 - kl_loss: 100.3565 - recon_loss: 0.1816 - val_loss: 0.1819 - val_kl_loss: 102.5181 - val_recon_loss: 0.1819\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1706 - kl_loss: 100.0048 - recon_loss: 0.1706 - val_loss: 0.1313 - val_kl_loss: 104.3066 - val_recon_loss: 0.1313\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1694 - kl_loss: 99.9425 - recon_loss: 0.1694 - val_loss: 0.1931 - val_kl_loss: 103.5874 - val_recon_loss: 0.1931\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1674 - kl_loss: 99.4364 - recon_loss: 0.1674 - val_loss: 0.1444 - val_kl_loss: 103.5060 - val_recon_loss: 0.1444\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1713 - kl_loss: 99.7086 - recon_loss: 0.1713 - val_loss: 0.1476 - val_kl_loss: 103.6900 - val_recon_loss: 0.1476\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1744 - kl_loss: 99.7810 - recon_loss: 0.1744 - val_loss: 0.1642 - val_kl_loss: 104.6876 - val_recon_loss: 0.1642\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1718 - kl_loss: 100.0955 - recon_loss: 0.1718 - val_loss: 0.1535 - val_kl_loss: 105.9138 - val_recon_loss: 0.1535\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1689 - kl_loss: 100.1740 - recon_loss: 0.1689 - val_loss: 0.1558 - val_kl_loss: 105.4398 - val_recon_loss: 0.1558\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1672 - kl_loss: 100.5338 - recon_loss: 0.1672 - val_loss: 0.2894 - val_kl_loss: 102.8738 - val_recon_loss: 0.2894\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1622 - kl_loss: 100.1876 - recon_loss: 0.1622 - val_loss: 0.1499 - val_kl_loss: 104.0046 - val_recon_loss: 0.1499\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1680 - kl_loss: 100.1528 - recon_loss: 0.1680 - val_loss: 0.1333 - val_kl_loss: 104.1877 - val_recon_loss: 0.1333\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1615 - kl_loss: 100.5687 - recon_loss: 0.1615 - val_loss: 0.2045 - val_kl_loss: 104.3441 - val_recon_loss: 0.2045\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1615 - kl_loss: 100.1443 - recon_loss: 0.1615 - val_loss: 0.1397 - val_kl_loss: 104.4522 - val_recon_loss: 0.1397\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1633 - kl_loss: 100.3304 - recon_loss: 0.1633 - val_loss: 0.1293 - val_kl_loss: 105.2069 - val_recon_loss: 0.1293\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1580 - kl_loss: 99.9651 - recon_loss: 0.1580 - val_loss: 0.1467 - val_kl_loss: 103.0977 - val_recon_loss: 0.1467\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1527 - kl_loss: 100.2263 - recon_loss: 0.1527 - val_loss: 0.2269 - val_kl_loss: 105.3130 - val_recon_loss: 0.2269\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1603 - kl_loss: 100.0338 - recon_loss: 0.1603 - val_loss: 0.1806 - val_kl_loss: 103.4753 - val_recon_loss: 0.1806\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1595 - kl_loss: 99.7008 - recon_loss: 0.1595 - val_loss: 0.1121 - val_kl_loss: 103.7787 - val_recon_loss: 0.1121\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1544 - kl_loss: 100.1240 - recon_loss: 0.1544 - val_loss: 0.1443 - val_kl_loss: 104.5073 - val_recon_loss: 0.1443\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1557 - kl_loss: 100.0029 - recon_loss: 0.1557 - val_loss: 0.1181 - val_kl_loss: 103.3142 - val_recon_loss: 0.1181\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1548 - kl_loss: 99.9175 - recon_loss: 0.1548 - val_loss: 0.1433 - val_kl_loss: 104.6694 - val_recon_loss: 0.1433\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1567 - kl_loss: 99.8702 - recon_loss: 0.1567 - val_loss: 0.1220 - val_kl_loss: 102.9901 - val_recon_loss: 0.1220\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1468 - kl_loss: 99.6680 - recon_loss: 0.1468 - val_loss: 0.2142 - val_kl_loss: 100.6066 - val_recon_loss: 0.2142\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1514 - kl_loss: 99.7993 - recon_loss: 0.1514 - val_loss: 0.2648 - val_kl_loss: 102.1710 - val_recon_loss: 0.2648\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1502 - kl_loss: 99.9554 - recon_loss: 0.1502 - val_loss: 0.1176 - val_kl_loss: 103.4377 - val_recon_loss: 0.1176\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1493 - kl_loss: 99.7935 - recon_loss: 0.1493 - val_loss: 0.1213 - val_kl_loss: 103.1589 - val_recon_loss: 0.1213\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1449 - kl_loss: 99.7029 - recon_loss: 0.1449 - val_loss: 0.5672 - val_kl_loss: 104.7711 - val_recon_loss: 0.5672\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1505 - kl_loss: 99.0078 - recon_loss: 0.1505 - val_loss: 0.1085 - val_kl_loss: 103.0546 - val_recon_loss: 0.1085\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1437 - kl_loss: 99.5631 - recon_loss: 0.1437 - val_loss: 0.1068 - val_kl_loss: 103.1531 - val_recon_loss: 0.1068\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1432 - kl_loss: 99.4068 - recon_loss: 0.1432 - val_loss: 0.1053 - val_kl_loss: 102.7400 - val_recon_loss: 0.1053\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1475 - kl_loss: 98.9175 - recon_loss: 0.1475 - val_loss: 0.1845 - val_kl_loss: 103.3686 - val_recon_loss: 0.1845\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1441 - kl_loss: 98.7754 - recon_loss: 0.1441 - val_loss: 0.2287 - val_kl_loss: 102.4852 - val_recon_loss: 0.2287\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1434 - kl_loss: 99.0646 - recon_loss: 0.1434 - val_loss: 0.1695 - val_kl_loss: 100.5624 - val_recon_loss: 0.1695\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1478 - kl_loss: 99.3079 - recon_loss: 0.1478 - val_loss: 0.1054 - val_kl_loss: 102.6364 - val_recon_loss: 0.1054\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.1370 - kl_loss: 99.2886 - recon_loss: 0.1370 - val_loss: 0.3257 - val_kl_loss: 101.9332 - val_recon_loss: 0.3257\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1412 - kl_loss: 99.1738 - recon_loss: 0.1412 - val_loss: 0.1396 - val_kl_loss: 102.9426 - val_recon_loss: 0.1396\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1417 - kl_loss: 99.5994 - recon_loss: 0.1417 - val_loss: 0.1350 - val_kl_loss: 102.7556 - val_recon_loss: 0.1350\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1356 - kl_loss: 99.7125 - recon_loss: 0.1356 - val_loss: 0.2233 - val_kl_loss: 105.7572 - val_recon_loss: 0.2233\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1408 - kl_loss: 100.1068 - recon_loss: 0.1408 - val_loss: 0.1106 - val_kl_loss: 103.1201 - val_recon_loss: 0.1106\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1376 - kl_loss: 100.4685 - recon_loss: 0.1376 - val_loss: 0.0941 - val_kl_loss: 104.0073 - val_recon_loss: 0.0941\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1280 - kl_loss: 100.5263 - recon_loss: 0.1280 - val_loss: 0.1693 - val_kl_loss: 105.0023 - val_recon_loss: 0.1693\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1397 - kl_loss: 100.5653 - recon_loss: 0.1397 - val_loss: 0.1106 - val_kl_loss: 103.2596 - val_recon_loss: 0.1106\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1370 - kl_loss: 100.4539 - recon_loss: 0.1370 - val_loss: 0.1065 - val_kl_loss: 104.1194 - val_recon_loss: 0.1065\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1273 - kl_loss: 100.7321 - recon_loss: 0.1273 - val_loss: 0.4220 - val_kl_loss: 102.1464 - val_recon_loss: 0.4220\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1350 - kl_loss: 100.5590 - recon_loss: 0.1350 - val_loss: 0.1446 - val_kl_loss: 103.9956 - val_recon_loss: 0.1446\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1299 - kl_loss: 100.4939 - recon_loss: 0.1299 - val_loss: 0.1192 - val_kl_loss: 102.1959 - val_recon_loss: 0.1192\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1338 - kl_loss: 100.5807 - recon_loss: 0.1338 - val_loss: 0.1014 - val_kl_loss: 104.0306 - val_recon_loss: 0.1014\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1269 - kl_loss: 101.0347 - recon_loss: 0.1269 - val_loss: 0.1585 - val_kl_loss: 103.3264 - val_recon_loss: 0.1585\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.1341 - kl_loss: 101.2301 - recon_loss: 0.1341 - val_loss: 0.1626 - val_kl_loss: 103.0729 - val_recon_loss: 0.1626\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1273 - kl_loss: 101.5702 - recon_loss: 0.1273 - val_loss: 0.2214 - val_kl_loss: 107.2730 - val_recon_loss: 0.2214\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1302 - kl_loss: 101.4627 - recon_loss: 0.1302 - val_loss: 0.1371 - val_kl_loss: 103.3533 - val_recon_loss: 0.1371\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1219 - kl_loss: 100.9140 - recon_loss: 0.1219 - val_loss: 0.1807 - val_kl_loss: 106.3951 - val_recon_loss: 0.1807\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1270 - kl_loss: 100.8631 - recon_loss: 0.1270 - val_loss: 0.1648 - val_kl_loss: 103.4053 - val_recon_loss: 0.1648\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1289 - kl_loss: 100.4814 - recon_loss: 0.1289 - val_loss: 0.0911 - val_kl_loss: 104.0817 - val_recon_loss: 0.0911\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1274 - kl_loss: 100.0698 - recon_loss: 0.1274 - val_loss: 0.3650 - val_kl_loss: 106.9227 - val_recon_loss: 0.3650\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1220 - kl_loss: 99.9554 - recon_loss: 0.1220 - val_loss: 0.1995 - val_kl_loss: 100.7094 - val_recon_loss: 0.1995\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1252 - kl_loss: 99.2742 - recon_loss: 0.1252 - val_loss: 0.0996 - val_kl_loss: 102.3401 - val_recon_loss: 0.0996\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1214 - kl_loss: 99.1770 - recon_loss: 0.1214 - val_loss: 0.1217 - val_kl_loss: 101.2403 - val_recon_loss: 0.1217\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1257 - kl_loss: 99.3335 - recon_loss: 0.1257 - val_loss: 0.1731 - val_kl_loss: 103.6541 - val_recon_loss: 0.1731\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1209 - kl_loss: 99.1526 - recon_loss: 0.1209 - val_loss: 0.1950 - val_kl_loss: 103.2946 - val_recon_loss: 0.1950\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1211 - kl_loss: 99.3816 - recon_loss: 0.1211 - val_loss: 0.1935 - val_kl_loss: 105.3921 - val_recon_loss: 0.1935\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1159 - kl_loss: 99.6103 - recon_loss: 0.1159 - val_loss: 0.1452 - val_kl_loss: 103.5226 - val_recon_loss: 0.1452\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1240 - kl_loss: 99.8511 - recon_loss: 0.1240 - val_loss: 0.2583 - val_kl_loss: 103.7742 - val_recon_loss: 0.2583\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1169 - kl_loss: 99.6251 - recon_loss: 0.1169 - val_loss: 0.4217 - val_kl_loss: 98.6655 - val_recon_loss: 0.4217\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1148 - kl_loss: 99.3371 - recon_loss: 0.1148 - val_loss: 0.1762 - val_kl_loss: 102.2749 - val_recon_loss: 0.1762\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1231 - kl_loss: 99.4141 - recon_loss: 0.1231 - val_loss: 0.1093 - val_kl_loss: 103.5935 - val_recon_loss: 0.1093\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1186 - kl_loss: 99.2910 - recon_loss: 0.1186 - val_loss: 0.1016 - val_kl_loss: 101.7260 - val_recon_loss: 0.1016\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1204 - kl_loss: 99.3996 - recon_loss: 0.1204 - val_loss: 0.1375 - val_kl_loss: 103.8925 - val_recon_loss: 0.1375\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1202 - kl_loss: 99.3855 - recon_loss: 0.1202 - val_loss: 0.0748 - val_kl_loss: 102.2527 - val_recon_loss: 0.0748\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1134 - kl_loss: 99.4930 - recon_loss: 0.1134 - val_loss: 0.0833 - val_kl_loss: 103.2314 - val_recon_loss: 0.0833\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1169 - kl_loss: 99.8357 - recon_loss: 0.1169 - val_loss: 0.0835 - val_kl_loss: 101.9714 - val_recon_loss: 0.0835\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 63us/step - loss: 0.1107 - kl_loss: 99.6098 - recon_loss: 0.1107 - val_loss: 0.0971 - val_kl_loss: 102.1186 - val_recon_loss: 0.0971\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1165 - kl_loss: 99.6636 - recon_loss: 0.1165 - val_loss: 0.0834 - val_kl_loss: 102.7666 - val_recon_loss: 0.0834\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1153 - kl_loss: 99.5140 - recon_loss: 0.1153 - val_loss: 0.1161 - val_kl_loss: 103.6025 - val_recon_loss: 0.1161\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1106 - kl_loss: 99.7524 - recon_loss: 0.1106 - val_loss: 0.2879 - val_kl_loss: 103.0576 - val_recon_loss: 0.2879\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 62us/step - loss: 0.1188 - kl_loss: 99.7158 - recon_loss: 0.1188 - val_loss: 0.1101 - val_kl_loss: 101.3113 - val_recon_loss: 0.1101\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1088 - kl_loss: 99.8190 - recon_loss: 0.1088 - val_loss: 0.1505 - val_kl_loss: 103.0616 - val_recon_loss: 0.1505\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1135 - kl_loss: 99.5047 - recon_loss: 0.1135 - val_loss: 0.0922 - val_kl_loss: 102.8848 - val_recon_loss: 0.0922\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1096 - kl_loss: 99.5755 - recon_loss: 0.1096 - val_loss: 0.2185 - val_kl_loss: 102.3165 - val_recon_loss: 0.2185\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1140 - kl_loss: 99.2505 - recon_loss: 0.1140 - val_loss: 0.1507 - val_kl_loss: 101.3859 - val_recon_loss: 0.1507\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1110 - kl_loss: 99.1421 - recon_loss: 0.1110 - val_loss: 0.0828 - val_kl_loss: 102.7428 - val_recon_loss: 0.0828\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1110 - kl_loss: 99.0583 - recon_loss: 0.1110 - val_loss: 0.1966 - val_kl_loss: 101.5829 - val_recon_loss: 0.1966\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1122 - kl_loss: 99.4944 - recon_loss: 0.1122 - val_loss: 0.0857 - val_kl_loss: 102.7184 - val_recon_loss: 0.0857\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1114 - kl_loss: 99.4188 - recon_loss: 0.1114 - val_loss: 0.0971 - val_kl_loss: 101.9337 - val_recon_loss: 0.0971\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1079 - kl_loss: 99.2251 - recon_loss: 0.1079 - val_loss: 0.0954 - val_kl_loss: 102.9284 - val_recon_loss: 0.0954\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1093 - kl_loss: 99.4964 - recon_loss: 0.1093 - val_loss: 0.0858 - val_kl_loss: 101.5797 - val_recon_loss: 0.0858\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1062 - kl_loss: 99.2158 - recon_loss: 0.1062 - val_loss: 0.4740 - val_kl_loss: 102.8562 - val_recon_loss: 0.4740\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.1092 - kl_loss: 99.5073 - recon_loss: 0.1092 - val_loss: 0.0851 - val_kl_loss: 102.6302 - val_recon_loss: 0.0851\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1147 - kl_loss: 99.7793 - recon_loss: 0.1147 - val_loss: 0.0751 - val_kl_loss: 103.0399 - val_recon_loss: 0.0751\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1049 - kl_loss: 100.4407 - recon_loss: 0.1049 - val_loss: 0.1139 - val_kl_loss: 102.2657 - val_recon_loss: 0.1139\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1110 - kl_loss: 100.4899 - recon_loss: 0.1110 - val_loss: 0.1357 - val_kl_loss: 102.9499 - val_recon_loss: 0.1357\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1086 - kl_loss: 100.4559 - recon_loss: 0.1086 - val_loss: 0.0869 - val_kl_loss: 103.5142 - val_recon_loss: 0.0869\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1070 - kl_loss: 100.0487 - recon_loss: 0.1070 - val_loss: 0.0947 - val_kl_loss: 103.4568 - val_recon_loss: 0.0947\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1080 - kl_loss: 100.1343 - recon_loss: 0.1080 - val_loss: 0.1112 - val_kl_loss: 102.0603 - val_recon_loss: 0.1112\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1063 - kl_loss: 99.9453 - recon_loss: 0.1063 - val_loss: 0.2799 - val_kl_loss: 103.5441 - val_recon_loss: 0.2799\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1075 - kl_loss: 100.2473 - recon_loss: 0.1075 - val_loss: 0.1508 - val_kl_loss: 101.3176 - val_recon_loss: 0.1508\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1087 - kl_loss: 99.7946 - recon_loss: 0.1087 - val_loss: 0.0869 - val_kl_loss: 102.5469 - val_recon_loss: 0.0869\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1053 - kl_loss: 99.5909 - recon_loss: 0.1053 - val_loss: 0.0922 - val_kl_loss: 102.3763 - val_recon_loss: 0.0922\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1051 - kl_loss: 99.9541 - recon_loss: 0.1051 - val_loss: 0.1596 - val_kl_loss: 102.9557 - val_recon_loss: 0.1596\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1079 - kl_loss: 100.1769 - recon_loss: 0.1079 - val_loss: 0.1221 - val_kl_loss: 104.7635 - val_recon_loss: 0.1221\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1019 - kl_loss: 100.2923 - recon_loss: 0.1019 - val_loss: 0.1935 - val_kl_loss: 101.1248 - val_recon_loss: 0.1935\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1080 - kl_loss: 100.3865 - recon_loss: 0.1080 - val_loss: 0.0920 - val_kl_loss: 104.3789 - val_recon_loss: 0.0920\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.1068 - kl_loss: 100.7560 - recon_loss: 0.1068 - val_loss: 0.1036 - val_kl_loss: 103.7454 - val_recon_loss: 0.1036\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1024 - kl_loss: 100.5141 - recon_loss: 0.1024 - val_loss: 0.0989 - val_kl_loss: 104.3701 - val_recon_loss: 0.0989\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1019 - kl_loss: 100.9988 - recon_loss: 0.1019 - val_loss: 0.0930 - val_kl_loss: 104.3373 - val_recon_loss: 0.0930\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1045 - kl_loss: 100.9138 - recon_loss: 0.1045 - val_loss: 0.0827 - val_kl_loss: 105.0601 - val_recon_loss: 0.0827\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1013 - kl_loss: 100.5737 - recon_loss: 0.1013 - val_loss: 0.1242 - val_kl_loss: 103.7710 - val_recon_loss: 0.1242\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0977 - kl_loss: 100.1894 - recon_loss: 0.0977 - val_loss: 0.0895 - val_kl_loss: 103.3614 - val_recon_loss: 0.0895\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1032 - kl_loss: 100.2500 - recon_loss: 0.1032 - val_loss: 0.0960 - val_kl_loss: 104.2195 - val_recon_loss: 0.0960\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1032 - kl_loss: 100.0501 - recon_loss: 0.1032 - val_loss: 0.0925 - val_kl_loss: 104.0545 - val_recon_loss: 0.0925\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1019 - kl_loss: 100.1095 - recon_loss: 0.1019 - val_loss: 0.0896 - val_kl_loss: 103.4388 - val_recon_loss: 0.0896\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0991 - kl_loss: 100.6672 - recon_loss: 0.0991 - val_loss: 0.0752 - val_kl_loss: 103.0868 - val_recon_loss: 0.0752\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1013 - kl_loss: 100.2122 - recon_loss: 0.1013 - val_loss: 0.0865 - val_kl_loss: 102.2675 - val_recon_loss: 0.0865\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0992 - kl_loss: 99.8206 - recon_loss: 0.0992 - val_loss: 0.1105 - val_kl_loss: 102.9393 - val_recon_loss: 0.1105\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.0999 - kl_loss: 99.4295 - recon_loss: 0.0999 - val_loss: 0.0809 - val_kl_loss: 102.0264 - val_recon_loss: 0.0809\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1023 - kl_loss: 99.7103 - recon_loss: 0.1023 - val_loss: 0.0670 - val_kl_loss: 102.9324 - val_recon_loss: 0.0670\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1034 - kl_loss: 99.8396 - recon_loss: 0.1034 - val_loss: 0.0827 - val_kl_loss: 103.6108 - val_recon_loss: 0.0827\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0983 - kl_loss: 99.9227 - recon_loss: 0.0983 - val_loss: 0.0710 - val_kl_loss: 103.1044 - val_recon_loss: 0.0710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0976 - kl_loss: 100.1393 - recon_loss: 0.0976 - val_loss: 0.0857 - val_kl_loss: 102.2528 - val_recon_loss: 0.0857\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0980 - kl_loss: 99.9452 - recon_loss: 0.0980 - val_loss: 0.1806 - val_kl_loss: 104.8274 - val_recon_loss: 0.1806\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1037 - kl_loss: 100.2428 - recon_loss: 0.1037 - val_loss: 0.1570 - val_kl_loss: 101.3676 - val_recon_loss: 0.1570\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.0974 - kl_loss: 100.1781 - recon_loss: 0.0974 - val_loss: 0.0746 - val_kl_loss: 103.4540 - val_recon_loss: 0.0746\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.0968 - kl_loss: 100.3130 - recon_loss: 0.0968 - val_loss: 0.2807 - val_kl_loss: 104.0611 - val_recon_loss: 0.2807\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0932 - kl_loss: 100.2847 - recon_loss: 0.0932 - val_loss: 0.0949 - val_kl_loss: 101.9232 - val_recon_loss: 0.0949\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1033 - kl_loss: 100.1152 - recon_loss: 0.1033 - val_loss: 0.0853 - val_kl_loss: 103.0236 - val_recon_loss: 0.0853\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0980 - kl_loss: 100.0540 - recon_loss: 0.0980 - val_loss: 0.0688 - val_kl_loss: 102.5152 - val_recon_loss: 0.0688\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0945 - kl_loss: 99.9040 - recon_loss: 0.0945 - val_loss: 0.0756 - val_kl_loss: 102.9323 - val_recon_loss: 0.0756\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1007 - kl_loss: 99.7660 - recon_loss: 0.1007 - val_loss: 0.1694 - val_kl_loss: 102.5947 - val_recon_loss: 0.1694\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0925 - kl_loss: 99.2901 - recon_loss: 0.0925 - val_loss: 0.1611 - val_kl_loss: 101.0038 - val_recon_loss: 0.1611\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0945 - kl_loss: 99.1768 - recon_loss: 0.0945 - val_loss: 0.0800 - val_kl_loss: 102.7984 - val_recon_loss: 0.0800\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1006 - kl_loss: 99.2599 - recon_loss: 0.1006 - val_loss: 0.1080 - val_kl_loss: 103.0780 - val_recon_loss: 0.1080\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0941 - kl_loss: 99.6452 - recon_loss: 0.0941 - val_loss: 0.2357 - val_kl_loss: 102.9360 - val_recon_loss: 0.2357\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.0999 - kl_loss: 99.5247 - recon_loss: 0.0999 - val_loss: 0.0692 - val_kl_loss: 102.4045 - val_recon_loss: 0.0692\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0905 - kl_loss: 99.7032 - recon_loss: 0.0905 - val_loss: 0.1627 - val_kl_loss: 101.9858 - val_recon_loss: 0.1627\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0983 - kl_loss: 99.7305 - recon_loss: 0.0983 - val_loss: 0.0848 - val_kl_loss: 102.2874 - val_recon_loss: 0.0848\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.0951 - kl_loss: 99.7272 - recon_loss: 0.0951 - val_loss: 0.1516 - val_kl_loss: 102.1409 - val_recon_loss: 0.1516\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0976 - kl_loss: 99.7729 - recon_loss: 0.0976 - val_loss: 0.0778 - val_kl_loss: 101.8853 - val_recon_loss: 0.0778\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.0979 - kl_loss: 99.5027 - recon_loss: 0.0979 - val_loss: 0.0626 - val_kl_loss: 102.1699 - val_recon_loss: 0.0626\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0918 - kl_loss: 100.1778 - recon_loss: 0.0918 - val_loss: 0.0845 - val_kl_loss: 103.3807 - val_recon_loss: 0.0845\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0932 - kl_loss: 100.0913 - recon_loss: 0.0932 - val_loss: 0.0660 - val_kl_loss: 102.7193 - val_recon_loss: 0.0660\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0944 - kl_loss: 100.1055 - recon_loss: 0.0944 - val_loss: 0.0605 - val_kl_loss: 102.8690 - val_recon_loss: 0.0605\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0931 - kl_loss: 100.1318 - recon_loss: 0.0931 - val_loss: 0.0680 - val_kl_loss: 103.7070 - val_recon_loss: 0.0680\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0952 - kl_loss: 100.2121 - recon_loss: 0.0952 - val_loss: 0.0646 - val_kl_loss: 103.0365 - val_recon_loss: 0.0646\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0915 - kl_loss: 99.9856 - recon_loss: 0.0915 - val_loss: 0.1997 - val_kl_loss: 101.6689 - val_recon_loss: 0.1997\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.0888 - kl_loss: 99.9795 - recon_loss: 0.0888 - val_loss: 0.0986 - val_kl_loss: 102.4457 - val_recon_loss: 0.0986\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0940 - kl_loss: 100.3129 - recon_loss: 0.0940 - val_loss: 0.0780 - val_kl_loss: 103.1169 - val_recon_loss: 0.0780\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0919 - kl_loss: 100.2861 - recon_loss: 0.0919 - val_loss: 0.1142 - val_kl_loss: 103.9101 - val_recon_loss: 0.1142\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0940 - kl_loss: 100.7478 - recon_loss: 0.0940 - val_loss: 0.1582 - val_kl_loss: 101.6626 - val_recon_loss: 0.1582\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0927 - kl_loss: 100.4639 - recon_loss: 0.0927 - val_loss: 0.0701 - val_kl_loss: 102.4062 - val_recon_loss: 0.0701\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0935 - kl_loss: 100.5573 - recon_loss: 0.0935 - val_loss: 0.1023 - val_kl_loss: 103.6658 - val_recon_loss: 0.1023\n",
      "========================= Model7=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 7), (None, 7 2042        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 7)            0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1800        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,940\n",
      "Trainable params: 3,940\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 7)            91          enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 7)            91          enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,042\n",
      "Trainable params: 2,042\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 23)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           288         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,800\n",
      "Trainable params: 1,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 126us/step - loss: 34.1140 - kl_loss: 14.0429 - recon_loss: 34.1140 - val_loss: 15.5431 - val_kl_loss: 37.0860 - val_recon_loss: 15.5431\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 6.3653 - kl_loss: 40.7997 - recon_loss: 6.3653 - val_loss: 3.4257 - val_kl_loss: 58.0404 - val_recon_loss: 3.4257\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 2.8178 - kl_loss: 51.9276 - recon_loss: 2.8178 - val_loss: 2.4648 - val_kl_loss: 64.7634 - val_recon_loss: 2.4648\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 1.9876 - kl_loss: 59.6445 - recon_loss: 1.9876 - val_loss: 1.5655 - val_kl_loss: 71.8127 - val_recon_loss: 1.5655\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 1.2899 - kl_loss: 66.0232 - recon_loss: 1.2899 - val_loss: 1.0786 - val_kl_loss: 78.2442 - val_recon_loss: 1.0786\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.9550 - kl_loss: 70.7905 - recon_loss: 0.9550 - val_loss: 0.9540 - val_kl_loss: 81.4181 - val_recon_loss: 0.9540\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.8080 - kl_loss: 74.3670 - recon_loss: 0.8080 - val_loss: 0.7407 - val_kl_loss: 86.2760 - val_recon_loss: 0.7407\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.7022 - kl_loss: 77.3140 - recon_loss: 0.7022 - val_loss: 0.7664 - val_kl_loss: 88.0635 - val_recon_loss: 0.7664\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.6315 - kl_loss: 80.1950 - recon_loss: 0.6315 - val_loss: 0.6619 - val_kl_loss: 91.4258 - val_recon_loss: 0.6619\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.5810 - kl_loss: 82.0752 - recon_loss: 0.5810 - val_loss: 0.5355 - val_kl_loss: 93.2641 - val_recon_loss: 0.5355\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.5236 - kl_loss: 84.0970 - recon_loss: 0.5236 - val_loss: 0.5475 - val_kl_loss: 96.0274 - val_recon_loss: 0.5475\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.4776 - kl_loss: 85.6042 - recon_loss: 0.4776 - val_loss: 0.7753 - val_kl_loss: 98.4152 - val_recon_loss: 0.7753\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.4505 - kl_loss: 86.9140 - recon_loss: 0.4505 - val_loss: 0.5195 - val_kl_loss: 94.9784 - val_recon_loss: 0.5195\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.4121 - kl_loss: 87.6619 - recon_loss: 0.4121 - val_loss: 0.3909 - val_kl_loss: 97.7344 - val_recon_loss: 0.3909\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3852 - kl_loss: 88.2184 - recon_loss: 0.3852 - val_loss: 0.5422 - val_kl_loss: 96.7810 - val_recon_loss: 0.5422\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3695 - kl_loss: 89.0956 - recon_loss: 0.3695 - val_loss: 0.4854 - val_kl_loss: 96.9648 - val_recon_loss: 0.4854\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.3546 - kl_loss: 89.1830 - recon_loss: 0.3546 - val_loss: 0.5487 - val_kl_loss: 97.2237 - val_recon_loss: 0.5487\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.3448 - kl_loss: 89.6373 - recon_loss: 0.3448 - val_loss: 0.3659 - val_kl_loss: 99.2670 - val_recon_loss: 0.3659\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.3292 - kl_loss: 89.4255 - recon_loss: 0.3292 - val_loss: 0.3081 - val_kl_loss: 97.7466 - val_recon_loss: 0.3081\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3204 - kl_loss: 89.5972 - recon_loss: 0.3204 - val_loss: 0.7704 - val_kl_loss: 99.4648 - val_recon_loss: 0.7704\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3073 - kl_loss: 89.6056 - recon_loss: 0.3073 - val_loss: 0.2862 - val_kl_loss: 100.0289 - val_recon_loss: 0.2862\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2989 - kl_loss: 90.0463 - recon_loss: 0.2989 - val_loss: 0.3112 - val_kl_loss: 99.1589 - val_recon_loss: 0.3112\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2918 - kl_loss: 90.0678 - recon_loss: 0.2918 - val_loss: 0.3060 - val_kl_loss: 99.2078 - val_recon_loss: 0.3060\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2800 - kl_loss: 90.6252 - recon_loss: 0.2800 - val_loss: 0.2983 - val_kl_loss: 99.3037 - val_recon_loss: 0.2983\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2746 - kl_loss: 90.6752 - recon_loss: 0.2746 - val_loss: 0.3772 - val_kl_loss: 97.2964 - val_recon_loss: 0.3772\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2711 - kl_loss: 90.4308 - recon_loss: 0.2711 - val_loss: 0.2676 - val_kl_loss: 96.8671 - val_recon_loss: 0.2676\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.2625 - kl_loss: 90.4071 - recon_loss: 0.2625 - val_loss: 0.2309 - val_kl_loss: 97.9635 - val_recon_loss: 0.2309\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2526 - kl_loss: 90.2622 - recon_loss: 0.2526 - val_loss: 0.3708 - val_kl_loss: 97.5197 - val_recon_loss: 0.3708\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.2532 - kl_loss: 90.1989 - recon_loss: 0.2532 - val_loss: 0.2409 - val_kl_loss: 96.7061 - val_recon_loss: 0.2409\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2458 - kl_loss: 89.8199 - recon_loss: 0.2458 - val_loss: 0.5470 - val_kl_loss: 97.4815 - val_recon_loss: 0.5470\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2423 - kl_loss: 89.8568 - recon_loss: 0.2423 - val_loss: 0.2604 - val_kl_loss: 97.5405 - val_recon_loss: 0.2604\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2333 - kl_loss: 89.7318 - recon_loss: 0.2333 - val_loss: 0.4390 - val_kl_loss: 95.2822 - val_recon_loss: 0.4390\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2364 - kl_loss: 89.4708 - recon_loss: 0.2364 - val_loss: 0.2408 - val_kl_loss: 97.3088 - val_recon_loss: 0.2408\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2305 - kl_loss: 89.9381 - recon_loss: 0.2305 - val_loss: 0.2697 - val_kl_loss: 96.5886 - val_recon_loss: 0.2697\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2247 - kl_loss: 89.8848 - recon_loss: 0.2247 - val_loss: 0.3046 - val_kl_loss: 97.7350 - val_recon_loss: 0.3046\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2244 - kl_loss: 89.5879 - recon_loss: 0.2244 - val_loss: 0.2090 - val_kl_loss: 96.3126 - val_recon_loss: 0.2090\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.2145 - kl_loss: 89.7028 - recon_loss: 0.2145 - val_loss: 0.1872 - val_kl_loss: 96.9029 - val_recon_loss: 0.1872\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2115 - kl_loss: 89.7980 - recon_loss: 0.2115 - val_loss: 0.2205 - val_kl_loss: 97.9790 - val_recon_loss: 0.2205\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.2084 - kl_loss: 89.8550 - recon_loss: 0.2084 - val_loss: 0.2265 - val_kl_loss: 96.5861 - val_recon_loss: 0.2265\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2072 - kl_loss: 89.6712 - recon_loss: 0.2072 - val_loss: 0.2112 - val_kl_loss: 96.8983 - val_recon_loss: 0.2112\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1995 - kl_loss: 89.7791 - recon_loss: 0.1995 - val_loss: 0.4106 - val_kl_loss: 97.7845 - val_recon_loss: 0.4106\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2012 - kl_loss: 89.4838 - recon_loss: 0.2012 - val_loss: 0.3465 - val_kl_loss: 97.4924 - val_recon_loss: 0.3465\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1977 - kl_loss: 89.3607 - recon_loss: 0.1977 - val_loss: 0.3428 - val_kl_loss: 94.5502 - val_recon_loss: 0.3428\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1930 - kl_loss: 89.3806 - recon_loss: 0.1930 - val_loss: 0.2709 - val_kl_loss: 97.4078 - val_recon_loss: 0.2709\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1856 - kl_loss: 89.4257 - recon_loss: 0.1856 - val_loss: 0.2428 - val_kl_loss: 96.8204 - val_recon_loss: 0.2428\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1906 - kl_loss: 89.6627 - recon_loss: 0.1906 - val_loss: 0.3303 - val_kl_loss: 94.1256 - val_recon_loss: 0.3303\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1862 - kl_loss: 89.7536 - recon_loss: 0.1862 - val_loss: 0.1978 - val_kl_loss: 96.3070 - val_recon_loss: 0.1978\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1867 - kl_loss: 90.1254 - recon_loss: 0.1867 - val_loss: 0.1783 - val_kl_loss: 95.7981 - val_recon_loss: 0.1783\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1822 - kl_loss: 90.2278 - recon_loss: 0.1822 - val_loss: 0.1722 - val_kl_loss: 96.5162 - val_recon_loss: 0.1722\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1838 - kl_loss: 90.1633 - recon_loss: 0.1838 - val_loss: 0.1512 - val_kl_loss: 96.8037 - val_recon_loss: 0.1512\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1792 - kl_loss: 89.9745 - recon_loss: 0.1792 - val_loss: 0.1369 - val_kl_loss: 95.9838 - val_recon_loss: 0.1369\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1750 - kl_loss: 89.9092 - recon_loss: 0.1750 - val_loss: 0.2347 - val_kl_loss: 95.1911 - val_recon_loss: 0.2347\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1673 - kl_loss: 89.9501 - recon_loss: 0.1673 - val_loss: 0.2495 - val_kl_loss: 96.1556 - val_recon_loss: 0.2495\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1728 - kl_loss: 89.8249 - recon_loss: 0.1728 - val_loss: 0.2757 - val_kl_loss: 96.4135 - val_recon_loss: 0.2757\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 86us/step - loss: 0.1725 - kl_loss: 90.0556 - recon_loss: 0.1725 - val_loss: 0.1725 - val_kl_loss: 96.5799 - val_recon_loss: 0.1725\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1642 - kl_loss: 90.1797 - recon_loss: 0.1642 - val_loss: 0.1384 - val_kl_loss: 96.3377 - val_recon_loss: 0.1384\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1644 - kl_loss: 90.2992 - recon_loss: 0.1644 - val_loss: 0.2368 - val_kl_loss: 95.6161 - val_recon_loss: 0.2368\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1692 - kl_loss: 90.0919 - recon_loss: 0.1692 - val_loss: 0.2320 - val_kl_loss: 94.6074 - val_recon_loss: 0.2320\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1667 - kl_loss: 90.0150 - recon_loss: 0.1667 - val_loss: 0.1535 - val_kl_loss: 95.9191 - val_recon_loss: 0.1535\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1639 - kl_loss: 90.1634 - recon_loss: 0.1639 - val_loss: 0.1285 - val_kl_loss: 96.0592 - val_recon_loss: 0.1285\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1614 - kl_loss: 90.0632 - recon_loss: 0.1614 - val_loss: 0.1336 - val_kl_loss: 94.9949 - val_recon_loss: 0.1336\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1619 - kl_loss: 89.9249 - recon_loss: 0.1619 - val_loss: 0.2521 - val_kl_loss: 94.4779 - val_recon_loss: 0.2521\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1586 - kl_loss: 89.6899 - recon_loss: 0.1586 - val_loss: 0.3238 - val_kl_loss: 96.9121 - val_recon_loss: 0.3238\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1509 - kl_loss: 90.0740 - recon_loss: 0.1509 - val_loss: 0.1349 - val_kl_loss: 95.8083 - val_recon_loss: 0.1349\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1564 - kl_loss: 90.1780 - recon_loss: 0.1564 - val_loss: 0.2704 - val_kl_loss: 96.6759 - val_recon_loss: 0.2704\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1555 - kl_loss: 90.4363 - recon_loss: 0.1555 - val_loss: 0.1781 - val_kl_loss: 96.7375 - val_recon_loss: 0.1781\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1558 - kl_loss: 90.4460 - recon_loss: 0.1558 - val_loss: 0.1256 - val_kl_loss: 95.6093 - val_recon_loss: 0.1256\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1452 - kl_loss: 89.9895 - recon_loss: 0.1452 - val_loss: 0.3058 - val_kl_loss: 95.8226 - val_recon_loss: 0.3058\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1548 - kl_loss: 89.9680 - recon_loss: 0.1548 - val_loss: 0.1431 - val_kl_loss: 94.9551 - val_recon_loss: 0.1431\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1458 - kl_loss: 89.6936 - recon_loss: 0.1458 - val_loss: 0.1616 - val_kl_loss: 95.4316 - val_recon_loss: 0.1616\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1457 - kl_loss: 89.6349 - recon_loss: 0.1457 - val_loss: 0.1223 - val_kl_loss: 94.3378 - val_recon_loss: 0.1223\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1464 - kl_loss: 89.4846 - recon_loss: 0.1464 - val_loss: 0.1516 - val_kl_loss: 95.0214 - val_recon_loss: 0.1516\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1441 - kl_loss: 89.3011 - recon_loss: 0.1441 - val_loss: 0.2750 - val_kl_loss: 93.9014 - val_recon_loss: 0.2750\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.1449 - kl_loss: 89.1450 - recon_loss: 0.1449 - val_loss: 0.3181 - val_kl_loss: 93.3130 - val_recon_loss: 0.3181\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1435 - kl_loss: 89.1644 - recon_loss: 0.1435 - val_loss: 0.1229 - val_kl_loss: 94.7868 - val_recon_loss: 0.1229\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1436 - kl_loss: 89.4288 - recon_loss: 0.1436 - val_loss: 0.1728 - val_kl_loss: 92.9166 - val_recon_loss: 0.1728\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1425 - kl_loss: 89.3007 - recon_loss: 0.1425 - val_loss: 0.1407 - val_kl_loss: 94.7938 - val_recon_loss: 0.1407\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1389 - kl_loss: 89.5267 - recon_loss: 0.1389 - val_loss: 0.1269 - val_kl_loss: 93.9114 - val_recon_loss: 0.1269\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1379 - kl_loss: 89.6313 - recon_loss: 0.1379 - val_loss: 0.1940 - val_kl_loss: 95.8153 - val_recon_loss: 0.1940\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1425 - kl_loss: 90.1048 - recon_loss: 0.1425 - val_loss: 0.1072 - val_kl_loss: 94.7730 - val_recon_loss: 0.1072\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1344 - kl_loss: 90.1157 - recon_loss: 0.1344 - val_loss: 0.1036 - val_kl_loss: 95.2222 - val_recon_loss: 0.1036\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1336 - kl_loss: 90.0291 - recon_loss: 0.1336 - val_loss: 0.1883 - val_kl_loss: 95.5808 - val_recon_loss: 0.1883\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1364 - kl_loss: 90.1559 - recon_loss: 0.1364 - val_loss: 0.1891 - val_kl_loss: 95.8850 - val_recon_loss: 0.1891\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1339 - kl_loss: 90.0855 - recon_loss: 0.1339 - val_loss: 0.2618 - val_kl_loss: 96.5667 - val_recon_loss: 0.2618\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1319 - kl_loss: 90.1146 - recon_loss: 0.1319 - val_loss: 0.4085 - val_kl_loss: 93.7115 - val_recon_loss: 0.4085\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1393 - kl_loss: 90.0716 - recon_loss: 0.1393 - val_loss: 0.1997 - val_kl_loss: 95.5561 - val_recon_loss: 0.1997\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 100us/step - loss: 0.1271 - kl_loss: 90.2519 - recon_loss: 0.1271 - val_loss: 0.1774 - val_kl_loss: 93.0294 - val_recon_loss: 0.1774\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1311 - kl_loss: 90.3110 - recon_loss: 0.1311 - val_loss: 0.1067 - val_kl_loss: 95.0835 - val_recon_loss: 0.1067\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1269 - kl_loss: 90.5849 - recon_loss: 0.1269 - val_loss: 0.1202 - val_kl_loss: 96.1001 - val_recon_loss: 0.1202\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1276 - kl_loss: 90.6573 - recon_loss: 0.1276 - val_loss: 0.1632 - val_kl_loss: 95.7745 - val_recon_loss: 0.1632\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1271 - kl_loss: 90.4747 - recon_loss: 0.1271 - val_loss: 0.3392 - val_kl_loss: 95.4954 - val_recon_loss: 0.3392\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1255 - kl_loss: 90.5818 - recon_loss: 0.1255 - val_loss: 0.1001 - val_kl_loss: 95.5547 - val_recon_loss: 0.1001\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1292 - kl_loss: 90.9598 - recon_loss: 0.1292 - val_loss: 0.1492 - val_kl_loss: 94.6026 - val_recon_loss: 0.1492\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1217 - kl_loss: 91.2081 - recon_loss: 0.1217 - val_loss: 0.1753 - val_kl_loss: 96.2862 - val_recon_loss: 0.1753\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1240 - kl_loss: 91.3874 - recon_loss: 0.1240 - val_loss: 0.1661 - val_kl_loss: 96.3018 - val_recon_loss: 0.1661\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1230 - kl_loss: 91.1872 - recon_loss: 0.1230 - val_loss: 0.1704 - val_kl_loss: 95.7874 - val_recon_loss: 0.1704\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1210 - kl_loss: 91.2211 - recon_loss: 0.1210 - val_loss: 0.1253 - val_kl_loss: 96.2749 - val_recon_loss: 0.1253\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1190 - kl_loss: 91.2912 - recon_loss: 0.1190 - val_loss: 0.1699 - val_kl_loss: 96.3411 - val_recon_loss: 0.1699\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1239 - kl_loss: 91.3889 - recon_loss: 0.1239 - val_loss: 0.1297 - val_kl_loss: 97.1062 - val_recon_loss: 0.1297\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1174 - kl_loss: 91.6577 - recon_loss: 0.1174 - val_loss: 0.3622 - val_kl_loss: 97.6271 - val_recon_loss: 0.3622\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1201 - kl_loss: 91.5756 - recon_loss: 0.1201 - val_loss: 0.1252 - val_kl_loss: 95.3490 - val_recon_loss: 0.1252\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1197 - kl_loss: 91.5100 - recon_loss: 0.1197 - val_loss: 0.1250 - val_kl_loss: 95.9155 - val_recon_loss: 0.1250\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1192 - kl_loss: 91.4757 - recon_loss: 0.1192 - val_loss: 0.1702 - val_kl_loss: 95.9420 - val_recon_loss: 0.1702\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1156 - kl_loss: 91.6921 - recon_loss: 0.1156 - val_loss: 0.2524 - val_kl_loss: 97.9122 - val_recon_loss: 0.2524\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1158 - kl_loss: 91.9323 - recon_loss: 0.1158 - val_loss: 0.1536 - val_kl_loss: 95.6844 - val_recon_loss: 0.1536\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1140 - kl_loss: 92.3171 - recon_loss: 0.1140 - val_loss: 0.1323 - val_kl_loss: 97.5769 - val_recon_loss: 0.1323\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1137 - kl_loss: 92.3356 - recon_loss: 0.1137 - val_loss: 0.1559 - val_kl_loss: 97.3930 - val_recon_loss: 0.1559\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1135 - kl_loss: 92.3740 - recon_loss: 0.1135 - val_loss: 0.1046 - val_kl_loss: 97.2446 - val_recon_loss: 0.1046\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.1152 - kl_loss: 92.2719 - recon_loss: 0.1152 - val_loss: 0.1019 - val_kl_loss: 96.6002 - val_recon_loss: 0.1019\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1103 - kl_loss: 92.2021 - recon_loss: 0.1103 - val_loss: 0.0887 - val_kl_loss: 97.0294 - val_recon_loss: 0.0887\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1129 - kl_loss: 92.0809 - recon_loss: 0.1129 - val_loss: 0.2777 - val_kl_loss: 95.3210 - val_recon_loss: 0.2777\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1115 - kl_loss: 91.9258 - recon_loss: 0.1115 - val_loss: 0.0872 - val_kl_loss: 96.5298 - val_recon_loss: 0.0872\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1077 - kl_loss: 92.1584 - recon_loss: 0.1077 - val_loss: 0.0865 - val_kl_loss: 96.5317 - val_recon_loss: 0.0865\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1114 - kl_loss: 92.0865 - recon_loss: 0.1114 - val_loss: 0.1486 - val_kl_loss: 96.5963 - val_recon_loss: 0.1486\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1106 - kl_loss: 92.4841 - recon_loss: 0.1106 - val_loss: 0.1844 - val_kl_loss: 97.0707 - val_recon_loss: 0.1844\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1117 - kl_loss: 92.5170 - recon_loss: 0.1117 - val_loss: 0.1299 - val_kl_loss: 96.3292 - val_recon_loss: 0.1299\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1066 - kl_loss: 92.7544 - recon_loss: 0.1066 - val_loss: 0.0816 - val_kl_loss: 97.2083 - val_recon_loss: 0.0816\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1111 - kl_loss: 92.9269 - recon_loss: 0.1111 - val_loss: 0.1256 - val_kl_loss: 97.4535 - val_recon_loss: 0.1256\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1063 - kl_loss: 92.8828 - recon_loss: 0.1063 - val_loss: 0.0899 - val_kl_loss: 97.0192 - val_recon_loss: 0.0899\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1102 - kl_loss: 92.9258 - recon_loss: 0.1102 - val_loss: 0.0716 - val_kl_loss: 97.8455 - val_recon_loss: 0.0716\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1069 - kl_loss: 93.4691 - recon_loss: 0.1069 - val_loss: 0.1459 - val_kl_loss: 97.1360 - val_recon_loss: 0.1459\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1065 - kl_loss: 93.5639 - recon_loss: 0.1065 - val_loss: 0.2607 - val_kl_loss: 97.7349 - val_recon_loss: 0.2607\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1065 - kl_loss: 93.7186 - recon_loss: 0.1065 - val_loss: 0.2375 - val_kl_loss: 96.3908 - val_recon_loss: 0.2375\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1075 - kl_loss: 93.8440 - recon_loss: 0.1075 - val_loss: 0.1027 - val_kl_loss: 97.5856 - val_recon_loss: 0.1027\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1064 - kl_loss: 93.7980 - recon_loss: 0.1064 - val_loss: 0.1223 - val_kl_loss: 98.7935 - val_recon_loss: 0.1223\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1090 - kl_loss: 93.4853 - recon_loss: 0.1090 - val_loss: 0.1397 - val_kl_loss: 98.1751 - val_recon_loss: 0.1397\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1020 - kl_loss: 93.4673 - recon_loss: 0.1020 - val_loss: 0.1803 - val_kl_loss: 97.7271 - val_recon_loss: 0.1803\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1060 - kl_loss: 93.7972 - recon_loss: 0.1060 - val_loss: 0.0754 - val_kl_loss: 98.5502 - val_recon_loss: 0.0754\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1062 - kl_loss: 94.0289 - recon_loss: 0.1062 - val_loss: 0.3237 - val_kl_loss: 98.1166 - val_recon_loss: 0.3237\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1035 - kl_loss: 93.9041 - recon_loss: 0.1035 - val_loss: 0.3626 - val_kl_loss: 96.1761 - val_recon_loss: 0.3626\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1013 - kl_loss: 93.9128 - recon_loss: 0.1013 - val_loss: 0.1771 - val_kl_loss: 100.3248 - val_recon_loss: 0.1771\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1047 - kl_loss: 94.1487 - recon_loss: 0.1047 - val_loss: 0.1091 - val_kl_loss: 97.8870 - val_recon_loss: 0.1091\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1048 - kl_loss: 94.2405 - recon_loss: 0.1048 - val_loss: 0.1424 - val_kl_loss: 97.5035 - val_recon_loss: 0.1424\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1021 - kl_loss: 94.3984 - recon_loss: 0.1021 - val_loss: 0.1838 - val_kl_loss: 97.7529 - val_recon_loss: 0.1838\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1018 - kl_loss: 94.5102 - recon_loss: 0.1018 - val_loss: 0.1857 - val_kl_loss: 99.8086 - val_recon_loss: 0.1857\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1018 - kl_loss: 94.6197 - recon_loss: 0.1018 - val_loss: 0.0704 - val_kl_loss: 99.0723 - val_recon_loss: 0.0704\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1027 - kl_loss: 94.8197 - recon_loss: 0.1027 - val_loss: 0.0831 - val_kl_loss: 99.1760 - val_recon_loss: 0.0831\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 60us/step - loss: 0.0961 - kl_loss: 94.9236 - recon_loss: 0.0961 - val_loss: 0.0917 - val_kl_loss: 99.7095 - val_recon_loss: 0.0917\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 60us/step - loss: 0.1019 - kl_loss: 94.9912 - recon_loss: 0.1019 - val_loss: 0.0908 - val_kl_loss: 99.4639 - val_recon_loss: 0.0908\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 62us/step - loss: 0.0996 - kl_loss: 94.6384 - recon_loss: 0.0996 - val_loss: 0.1122 - val_kl_loss: 97.7829 - val_recon_loss: 0.1122\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1034 - kl_loss: 94.4263 - recon_loss: 0.1034 - val_loss: 0.0832 - val_kl_loss: 98.3670 - val_recon_loss: 0.0832\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 63us/step - loss: 0.0977 - kl_loss: 94.6106 - recon_loss: 0.0977 - val_loss: 0.0745 - val_kl_loss: 98.3969 - val_recon_loss: 0.0745\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 61us/step - loss: 0.1018 - kl_loss: 94.6449 - recon_loss: 0.1018 - val_loss: 0.0777 - val_kl_loss: 98.9129 - val_recon_loss: 0.0777\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.0979 - kl_loss: 94.6160 - recon_loss: 0.0979 - val_loss: 0.0829 - val_kl_loss: 99.5574 - val_recon_loss: 0.0829\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.0953 - kl_loss: 94.7210 - recon_loss: 0.0953 - val_loss: 0.1723 - val_kl_loss: 99.4618 - val_recon_loss: 0.1723\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1012 - kl_loss: 94.4653 - recon_loss: 0.1012 - val_loss: 0.1342 - val_kl_loss: 98.6524 - val_recon_loss: 0.1342\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.0994 - kl_loss: 94.4800 - recon_loss: 0.0994 - val_loss: 0.0834 - val_kl_loss: 98.6697 - val_recon_loss: 0.0834\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0996 - kl_loss: 94.5677 - recon_loss: 0.0996 - val_loss: 0.1341 - val_kl_loss: 99.4641 - val_recon_loss: 0.1341\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0954 - kl_loss: 94.6784 - recon_loss: 0.0954 - val_loss: 0.1352 - val_kl_loss: 99.9442 - val_recon_loss: 0.1352\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1005 - kl_loss: 94.8712 - recon_loss: 0.1005 - val_loss: 0.0652 - val_kl_loss: 99.1753 - val_recon_loss: 0.0652\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0974 - kl_loss: 95.0751 - recon_loss: 0.0974 - val_loss: 0.0794 - val_kl_loss: 98.2467 - val_recon_loss: 0.0794\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0982 - kl_loss: 95.0738 - recon_loss: 0.0982 - val_loss: 0.0753 - val_kl_loss: 98.7359 - val_recon_loss: 0.0753\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.0931 - kl_loss: 94.8416 - recon_loss: 0.0931 - val_loss: 0.0914 - val_kl_loss: 98.8109 - val_recon_loss: 0.0914\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0980 - kl_loss: 95.2231 - recon_loss: 0.0980 - val_loss: 0.2032 - val_kl_loss: 101.3808 - val_recon_loss: 0.2032\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0949 - kl_loss: 95.3729 - recon_loss: 0.0949 - val_loss: 0.0730 - val_kl_loss: 99.4583 - val_recon_loss: 0.0730\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0940 - kl_loss: 95.3139 - recon_loss: 0.0940 - val_loss: 0.0753 - val_kl_loss: 99.1594 - val_recon_loss: 0.0753\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0963 - kl_loss: 95.5696 - recon_loss: 0.0963 - val_loss: 0.1142 - val_kl_loss: 98.7494 - val_recon_loss: 0.1142\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0931 - kl_loss: 95.7529 - recon_loss: 0.0931 - val_loss: 0.0802 - val_kl_loss: 99.3470 - val_recon_loss: 0.0802\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0949 - kl_loss: 95.7970 - recon_loss: 0.0949 - val_loss: 0.1375 - val_kl_loss: 98.5140 - val_recon_loss: 0.1375\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0923 - kl_loss: 95.8176 - recon_loss: 0.0923 - val_loss: 0.1191 - val_kl_loss: 100.3954 - val_recon_loss: 0.1191\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.0957 - kl_loss: 95.8473 - recon_loss: 0.0957 - val_loss: 0.0653 - val_kl_loss: 99.7738 - val_recon_loss: 0.0653\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0983 - kl_loss: 95.7626 - recon_loss: 0.0983 - val_loss: 0.2243 - val_kl_loss: 98.4260 - val_recon_loss: 0.2243\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0947 - kl_loss: 95.9460 - recon_loss: 0.0947 - val_loss: 0.0874 - val_kl_loss: 100.2663 - val_recon_loss: 0.0874\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0920 - kl_loss: 96.0713 - recon_loss: 0.0920 - val_loss: 0.1074 - val_kl_loss: 99.2540 - val_recon_loss: 0.1074\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0952 - kl_loss: 96.0426 - recon_loss: 0.0952 - val_loss: 0.1004 - val_kl_loss: 99.3771 - val_recon_loss: 0.1004\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0974 - kl_loss: 95.8705 - recon_loss: 0.0974 - val_loss: 0.0694 - val_kl_loss: 99.4642 - val_recon_loss: 0.0694\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0909 - kl_loss: 95.7726 - recon_loss: 0.0909 - val_loss: 0.2071 - val_kl_loss: 98.4776 - val_recon_loss: 0.2071\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0924 - kl_loss: 95.8632 - recon_loss: 0.0924 - val_loss: 0.1252 - val_kl_loss: 101.0686 - val_recon_loss: 0.1252\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0907 - kl_loss: 95.8303 - recon_loss: 0.0907 - val_loss: 0.1191 - val_kl_loss: 99.9562 - val_recon_loss: 0.1191\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0957 - kl_loss: 95.9598 - recon_loss: 0.0957 - val_loss: 0.2185 - val_kl_loss: 101.9173 - val_recon_loss: 0.2185\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0922 - kl_loss: 95.9263 - recon_loss: 0.0922 - val_loss: 0.1417 - val_kl_loss: 101.5438 - val_recon_loss: 0.1417\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0971 - kl_loss: 95.8253 - recon_loss: 0.0971 - val_loss: 0.0918 - val_kl_loss: 100.0686 - val_recon_loss: 0.0918\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.0886 - kl_loss: 95.7365 - recon_loss: 0.0886 - val_loss: 0.0788 - val_kl_loss: 98.8960 - val_recon_loss: 0.0788\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0942 - kl_loss: 95.9349 - recon_loss: 0.0942 - val_loss: 0.0658 - val_kl_loss: 100.4474 - val_recon_loss: 0.0658\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0904 - kl_loss: 95.8897 - recon_loss: 0.0904 - val_loss: 0.0717 - val_kl_loss: 99.4653 - val_recon_loss: 0.0717\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0924 - kl_loss: 95.7005 - recon_loss: 0.0924 - val_loss: 0.1470 - val_kl_loss: 101.1959 - val_recon_loss: 0.1470\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0919 - kl_loss: 96.3922 - recon_loss: 0.0919 - val_loss: 0.0727 - val_kl_loss: 100.0414 - val_recon_loss: 0.0727\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0929 - kl_loss: 96.1718 - recon_loss: 0.0929 - val_loss: 0.0871 - val_kl_loss: 100.9791 - val_recon_loss: 0.0871\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.0892 - kl_loss: 96.2982 - recon_loss: 0.0892 - val_loss: 0.0939 - val_kl_loss: 100.3941 - val_recon_loss: 0.0939\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0895 - kl_loss: 96.2839 - recon_loss: 0.0895 - val_loss: 0.1810 - val_kl_loss: 99.0331 - val_recon_loss: 0.1810\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0894 - kl_loss: 96.2736 - recon_loss: 0.0894 - val_loss: 0.1192 - val_kl_loss: 98.7853 - val_recon_loss: 0.1192\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0884 - kl_loss: 96.1852 - recon_loss: 0.0884 - val_loss: 0.0842 - val_kl_loss: 100.1300 - val_recon_loss: 0.0842\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0879 - kl_loss: 96.4738 - recon_loss: 0.0879 - val_loss: 0.2487 - val_kl_loss: 101.5397 - val_recon_loss: 0.2487\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0929 - kl_loss: 96.6141 - recon_loss: 0.0929 - val_loss: 0.0603 - val_kl_loss: 100.7192 - val_recon_loss: 0.0603\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.0881 - kl_loss: 96.6240 - recon_loss: 0.0881 - val_loss: 0.0658 - val_kl_loss: 101.0230 - val_recon_loss: 0.0658\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.0897 - kl_loss: 97.1459 - recon_loss: 0.0897 - val_loss: 0.1773 - val_kl_loss: 101.6074 - val_recon_loss: 0.1773\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.0892 - kl_loss: 96.9280 - recon_loss: 0.0892 - val_loss: 0.0730 - val_kl_loss: 100.8312 - val_recon_loss: 0.0730\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.0916 - kl_loss: 96.7791 - recon_loss: 0.0916 - val_loss: 0.0567 - val_kl_loss: 100.7371 - val_recon_loss: 0.0567\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0885 - kl_loss: 97.1882 - recon_loss: 0.0885 - val_loss: 0.0580 - val_kl_loss: 101.4964 - val_recon_loss: 0.0580\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0902 - kl_loss: 97.0225 - recon_loss: 0.0902 - val_loss: 0.1830 - val_kl_loss: 98.6200 - val_recon_loss: 0.1830\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.0912 - kl_loss: 96.8727 - recon_loss: 0.0912 - val_loss: 0.0855 - val_kl_loss: 100.9594 - val_recon_loss: 0.0855\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0880 - kl_loss: 96.9205 - recon_loss: 0.0880 - val_loss: 0.0914 - val_kl_loss: 101.2220 - val_recon_loss: 0.0914\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0881 - kl_loss: 96.9193 - recon_loss: 0.0881 - val_loss: 0.1030 - val_kl_loss: 99.9240 - val_recon_loss: 0.1030\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0892 - kl_loss: 96.7856 - recon_loss: 0.0892 - val_loss: 0.0664 - val_kl_loss: 100.5025 - val_recon_loss: 0.0664\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0891 - kl_loss: 96.5825 - recon_loss: 0.0891 - val_loss: 0.0825 - val_kl_loss: 99.7479 - val_recon_loss: 0.0825\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.0900 - kl_loss: 96.7350 - recon_loss: 0.0900 - val_loss: 0.1425 - val_kl_loss: 99.7510 - val_recon_loss: 0.1425\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0866 - kl_loss: 96.9762 - recon_loss: 0.0866 - val_loss: 0.0636 - val_kl_loss: 100.6780 - val_recon_loss: 0.0636\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0881 - kl_loss: 96.7487 - recon_loss: 0.0881 - val_loss: 0.0614 - val_kl_loss: 100.8128 - val_recon_loss: 0.0614\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.0888 - kl_loss: 97.1210 - recon_loss: 0.0888 - val_loss: 0.0756 - val_kl_loss: 100.1725 - val_recon_loss: 0.0756\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.0875 - kl_loss: 97.2681 - recon_loss: 0.0875 - val_loss: 0.0989 - val_kl_loss: 99.9657 - val_recon_loss: 0.0989\n",
      "========================= Model8=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 8), (None, 8 2068        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 8)            0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1812        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,978\n",
      "Trainable params: 3,978\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 8)            104         enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 8)            104         enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,068\n",
      "Trainable params: 2,068\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 24)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           300         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,812\n",
      "Trainable params: 1,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 137us/step - loss: 26.4961 - kl_loss: 21.7167 - recon_loss: 26.4961 - val_loss: 7.8925 - val_kl_loss: 51.3525 - val_recon_loss: 7.8925\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 4.0853 - kl_loss: 53.3359 - recon_loss: 4.0853 - val_loss: 2.8919 - val_kl_loss: 64.6835 - val_recon_loss: 2.8919\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 2.2224 - kl_loss: 61.1844 - recon_loss: 2.2224 - val_loss: 1.5556 - val_kl_loss: 75.2379 - val_recon_loss: 1.5556\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 1.3395 - kl_loss: 68.7546 - recon_loss: 1.3395 - val_loss: 1.1504 - val_kl_loss: 78.9175 - val_recon_loss: 1.1504\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 1.0186 - kl_loss: 74.4967 - recon_loss: 1.0186 - val_loss: 1.2284 - val_kl_loss: 88.3642 - val_recon_loss: 1.2284\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.8851 - kl_loss: 80.0044 - recon_loss: 0.8851 - val_loss: 0.8388 - val_kl_loss: 89.1346 - val_recon_loss: 0.8388\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.7949 - kl_loss: 82.9538 - recon_loss: 0.7949 - val_loss: 1.1664 - val_kl_loss: 90.6718 - val_recon_loss: 1.1664\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.7370 - kl_loss: 85.9012 - recon_loss: 0.7370 - val_loss: 0.7819 - val_kl_loss: 95.6109 - val_recon_loss: 0.7819\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.6847 - kl_loss: 87.4142 - recon_loss: 0.6847 - val_loss: 0.8386 - val_kl_loss: 102.2491 - val_recon_loss: 0.8386\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.6471 - kl_loss: 89.7919 - recon_loss: 0.6471 - val_loss: 0.5626 - val_kl_loss: 98.1357 - val_recon_loss: 0.5626\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.5980 - kl_loss: 90.8531 - recon_loss: 0.5980 - val_loss: 0.5560 - val_kl_loss: 101.0281 - val_recon_loss: 0.5560\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.5403 - kl_loss: 91.5730 - recon_loss: 0.5403 - val_loss: 0.4951 - val_kl_loss: 99.8455 - val_recon_loss: 0.4951\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.5073 - kl_loss: 92.2342 - recon_loss: 0.5073 - val_loss: 0.5020 - val_kl_loss: 101.5121 - val_recon_loss: 0.5020\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.4706 - kl_loss: 93.7910 - recon_loss: 0.4706 - val_loss: 1.1075 - val_kl_loss: 106.0426 - val_recon_loss: 1.1075\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.4345 - kl_loss: 95.0549 - recon_loss: 0.4345 - val_loss: 0.7933 - val_kl_loss: 106.2300 - val_recon_loss: 0.7933\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.4019 - kl_loss: 96.4794 - recon_loss: 0.4019 - val_loss: 0.3903 - val_kl_loss: 105.6525 - val_recon_loss: 0.3903\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3746 - kl_loss: 97.6310 - recon_loss: 0.3746 - val_loss: 0.3264 - val_kl_loss: 105.0089 - val_recon_loss: 0.3264\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3581 - kl_loss: 98.4781 - recon_loss: 0.3581 - val_loss: 0.3771 - val_kl_loss: 104.8917 - val_recon_loss: 0.3771\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3487 - kl_loss: 98.7018 - recon_loss: 0.3487 - val_loss: 0.2904 - val_kl_loss: 105.7902 - val_recon_loss: 0.2904\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3267 - kl_loss: 99.2561 - recon_loss: 0.3267 - val_loss: 0.5770 - val_kl_loss: 105.8127 - val_recon_loss: 0.5770\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.3118 - kl_loss: 99.6699 - recon_loss: 0.3118 - val_loss: 0.9776 - val_kl_loss: 111.4470 - val_recon_loss: 0.9776\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 63us/step - loss: 0.3120 - kl_loss: 100.0096 - recon_loss: 0.3120 - val_loss: 0.5192 - val_kl_loss: 106.1515 - val_recon_loss: 0.5192\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.2957 - kl_loss: 100.6040 - recon_loss: 0.2957 - val_loss: 0.2521 - val_kl_loss: 106.7648 - val_recon_loss: 0.2521\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 61us/step - loss: 0.2890 - kl_loss: 100.4375 - recon_loss: 0.2890 - val_loss: 0.3996 - val_kl_loss: 107.4937 - val_recon_loss: 0.3996\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 60us/step - loss: 0.2758 - kl_loss: 101.1732 - recon_loss: 0.2758 - val_loss: 0.3000 - val_kl_loss: 109.8894 - val_recon_loss: 0.3000\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 62us/step - loss: 0.2759 - kl_loss: 100.7784 - recon_loss: 0.2759 - val_loss: 0.2933 - val_kl_loss: 105.7087 - val_recon_loss: 0.2933\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 63us/step - loss: 0.2673 - kl_loss: 101.2032 - recon_loss: 0.2673 - val_loss: 0.6685 - val_kl_loss: 111.1077 - val_recon_loss: 0.6685\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 60us/step - loss: 0.2560 - kl_loss: 101.9010 - recon_loss: 0.2560 - val_loss: 0.2229 - val_kl_loss: 106.9940 - val_recon_loss: 0.2229\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 62us/step - loss: 0.2372 - kl_loss: 102.2433 - recon_loss: 0.2372 - val_loss: 0.2658 - val_kl_loss: 108.7141 - val_recon_loss: 0.2658\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 61us/step - loss: 0.2430 - kl_loss: 102.4557 - recon_loss: 0.2430 - val_loss: 0.2968 - val_kl_loss: 108.0077 - val_recon_loss: 0.2968\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 60us/step - loss: 0.2310 - kl_loss: 102.7172 - recon_loss: 0.2310 - val_loss: 0.5595 - val_kl_loss: 111.3093 - val_recon_loss: 0.5595\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 62us/step - loss: 0.2306 - kl_loss: 102.7371 - recon_loss: 0.2306 - val_loss: 0.3319 - val_kl_loss: 108.6585 - val_recon_loss: 0.3319\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 62us/step - loss: 0.2226 - kl_loss: 103.1139 - recon_loss: 0.2226 - val_loss: 0.2241 - val_kl_loss: 110.0183 - val_recon_loss: 0.2241\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2164 - kl_loss: 103.8105 - recon_loss: 0.2164 - val_loss: 0.1748 - val_kl_loss: 109.0342 - val_recon_loss: 0.1748\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2141 - kl_loss: 103.8063 - recon_loss: 0.2141 - val_loss: 0.1996 - val_kl_loss: 109.7139 - val_recon_loss: 0.1996\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2049 - kl_loss: 103.8512 - recon_loss: 0.2049 - val_loss: 0.2283 - val_kl_loss: 109.7147 - val_recon_loss: 0.2283\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1940 - kl_loss: 103.6188 - recon_loss: 0.1940 - val_loss: 0.3031 - val_kl_loss: 112.1755 - val_recon_loss: 0.3031\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.2085 - kl_loss: 103.5336 - recon_loss: 0.2085 - val_loss: 0.2507 - val_kl_loss: 110.0149 - val_recon_loss: 0.2507\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1959 - kl_loss: 103.6673 - recon_loss: 0.1959 - val_loss: 0.1643 - val_kl_loss: 110.6018 - val_recon_loss: 0.1643\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1896 - kl_loss: 103.6325 - recon_loss: 0.1896 - val_loss: 0.1626 - val_kl_loss: 110.0151 - val_recon_loss: 0.1626\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1927 - kl_loss: 104.2066 - recon_loss: 0.1927 - val_loss: 0.2187 - val_kl_loss: 111.2111 - val_recon_loss: 0.2187\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1935 - kl_loss: 104.8043 - recon_loss: 0.1935 - val_loss: 0.2276 - val_kl_loss: 111.5980 - val_recon_loss: 0.2276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1837 - kl_loss: 104.9658 - recon_loss: 0.1837 - val_loss: 0.1528 - val_kl_loss: 111.5298 - val_recon_loss: 0.1528\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1843 - kl_loss: 105.1934 - recon_loss: 0.1843 - val_loss: 0.1625 - val_kl_loss: 112.2719 - val_recon_loss: 0.1625\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.1798 - kl_loss: 105.2920 - recon_loss: 0.1798 - val_loss: 0.5523 - val_kl_loss: 110.4977 - val_recon_loss: 0.5523\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1795 - kl_loss: 104.9798 - recon_loss: 0.1795 - val_loss: 0.1857 - val_kl_loss: 112.3763 - val_recon_loss: 0.1857\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1716 - kl_loss: 105.4764 - recon_loss: 0.1716 - val_loss: 0.3058 - val_kl_loss: 111.6631 - val_recon_loss: 0.3058\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1760 - kl_loss: 105.8236 - recon_loss: 0.1760 - val_loss: 0.2441 - val_kl_loss: 113.4205 - val_recon_loss: 0.2441\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1827 - kl_loss: 106.4463 - recon_loss: 0.1827 - val_loss: 0.1335 - val_kl_loss: 112.1252 - val_recon_loss: 0.1335\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1626 - kl_loss: 106.5546 - recon_loss: 0.1626 - val_loss: 0.1400 - val_kl_loss: 113.1364 - val_recon_loss: 0.1400\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1765 - kl_loss: 106.5054 - recon_loss: 0.1765 - val_loss: 0.1422 - val_kl_loss: 111.5017 - val_recon_loss: 0.1422\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1654 - kl_loss: 105.9382 - recon_loss: 0.1654 - val_loss: 0.3248 - val_kl_loss: 111.8477 - val_recon_loss: 0.3248\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1693 - kl_loss: 106.3072 - recon_loss: 0.1693 - val_loss: 0.1548 - val_kl_loss: 113.7805 - val_recon_loss: 0.1548\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1629 - kl_loss: 106.4157 - recon_loss: 0.1629 - val_loss: 0.2370 - val_kl_loss: 110.8149 - val_recon_loss: 0.2370\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1600 - kl_loss: 106.1819 - recon_loss: 0.1600 - val_loss: 0.2764 - val_kl_loss: 113.6669 - val_recon_loss: 0.2764\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1594 - kl_loss: 106.2424 - recon_loss: 0.1594 - val_loss: 0.2043 - val_kl_loss: 110.6410 - val_recon_loss: 0.2043\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1588 - kl_loss: 105.9333 - recon_loss: 0.1588 - val_loss: 0.4531 - val_kl_loss: 109.7235 - val_recon_loss: 0.4531\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1590 - kl_loss: 106.1334 - recon_loss: 0.1590 - val_loss: 0.1808 - val_kl_loss: 112.7334 - val_recon_loss: 0.1808\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1568 - kl_loss: 105.9289 - recon_loss: 0.1568 - val_loss: 0.1227 - val_kl_loss: 110.4333 - val_recon_loss: 0.1227\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1565 - kl_loss: 105.6752 - recon_loss: 0.1565 - val_loss: 0.1196 - val_kl_loss: 110.6564 - val_recon_loss: 0.1196\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1528 - kl_loss: 105.3338 - recon_loss: 0.1528 - val_loss: 0.2964 - val_kl_loss: 110.7025 - val_recon_loss: 0.2964\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1572 - kl_loss: 104.7784 - recon_loss: 0.1572 - val_loss: 0.1704 - val_kl_loss: 112.0045 - val_recon_loss: 0.1704\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1535 - kl_loss: 105.0705 - recon_loss: 0.1535 - val_loss: 0.2365 - val_kl_loss: 108.5778 - val_recon_loss: 0.2365\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1541 - kl_loss: 104.8694 - recon_loss: 0.1541 - val_loss: 0.1291 - val_kl_loss: 110.8698 - val_recon_loss: 0.1291\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1508 - kl_loss: 104.6101 - recon_loss: 0.1508 - val_loss: 0.4926 - val_kl_loss: 107.5255 - val_recon_loss: 0.4926\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1481 - kl_loss: 104.6934 - recon_loss: 0.1481 - val_loss: 0.1347 - val_kl_loss: 109.1684 - val_recon_loss: 0.1347\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1456 - kl_loss: 104.6867 - recon_loss: 0.1456 - val_loss: 0.2793 - val_kl_loss: 110.4613 - val_recon_loss: 0.2793\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1552 - kl_loss: 104.7867 - recon_loss: 0.1552 - val_loss: 0.1288 - val_kl_loss: 111.3829 - val_recon_loss: 0.1288\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1447 - kl_loss: 104.4471 - recon_loss: 0.1447 - val_loss: 0.3448 - val_kl_loss: 107.2636 - val_recon_loss: 0.3448\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1504 - kl_loss: 104.3013 - recon_loss: 0.1504 - val_loss: 0.1207 - val_kl_loss: 110.7992 - val_recon_loss: 0.1207\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1445 - kl_loss: 104.4839 - recon_loss: 0.1445 - val_loss: 0.1070 - val_kl_loss: 109.8947 - val_recon_loss: 0.1070\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1448 - kl_loss: 104.4088 - recon_loss: 0.1448 - val_loss: 0.1161 - val_kl_loss: 110.5769 - val_recon_loss: 0.1161\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1432 - kl_loss: 104.4559 - recon_loss: 0.1432 - val_loss: 0.1186 - val_kl_loss: 110.7764 - val_recon_loss: 0.1186\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1402 - kl_loss: 104.7272 - recon_loss: 0.1402 - val_loss: 0.0966 - val_kl_loss: 109.7229 - val_recon_loss: 0.0966\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1418 - kl_loss: 104.7219 - recon_loss: 0.1418 - val_loss: 0.2512 - val_kl_loss: 109.1047 - val_recon_loss: 0.2512\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1425 - kl_loss: 104.5992 - recon_loss: 0.1425 - val_loss: 0.0957 - val_kl_loss: 109.7198 - val_recon_loss: 0.0957\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1426 - kl_loss: 104.6816 - recon_loss: 0.1426 - val_loss: 0.1612 - val_kl_loss: 110.9402 - val_recon_loss: 0.1612\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1359 - kl_loss: 104.6100 - recon_loss: 0.1359 - val_loss: 0.2596 - val_kl_loss: 111.3878 - val_recon_loss: 0.2596\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1428 - kl_loss: 104.5711 - recon_loss: 0.1428 - val_loss: 0.0982 - val_kl_loss: 109.7940 - val_recon_loss: 0.0982\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1369 - kl_loss: 104.9243 - recon_loss: 0.1369 - val_loss: 0.2188 - val_kl_loss: 110.4794 - val_recon_loss: 0.2188\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1359 - kl_loss: 105.2382 - recon_loss: 0.1359 - val_loss: 0.2147 - val_kl_loss: 111.2993 - val_recon_loss: 0.2147\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1334 - kl_loss: 104.9526 - recon_loss: 0.1334 - val_loss: 0.1399 - val_kl_loss: 109.6869 - val_recon_loss: 0.1399\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1361 - kl_loss: 105.2998 - recon_loss: 0.1361 - val_loss: 0.1071 - val_kl_loss: 109.6797 - val_recon_loss: 0.1071\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1382 - kl_loss: 105.3402 - recon_loss: 0.1382 - val_loss: 0.1321 - val_kl_loss: 110.6907 - val_recon_loss: 0.1321\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1355 - kl_loss: 105.9288 - recon_loss: 0.1355 - val_loss: 0.1288 - val_kl_loss: 110.3741 - val_recon_loss: 0.1288\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1313 - kl_loss: 105.8090 - recon_loss: 0.1313 - val_loss: 0.3649 - val_kl_loss: 110.4905 - val_recon_loss: 0.3649\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1295 - kl_loss: 105.2668 - recon_loss: 0.1295 - val_loss: 0.2440 - val_kl_loss: 111.9113 - val_recon_loss: 0.2440\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1322 - kl_loss: 105.7350 - recon_loss: 0.1322 - val_loss: 0.0949 - val_kl_loss: 111.5377 - val_recon_loss: 0.0949\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1328 - kl_loss: 105.3279 - recon_loss: 0.1328 - val_loss: 0.1236 - val_kl_loss: 111.0636 - val_recon_loss: 0.1236\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1316 - kl_loss: 105.2548 - recon_loss: 0.1316 - val_loss: 0.0861 - val_kl_loss: 110.3353 - val_recon_loss: 0.0861\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1249 - kl_loss: 104.8645 - recon_loss: 0.1249 - val_loss: 0.3404 - val_kl_loss: 107.5990 - val_recon_loss: 0.3404\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1295 - kl_loss: 104.5054 - recon_loss: 0.1295 - val_loss: 0.2937 - val_kl_loss: 109.5979 - val_recon_loss: 0.2937\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1273 - kl_loss: 104.6214 - recon_loss: 0.1273 - val_loss: 0.1678 - val_kl_loss: 109.3572 - val_recon_loss: 0.1678\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1234 - kl_loss: 105.1467 - recon_loss: 0.1234 - val_loss: 0.1171 - val_kl_loss: 109.0415 - val_recon_loss: 0.1171\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1334 - kl_loss: 105.0610 - recon_loss: 0.1334 - val_loss: 0.1093 - val_kl_loss: 110.1814 - val_recon_loss: 0.1093\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1236 - kl_loss: 105.4085 - recon_loss: 0.1236 - val_loss: 0.1951 - val_kl_loss: 109.0666 - val_recon_loss: 0.1951\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.1259 - kl_loss: 104.8858 - recon_loss: 0.1259 - val_loss: 0.0994 - val_kl_loss: 110.6036 - val_recon_loss: 0.0994\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1248 - kl_loss: 104.8555 - recon_loss: 0.1248 - val_loss: 0.0985 - val_kl_loss: 109.9054 - val_recon_loss: 0.0985\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1277 - kl_loss: 104.9731 - recon_loss: 0.1277 - val_loss: 0.0990 - val_kl_loss: 108.7294 - val_recon_loss: 0.0990\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1235 - kl_loss: 104.9871 - recon_loss: 0.1235 - val_loss: 0.0822 - val_kl_loss: 110.2569 - val_recon_loss: 0.0822\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1200 - kl_loss: 105.3104 - recon_loss: 0.1200 - val_loss: 0.2470 - val_kl_loss: 109.8633 - val_recon_loss: 0.2470\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1256 - kl_loss: 105.6346 - recon_loss: 0.1256 - val_loss: 0.1031 - val_kl_loss: 110.5094 - val_recon_loss: 0.1031\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1224 - kl_loss: 106.0149 - recon_loss: 0.1224 - val_loss: 0.2384 - val_kl_loss: 112.7652 - val_recon_loss: 0.2384\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1211 - kl_loss: 105.7029 - recon_loss: 0.1211 - val_loss: 0.0833 - val_kl_loss: 111.2532 - val_recon_loss: 0.0833\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1212 - kl_loss: 105.8967 - recon_loss: 0.1212 - val_loss: 0.0937 - val_kl_loss: 110.6542 - val_recon_loss: 0.0937\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1177 - kl_loss: 105.5359 - recon_loss: 0.1177 - val_loss: 0.1715 - val_kl_loss: 110.3668 - val_recon_loss: 0.1715\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1212 - kl_loss: 105.9354 - recon_loss: 0.1212 - val_loss: 0.1020 - val_kl_loss: 110.8063 - val_recon_loss: 0.1020\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1185 - kl_loss: 105.8379 - recon_loss: 0.1185 - val_loss: 0.2077 - val_kl_loss: 109.3043 - val_recon_loss: 0.2077\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1184 - kl_loss: 105.4061 - recon_loss: 0.1184 - val_loss: 0.0844 - val_kl_loss: 110.5796 - val_recon_loss: 0.0844\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1169 - kl_loss: 105.4904 - recon_loss: 0.1169 - val_loss: 0.2008 - val_kl_loss: 108.3583 - val_recon_loss: 0.2008\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1194 - kl_loss: 105.0818 - recon_loss: 0.1194 - val_loss: 0.1171 - val_kl_loss: 109.9043 - val_recon_loss: 0.1171\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1159 - kl_loss: 105.3974 - recon_loss: 0.1159 - val_loss: 0.0730 - val_kl_loss: 109.9907 - val_recon_loss: 0.0730\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1089 - kl_loss: 105.6061 - recon_loss: 0.1089 - val_loss: 0.1121 - val_kl_loss: 111.2095 - val_recon_loss: 0.1121\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1188 - kl_loss: 105.5932 - recon_loss: 0.1188 - val_loss: 0.0849 - val_kl_loss: 110.1487 - val_recon_loss: 0.0849\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1158 - kl_loss: 105.6886 - recon_loss: 0.1158 - val_loss: 0.0934 - val_kl_loss: 110.7109 - val_recon_loss: 0.0934\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1191 - kl_loss: 105.8974 - recon_loss: 0.1191 - val_loss: 0.1654 - val_kl_loss: 111.4814 - val_recon_loss: 0.1654\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1138 - kl_loss: 105.7993 - recon_loss: 0.1138 - val_loss: 0.1362 - val_kl_loss: 109.8518 - val_recon_loss: 0.1362\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1115 - kl_loss: 105.8236 - recon_loss: 0.1115 - val_loss: 0.0795 - val_kl_loss: 110.5961 - val_recon_loss: 0.0795\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1119 - kl_loss: 105.7428 - recon_loss: 0.1119 - val_loss: 0.1254 - val_kl_loss: 110.5981 - val_recon_loss: 0.1254\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1103 - kl_loss: 105.7836 - recon_loss: 0.1103 - val_loss: 0.1011 - val_kl_loss: 111.2191 - val_recon_loss: 0.1011\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1179 - kl_loss: 105.7723 - recon_loss: 0.1179 - val_loss: 0.0915 - val_kl_loss: 111.0163 - val_recon_loss: 0.0915\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1069 - kl_loss: 106.2563 - recon_loss: 0.1069 - val_loss: 0.1826 - val_kl_loss: 109.2597 - val_recon_loss: 0.1826\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 62us/step - loss: 0.1154 - kl_loss: 106.2069 - recon_loss: 0.1154 - val_loss: 0.1195 - val_kl_loss: 111.6626 - val_recon_loss: 0.1195\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 61us/step - loss: 0.1091 - kl_loss: 106.6116 - recon_loss: 0.1091 - val_loss: 0.0863 - val_kl_loss: 111.1526 - val_recon_loss: 0.0863\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1082 - kl_loss: 106.3717 - recon_loss: 0.1082 - val_loss: 0.2441 - val_kl_loss: 108.8902 - val_recon_loss: 0.2441\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1122 - kl_loss: 106.1479 - recon_loss: 0.1122 - val_loss: 0.1233 - val_kl_loss: 110.4140 - val_recon_loss: 0.1233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1093 - kl_loss: 106.2036 - recon_loss: 0.1093 - val_loss: 0.1256 - val_kl_loss: 110.4538 - val_recon_loss: 0.1256\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1057 - kl_loss: 106.5856 - recon_loss: 0.1057 - val_loss: 0.2256 - val_kl_loss: 112.1606 - val_recon_loss: 0.2256\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1050 - kl_loss: 106.9616 - recon_loss: 0.1050 - val_loss: 0.1090 - val_kl_loss: 111.8093 - val_recon_loss: 0.1090\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1091 - kl_loss: 106.6995 - recon_loss: 0.1091 - val_loss: 0.1071 - val_kl_loss: 110.7666 - val_recon_loss: 0.1071\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1088 - kl_loss: 106.5093 - recon_loss: 0.1088 - val_loss: 0.0750 - val_kl_loss: 111.4496 - val_recon_loss: 0.0750\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1013 - kl_loss: 106.8259 - recon_loss: 0.1013 - val_loss: 0.1328 - val_kl_loss: 111.6629 - val_recon_loss: 0.1328\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1065 - kl_loss: 106.3230 - recon_loss: 0.1065 - val_loss: 0.1508 - val_kl_loss: 110.4299 - val_recon_loss: 0.1508\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1051 - kl_loss: 106.3695 - recon_loss: 0.1051 - val_loss: 0.2013 - val_kl_loss: 110.1301 - val_recon_loss: 0.2013\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1041 - kl_loss: 106.3779 - recon_loss: 0.1041 - val_loss: 0.3803 - val_kl_loss: 108.4767 - val_recon_loss: 0.3803\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1056 - kl_loss: 106.4035 - recon_loss: 0.1056 - val_loss: 0.0794 - val_kl_loss: 111.4752 - val_recon_loss: 0.0794\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1053 - kl_loss: 106.4719 - recon_loss: 0.1053 - val_loss: 0.1044 - val_kl_loss: 110.9949 - val_recon_loss: 0.1044\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1054 - kl_loss: 106.3756 - recon_loss: 0.1054 - val_loss: 0.3671 - val_kl_loss: 109.7329 - val_recon_loss: 0.3671\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1021 - kl_loss: 106.3662 - recon_loss: 0.1021 - val_loss: 0.1163 - val_kl_loss: 109.9470 - val_recon_loss: 0.1163\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1075 - kl_loss: 106.1015 - recon_loss: 0.1075 - val_loss: 0.3102 - val_kl_loss: 112.3434 - val_recon_loss: 0.3102\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1041 - kl_loss: 105.8610 - recon_loss: 0.1041 - val_loss: 0.2250 - val_kl_loss: 112.2661 - val_recon_loss: 0.2250\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1047 - kl_loss: 106.4468 - recon_loss: 0.1047 - val_loss: 0.0839 - val_kl_loss: 110.8960 - val_recon_loss: 0.0839\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1026 - kl_loss: 106.4732 - recon_loss: 0.1026 - val_loss: 0.0797 - val_kl_loss: 110.8130 - val_recon_loss: 0.0797\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1035 - kl_loss: 106.6134 - recon_loss: 0.1035 - val_loss: 0.0681 - val_kl_loss: 110.5703 - val_recon_loss: 0.0681\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1030 - kl_loss: 106.6029 - recon_loss: 0.1030 - val_loss: 0.0952 - val_kl_loss: 111.6951 - val_recon_loss: 0.0952\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1016 - kl_loss: 106.8272 - recon_loss: 0.1016 - val_loss: 0.0985 - val_kl_loss: 110.7392 - val_recon_loss: 0.0985\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0981 - kl_loss: 107.1629 - recon_loss: 0.0981 - val_loss: 0.1542 - val_kl_loss: 112.8483 - val_recon_loss: 0.1542\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0991 - kl_loss: 107.1366 - recon_loss: 0.0991 - val_loss: 0.1691 - val_kl_loss: 112.7647 - val_recon_loss: 0.1691\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1032 - kl_loss: 107.4690 - recon_loss: 0.1032 - val_loss: 0.1019 - val_kl_loss: 110.3856 - val_recon_loss: 0.1019\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1026 - kl_loss: 107.2456 - recon_loss: 0.1026 - val_loss: 0.0959 - val_kl_loss: 111.0672 - val_recon_loss: 0.0959\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0975 - kl_loss: 107.2618 - recon_loss: 0.0975 - val_loss: 0.0936 - val_kl_loss: 112.1012 - val_recon_loss: 0.0936\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1038 - kl_loss: 107.3187 - recon_loss: 0.1038 - val_loss: 0.0604 - val_kl_loss: 111.5010 - val_recon_loss: 0.0604\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0941 - kl_loss: 107.5678 - recon_loss: 0.0941 - val_loss: 0.1152 - val_kl_loss: 111.5408 - val_recon_loss: 0.1152\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1005 - kl_loss: 107.9670 - recon_loss: 0.1005 - val_loss: 0.1315 - val_kl_loss: 111.8138 - val_recon_loss: 0.1315\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0949 - kl_loss: 108.2082 - recon_loss: 0.0949 - val_loss: 0.0896 - val_kl_loss: 112.2188 - val_recon_loss: 0.0896\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0983 - kl_loss: 107.9663 - recon_loss: 0.0983 - val_loss: 0.1005 - val_kl_loss: 112.4534 - val_recon_loss: 0.1005\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.0997 - kl_loss: 107.7772 - recon_loss: 0.0997 - val_loss: 0.0738 - val_kl_loss: 112.5954 - val_recon_loss: 0.0738\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.0960 - kl_loss: 107.8332 - recon_loss: 0.0960 - val_loss: 0.1035 - val_kl_loss: 112.7286 - val_recon_loss: 0.1035\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0986 - kl_loss: 108.3328 - recon_loss: 0.0986 - val_loss: 0.0915 - val_kl_loss: 112.5922 - val_recon_loss: 0.0915\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0968 - kl_loss: 108.5620 - recon_loss: 0.0968 - val_loss: 0.0916 - val_kl_loss: 113.2081 - val_recon_loss: 0.0916\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0973 - kl_loss: 108.2940 - recon_loss: 0.0973 - val_loss: 0.1592 - val_kl_loss: 112.0796 - val_recon_loss: 0.1592\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0973 - kl_loss: 108.3994 - recon_loss: 0.0973 - val_loss: 0.0680 - val_kl_loss: 112.8303 - val_recon_loss: 0.0680\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0977 - kl_loss: 108.5414 - recon_loss: 0.0977 - val_loss: 0.1185 - val_kl_loss: 113.8277 - val_recon_loss: 0.1185\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0951 - kl_loss: 108.5358 - recon_loss: 0.0951 - val_loss: 0.1323 - val_kl_loss: 111.8743 - val_recon_loss: 0.1323\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0940 - kl_loss: 108.8664 - recon_loss: 0.0940 - val_loss: 0.1193 - val_kl_loss: 113.1532 - val_recon_loss: 0.1193\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0985 - kl_loss: 108.8873 - recon_loss: 0.0985 - val_loss: 0.1145 - val_kl_loss: 114.2115 - val_recon_loss: 0.1145\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0901 - kl_loss: 109.1621 - recon_loss: 0.0901 - val_loss: 0.1001 - val_kl_loss: 113.0688 - val_recon_loss: 0.1001\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0940 - kl_loss: 108.7804 - recon_loss: 0.0940 - val_loss: 0.1449 - val_kl_loss: 112.7080 - val_recon_loss: 0.1449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.0949 - kl_loss: 108.5480 - recon_loss: 0.0949 - val_loss: 0.0610 - val_kl_loss: 112.9168 - val_recon_loss: 0.0610\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0926 - kl_loss: 108.9249 - recon_loss: 0.0926 - val_loss: 0.1855 - val_kl_loss: 112.5229 - val_recon_loss: 0.1855\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0965 - kl_loss: 108.6822 - recon_loss: 0.0965 - val_loss: 0.0999 - val_kl_loss: 113.2284 - val_recon_loss: 0.0999\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0909 - kl_loss: 108.8090 - recon_loss: 0.0909 - val_loss: 0.0762 - val_kl_loss: 113.0996 - val_recon_loss: 0.0762\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0942 - kl_loss: 109.0191 - recon_loss: 0.0942 - val_loss: 0.1817 - val_kl_loss: 111.1142 - val_recon_loss: 0.1817\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.0905 - kl_loss: 108.7259 - recon_loss: 0.0905 - val_loss: 0.2074 - val_kl_loss: 111.8140 - val_recon_loss: 0.2074\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0922 - kl_loss: 108.7118 - recon_loss: 0.0922 - val_loss: 0.0921 - val_kl_loss: 112.1285 - val_recon_loss: 0.0921\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.0916 - kl_loss: 108.7611 - recon_loss: 0.0916 - val_loss: 0.1081 - val_kl_loss: 114.3787 - val_recon_loss: 0.1081\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0927 - kl_loss: 108.9213 - recon_loss: 0.0927 - val_loss: 0.1040 - val_kl_loss: 113.1575 - val_recon_loss: 0.1040\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.0902 - kl_loss: 109.0542 - recon_loss: 0.0902 - val_loss: 0.0951 - val_kl_loss: 113.8700 - val_recon_loss: 0.0951\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0900 - kl_loss: 109.0306 - recon_loss: 0.0900 - val_loss: 0.0790 - val_kl_loss: 112.8654 - val_recon_loss: 0.0790\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.0869 - kl_loss: 108.9763 - recon_loss: 0.0869 - val_loss: 0.1115 - val_kl_loss: 111.8676 - val_recon_loss: 0.1115\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.0886 - kl_loss: 109.2062 - recon_loss: 0.0886 - val_loss: 0.2107 - val_kl_loss: 112.7027 - val_recon_loss: 0.2107\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0954 - kl_loss: 109.6503 - recon_loss: 0.0954 - val_loss: 0.0627 - val_kl_loss: 113.7698 - val_recon_loss: 0.0627\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0883 - kl_loss: 109.9685 - recon_loss: 0.0883 - val_loss: 0.1505 - val_kl_loss: 113.1007 - val_recon_loss: 0.1505\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0903 - kl_loss: 109.9471 - recon_loss: 0.0903 - val_loss: 0.0859 - val_kl_loss: 114.8659 - val_recon_loss: 0.0859\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0882 - kl_loss: 109.9835 - recon_loss: 0.0882 - val_loss: 0.1046 - val_kl_loss: 113.2893 - val_recon_loss: 0.1046\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0900 - kl_loss: 109.8200 - recon_loss: 0.0900 - val_loss: 0.0722 - val_kl_loss: 113.5947 - val_recon_loss: 0.0722\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.0884 - kl_loss: 109.9256 - recon_loss: 0.0884 - val_loss: 0.0659 - val_kl_loss: 113.8558 - val_recon_loss: 0.0659\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.0886 - kl_loss: 109.8344 - recon_loss: 0.0886 - val_loss: 0.1034 - val_kl_loss: 114.3958 - val_recon_loss: 0.1034\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0850 - kl_loss: 109.8197 - recon_loss: 0.0850 - val_loss: 0.0731 - val_kl_loss: 114.0291 - val_recon_loss: 0.0731\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0886 - kl_loss: 109.6129 - recon_loss: 0.0886 - val_loss: 0.0650 - val_kl_loss: 113.7573 - val_recon_loss: 0.0650\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0844 - kl_loss: 109.3975 - recon_loss: 0.0844 - val_loss: 0.0690 - val_kl_loss: 113.6687 - val_recon_loss: 0.0690\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0855 - kl_loss: 109.7179 - recon_loss: 0.0855 - val_loss: 0.0782 - val_kl_loss: 114.6956 - val_recon_loss: 0.0782\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0895 - kl_loss: 110.2624 - recon_loss: 0.0895 - val_loss: 0.1246 - val_kl_loss: 114.7149 - val_recon_loss: 0.1246\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0842 - kl_loss: 110.3387 - recon_loss: 0.0842 - val_loss: 0.0940 - val_kl_loss: 113.0437 - val_recon_loss: 0.0940\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0887 - kl_loss: 110.2596 - recon_loss: 0.0887 - val_loss: 0.0917 - val_kl_loss: 114.5951 - val_recon_loss: 0.0917\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0838 - kl_loss: 110.2553 - recon_loss: 0.0838 - val_loss: 0.0615 - val_kl_loss: 113.6801 - val_recon_loss: 0.0615\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0822 - kl_loss: 109.9856 - recon_loss: 0.0822 - val_loss: 0.1577 - val_kl_loss: 113.5410 - val_recon_loss: 0.1577\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0836 - kl_loss: 110.1248 - recon_loss: 0.0836 - val_loss: 0.1031 - val_kl_loss: 115.7393 - val_recon_loss: 0.1031\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0850 - kl_loss: 110.3311 - recon_loss: 0.0850 - val_loss: 0.1407 - val_kl_loss: 113.3254 - val_recon_loss: 0.1407\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0869 - kl_loss: 109.9549 - recon_loss: 0.0869 - val_loss: 0.1080 - val_kl_loss: 114.6090 - val_recon_loss: 0.1080\n",
      "========================= Model9=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 9), (None, 9 2094        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 9)            0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1824        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,016\n",
      "Trainable params: 4,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 9)            117         enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 9)            117         enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,094\n",
      "Trainable params: 2,094\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 25)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           312         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,824\n",
      "Trainable params: 1,824\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 126us/step - loss: 32.9615 - kl_loss: 12.4330 - recon_loss: 32.9615 - val_loss: 10.1245 - val_kl_loss: 34.1030 - val_recon_loss: 10.1245\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 4.1378 - kl_loss: 45.1834 - recon_loss: 4.1378 - val_loss: 2.4517 - val_kl_loss: 62.4793 - val_recon_loss: 2.4517\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 2.0186 - kl_loss: 61.6299 - recon_loss: 2.0186 - val_loss: 1.6188 - val_kl_loss: 75.8497 - val_recon_loss: 1.6188\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 1.2746 - kl_loss: 73.3486 - recon_loss: 1.2746 - val_loss: 1.0167 - val_kl_loss: 86.0665 - val_recon_loss: 1.0167\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.9624 - kl_loss: 81.3705 - recon_loss: 0.9624 - val_loss: 0.9601 - val_kl_loss: 95.0772 - val_recon_loss: 0.9601\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.8076 - kl_loss: 87.8224 - recon_loss: 0.8076 - val_loss: 0.7599 - val_kl_loss: 100.8697 - val_recon_loss: 0.7599\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.6914 - kl_loss: 92.5027 - recon_loss: 0.6914 - val_loss: 0.7119 - val_kl_loss: 105.6246 - val_recon_loss: 0.7119\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.6259 - kl_loss: 96.7741 - recon_loss: 0.6259 - val_loss: 1.1127 - val_kl_loss: 104.2011 - val_recon_loss: 1.1127\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.5502 - kl_loss: 99.1053 - recon_loss: 0.5502 - val_loss: 0.6117 - val_kl_loss: 112.1323 - val_recon_loss: 0.6117\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.5115 - kl_loss: 101.1883 - recon_loss: 0.5115 - val_loss: 0.5350 - val_kl_loss: 112.1763 - val_recon_loss: 0.5350\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.4716 - kl_loss: 102.8519 - recon_loss: 0.4716 - val_loss: 0.5799 - val_kl_loss: 112.5448 - val_recon_loss: 0.5799\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.4480 - kl_loss: 104.8619 - recon_loss: 0.4480 - val_loss: 0.5602 - val_kl_loss: 116.0569 - val_recon_loss: 0.5602\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.4160 - kl_loss: 106.1262 - recon_loss: 0.4160 - val_loss: 0.4408 - val_kl_loss: 118.7145 - val_recon_loss: 0.4408\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3996 - kl_loss: 107.9517 - recon_loss: 0.3996 - val_loss: 0.3294 - val_kl_loss: 118.9331 - val_recon_loss: 0.3294\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.3820 - kl_loss: 108.5806 - recon_loss: 0.3820 - val_loss: 0.4219 - val_kl_loss: 117.4493 - val_recon_loss: 0.4219\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.3695 - kl_loss: 109.3186 - recon_loss: 0.3695 - val_loss: 0.4283 - val_kl_loss: 118.9610 - val_recon_loss: 0.4283\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3522 - kl_loss: 109.5667 - recon_loss: 0.3522 - val_loss: 0.3433 - val_kl_loss: 120.9492 - val_recon_loss: 0.3433\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.3393 - kl_loss: 110.0666 - recon_loss: 0.3393 - val_loss: 0.6862 - val_kl_loss: 119.7389 - val_recon_loss: 0.6862\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.3379 - kl_loss: 110.4655 - recon_loss: 0.3379 - val_loss: 0.3490 - val_kl_loss: 119.7257 - val_recon_loss: 0.3490\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3214 - kl_loss: 110.5470 - recon_loss: 0.3214 - val_loss: 0.4746 - val_kl_loss: 121.3801 - val_recon_loss: 0.4746\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.3203 - kl_loss: 110.9478 - recon_loss: 0.3203 - val_loss: 0.3412 - val_kl_loss: 122.4991 - val_recon_loss: 0.3412\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.3050 - kl_loss: 111.4980 - recon_loss: 0.3050 - val_loss: 0.2906 - val_kl_loss: 121.3109 - val_recon_loss: 0.2906\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3038 - kl_loss: 111.3358 - recon_loss: 0.3038 - val_loss: 0.3472 - val_kl_loss: 122.1762 - val_recon_loss: 0.3472\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2949 - kl_loss: 111.7324 - recon_loss: 0.2949 - val_loss: 0.4080 - val_kl_loss: 120.3387 - val_recon_loss: 0.4080\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2882 - kl_loss: 111.8600 - recon_loss: 0.2882 - val_loss: 0.4128 - val_kl_loss: 123.0875 - val_recon_loss: 0.4128\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.2886 - kl_loss: 112.1649 - recon_loss: 0.2886 - val_loss: 0.2345 - val_kl_loss: 121.6441 - val_recon_loss: 0.2345\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2713 - kl_loss: 112.3486 - recon_loss: 0.2713 - val_loss: 0.2548 - val_kl_loss: 121.0624 - val_recon_loss: 0.2548\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.2709 - kl_loss: 112.5099 - recon_loss: 0.2709 - val_loss: 0.2785 - val_kl_loss: 122.3990 - val_recon_loss: 0.2785\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2692 - kl_loss: 112.3490 - recon_loss: 0.2692 - val_loss: 0.3017 - val_kl_loss: 121.7193 - val_recon_loss: 0.3017\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2583 - kl_loss: 112.2998 - recon_loss: 0.2583 - val_loss: 0.3267 - val_kl_loss: 122.6819 - val_recon_loss: 0.3267\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2565 - kl_loss: 112.3398 - recon_loss: 0.2565 - val_loss: 0.4491 - val_kl_loss: 119.1283 - val_recon_loss: 0.4491\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2546 - kl_loss: 112.0652 - recon_loss: 0.2546 - val_loss: 0.1930 - val_kl_loss: 120.0880 - val_recon_loss: 0.1930\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2479 - kl_loss: 112.0743 - recon_loss: 0.2479 - val_loss: 0.4267 - val_kl_loss: 124.5063 - val_recon_loss: 0.4267\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2529 - kl_loss: 112.3752 - recon_loss: 0.2529 - val_loss: 0.3444 - val_kl_loss: 119.7224 - val_recon_loss: 0.3444\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.2458 - kl_loss: 112.1952 - recon_loss: 0.2458 - val_loss: 0.2698 - val_kl_loss: 119.5387 - val_recon_loss: 0.2698\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2409 - kl_loss: 112.2078 - recon_loss: 0.2409 - val_loss: 0.1761 - val_kl_loss: 119.8507 - val_recon_loss: 0.1761\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2281 - kl_loss: 112.2002 - recon_loss: 0.2281 - val_loss: 0.7579 - val_kl_loss: 118.5905 - val_recon_loss: 0.7579\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2395 - kl_loss: 112.1171 - recon_loss: 0.2395 - val_loss: 0.1644 - val_kl_loss: 120.7107 - val_recon_loss: 0.1644\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2274 - kl_loss: 112.2908 - recon_loss: 0.2274 - val_loss: 0.2036 - val_kl_loss: 121.4706 - val_recon_loss: 0.2036\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2293 - kl_loss: 112.3814 - recon_loss: 0.2293 - val_loss: 0.2188 - val_kl_loss: 121.6672 - val_recon_loss: 0.2188\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2176 - kl_loss: 112.4115 - recon_loss: 0.2176 - val_loss: 0.2077 - val_kl_loss: 119.5361 - val_recon_loss: 0.2077\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.2171 - kl_loss: 112.0077 - recon_loss: 0.2171 - val_loss: 0.2245 - val_kl_loss: 120.3675 - val_recon_loss: 0.2245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2140 - kl_loss: 111.6515 - recon_loss: 0.2140 - val_loss: 0.2040 - val_kl_loss: 119.6802 - val_recon_loss: 0.2040\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2114 - kl_loss: 111.5886 - recon_loss: 0.2114 - val_loss: 0.2932 - val_kl_loss: 121.3742 - val_recon_loss: 0.2932\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.2117 - kl_loss: 111.2332 - recon_loss: 0.2117 - val_loss: 0.4762 - val_kl_loss: 117.5877 - val_recon_loss: 0.4762\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2116 - kl_loss: 111.1892 - recon_loss: 0.2116 - val_loss: 0.1853 - val_kl_loss: 118.7239 - val_recon_loss: 0.1853\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1941 - kl_loss: 111.1197 - recon_loss: 0.1941 - val_loss: 0.2795 - val_kl_loss: 117.2998 - val_recon_loss: 0.2795\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2048 - kl_loss: 111.5380 - recon_loss: 0.2048 - val_loss: 0.2739 - val_kl_loss: 116.7781 - val_recon_loss: 0.2739\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2013 - kl_loss: 111.7863 - recon_loss: 0.2013 - val_loss: 0.1771 - val_kl_loss: 120.0023 - val_recon_loss: 0.1771\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1959 - kl_loss: 111.5778 - recon_loss: 0.1959 - val_loss: 0.2586 - val_kl_loss: 120.5943 - val_recon_loss: 0.2586\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1889 - kl_loss: 111.5420 - recon_loss: 0.1889 - val_loss: 0.2071 - val_kl_loss: 120.2082 - val_recon_loss: 0.2071\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1970 - kl_loss: 111.1637 - recon_loss: 0.1970 - val_loss: 0.1656 - val_kl_loss: 118.3747 - val_recon_loss: 0.1656\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1890 - kl_loss: 111.1702 - recon_loss: 0.1890 - val_loss: 0.1377 - val_kl_loss: 118.9584 - val_recon_loss: 0.1377\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1820 - kl_loss: 111.3543 - recon_loss: 0.1820 - val_loss: 0.1874 - val_kl_loss: 117.5953 - val_recon_loss: 0.1874\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1868 - kl_loss: 110.8936 - recon_loss: 0.1868 - val_loss: 0.2298 - val_kl_loss: 118.4894 - val_recon_loss: 0.2298\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1826 - kl_loss: 110.9397 - recon_loss: 0.1826 - val_loss: 0.4654 - val_kl_loss: 119.6395 - val_recon_loss: 0.4654\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1819 - kl_loss: 110.7643 - recon_loss: 0.1819 - val_loss: 0.1518 - val_kl_loss: 117.4683 - val_recon_loss: 0.1518\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1803 - kl_loss: 110.6175 - recon_loss: 0.1803 - val_loss: 0.6069 - val_kl_loss: 113.6861 - val_recon_loss: 0.6069\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1775 - kl_loss: 110.7902 - recon_loss: 0.1775 - val_loss: 0.1360 - val_kl_loss: 117.7190 - val_recon_loss: 0.1360\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1782 - kl_loss: 110.9680 - recon_loss: 0.1782 - val_loss: 0.3079 - val_kl_loss: 121.2425 - val_recon_loss: 0.3079\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1787 - kl_loss: 110.9832 - recon_loss: 0.1787 - val_loss: 0.2070 - val_kl_loss: 118.8711 - val_recon_loss: 0.2070\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1728 - kl_loss: 110.9918 - recon_loss: 0.1728 - val_loss: 0.4873 - val_kl_loss: 115.4838 - val_recon_loss: 0.4873\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1787 - kl_loss: 110.6684 - recon_loss: 0.1787 - val_loss: 0.1328 - val_kl_loss: 117.8710 - val_recon_loss: 0.1328\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1718 - kl_loss: 110.4830 - recon_loss: 0.1718 - val_loss: 0.1674 - val_kl_loss: 117.6207 - val_recon_loss: 0.1674\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1698 - kl_loss: 110.3666 - recon_loss: 0.1698 - val_loss: 0.1515 - val_kl_loss: 117.2895 - val_recon_loss: 0.1515\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1709 - kl_loss: 110.4681 - recon_loss: 0.1709 - val_loss: 0.2544 - val_kl_loss: 117.5740 - val_recon_loss: 0.2544\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1684 - kl_loss: 110.3120 - recon_loss: 0.1684 - val_loss: 0.3283 - val_kl_loss: 119.4158 - val_recon_loss: 0.3283\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1644 - kl_loss: 110.4022 - recon_loss: 0.1644 - val_loss: 0.2113 - val_kl_loss: 116.7312 - val_recon_loss: 0.2113\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1666 - kl_loss: 110.7972 - recon_loss: 0.1666 - val_loss: 0.2986 - val_kl_loss: 116.0810 - val_recon_loss: 0.2986\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1612 - kl_loss: 111.1841 - recon_loss: 0.1612 - val_loss: 0.1957 - val_kl_loss: 117.5741 - val_recon_loss: 0.1957\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1708 - kl_loss: 111.1670 - recon_loss: 0.1708 - val_loss: 0.1212 - val_kl_loss: 117.8918 - val_recon_loss: 0.1212\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1558 - kl_loss: 111.1484 - recon_loss: 0.1558 - val_loss: 0.6571 - val_kl_loss: 120.2496 - val_recon_loss: 0.6571\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1579 - kl_loss: 110.9326 - recon_loss: 0.1579 - val_loss: 0.1988 - val_kl_loss: 119.7474 - val_recon_loss: 0.1988\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1609 - kl_loss: 110.8845 - recon_loss: 0.1609 - val_loss: 0.4375 - val_kl_loss: 114.1896 - val_recon_loss: 0.4375\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1623 - kl_loss: 110.8329 - recon_loss: 0.1623 - val_loss: 0.2251 - val_kl_loss: 115.5442 - val_recon_loss: 0.2251\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1530 - kl_loss: 110.9738 - recon_loss: 0.1530 - val_loss: 0.5401 - val_kl_loss: 114.6139 - val_recon_loss: 0.5401\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1620 - kl_loss: 111.4948 - recon_loss: 0.1620 - val_loss: 0.1741 - val_kl_loss: 117.0638 - val_recon_loss: 0.1741\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1530 - kl_loss: 111.1167 - recon_loss: 0.1530 - val_loss: 0.1400 - val_kl_loss: 116.6577 - val_recon_loss: 0.1400\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1593 - kl_loss: 111.5270 - recon_loss: 0.1593 - val_loss: 0.1660 - val_kl_loss: 118.8336 - val_recon_loss: 0.1660\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.1574 - kl_loss: 111.8512 - recon_loss: 0.1574 - val_loss: 0.2116 - val_kl_loss: 120.6351 - val_recon_loss: 0.2116\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1463 - kl_loss: 112.3025 - recon_loss: 0.1463 - val_loss: 0.3375 - val_kl_loss: 117.4758 - val_recon_loss: 0.3375\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1531 - kl_loss: 112.2383 - recon_loss: 0.1531 - val_loss: 0.4005 - val_kl_loss: 117.8062 - val_recon_loss: 0.4005\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1513 - kl_loss: 112.0225 - recon_loss: 0.1513 - val_loss: 0.1597 - val_kl_loss: 117.0968 - val_recon_loss: 0.1597\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1536 - kl_loss: 111.9324 - recon_loss: 0.1536 - val_loss: 0.3167 - val_kl_loss: 117.1962 - val_recon_loss: 0.3167\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1539 - kl_loss: 112.0084 - recon_loss: 0.1539 - val_loss: 0.1438 - val_kl_loss: 118.5994 - val_recon_loss: 0.1438\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1457 - kl_loss: 111.9086 - recon_loss: 0.1457 - val_loss: 0.1663 - val_kl_loss: 118.3408 - val_recon_loss: 0.1663\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1471 - kl_loss: 111.7186 - recon_loss: 0.1471 - val_loss: 0.2048 - val_kl_loss: 118.9643 - val_recon_loss: 0.2048\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1495 - kl_loss: 111.8048 - recon_loss: 0.1495 - val_loss: 0.1853 - val_kl_loss: 117.0817 - val_recon_loss: 0.1853\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1491 - kl_loss: 111.3673 - recon_loss: 0.1491 - val_loss: 0.1464 - val_kl_loss: 118.6652 - val_recon_loss: 0.1464\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1464 - kl_loss: 111.5155 - recon_loss: 0.1464 - val_loss: 0.2121 - val_kl_loss: 116.7187 - val_recon_loss: 0.2121\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1439 - kl_loss: 111.3942 - recon_loss: 0.1439 - val_loss: 0.1955 - val_kl_loss: 118.7296 - val_recon_loss: 0.1955\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1460 - kl_loss: 111.6957 - recon_loss: 0.1460 - val_loss: 0.1685 - val_kl_loss: 119.3444 - val_recon_loss: 0.1685\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1433 - kl_loss: 111.7975 - recon_loss: 0.1433 - val_loss: 0.2120 - val_kl_loss: 117.5813 - val_recon_loss: 0.2120\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1470 - kl_loss: 112.3338 - recon_loss: 0.1470 - val_loss: 0.2088 - val_kl_loss: 117.9771 - val_recon_loss: 0.2088\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1466 - kl_loss: 112.1349 - recon_loss: 0.1466 - val_loss: 0.1215 - val_kl_loss: 118.5644 - val_recon_loss: 0.1215\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1452 - kl_loss: 112.2090 - recon_loss: 0.1452 - val_loss: 0.1498 - val_kl_loss: 118.8691 - val_recon_loss: 0.1498\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1369 - kl_loss: 112.6961 - recon_loss: 0.1369 - val_loss: 0.1219 - val_kl_loss: 117.6982 - val_recon_loss: 0.1219\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1374 - kl_loss: 112.4512 - recon_loss: 0.1374 - val_loss: 0.1236 - val_kl_loss: 119.0184 - val_recon_loss: 0.1236\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1383 - kl_loss: 112.7217 - recon_loss: 0.1383 - val_loss: 0.2859 - val_kl_loss: 118.5620 - val_recon_loss: 0.2859\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1389 - kl_loss: 112.4245 - recon_loss: 0.1389 - val_loss: 0.1695 - val_kl_loss: 118.8724 - val_recon_loss: 0.1695\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1402 - kl_loss: 112.4981 - recon_loss: 0.1402 - val_loss: 0.3880 - val_kl_loss: 116.7771 - val_recon_loss: 0.3880\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1359 - kl_loss: 112.9616 - recon_loss: 0.1359 - val_loss: 0.1335 - val_kl_loss: 119.5490 - val_recon_loss: 0.1335\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1331 - kl_loss: 113.0338 - recon_loss: 0.1331 - val_loss: 0.1204 - val_kl_loss: 119.3192 - val_recon_loss: 0.1204\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1391 - kl_loss: 113.3340 - recon_loss: 0.1391 - val_loss: 0.2846 - val_kl_loss: 119.8705 - val_recon_loss: 0.2846\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1350 - kl_loss: 113.5668 - recon_loss: 0.1350 - val_loss: 0.1268 - val_kl_loss: 119.0723 - val_recon_loss: 0.1268\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1372 - kl_loss: 113.5734 - recon_loss: 0.1372 - val_loss: 0.1274 - val_kl_loss: 118.1343 - val_recon_loss: 0.1274\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1340 - kl_loss: 113.7466 - recon_loss: 0.1340 - val_loss: 0.1377 - val_kl_loss: 120.2318 - val_recon_loss: 0.1377\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1302 - kl_loss: 114.0271 - recon_loss: 0.1302 - val_loss: 0.1216 - val_kl_loss: 118.8640 - val_recon_loss: 0.1216\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1340 - kl_loss: 113.7325 - recon_loss: 0.1340 - val_loss: 0.2097 - val_kl_loss: 120.2117 - val_recon_loss: 0.2097\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1329 - kl_loss: 113.9401 - recon_loss: 0.1329 - val_loss: 0.3058 - val_kl_loss: 121.7330 - val_recon_loss: 0.3058\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1324 - kl_loss: 113.8620 - recon_loss: 0.1324 - val_loss: 0.1430 - val_kl_loss: 118.4006 - val_recon_loss: 0.1430\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1295 - kl_loss: 113.5678 - recon_loss: 0.1295 - val_loss: 0.2408 - val_kl_loss: 119.2394 - val_recon_loss: 0.2408\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1330 - kl_loss: 113.8637 - recon_loss: 0.1330 - val_loss: 0.1127 - val_kl_loss: 119.6647 - val_recon_loss: 0.1127\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1351 - kl_loss: 114.0740 - recon_loss: 0.1351 - val_loss: 0.1325 - val_kl_loss: 118.2516 - val_recon_loss: 0.1325\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1289 - kl_loss: 114.1095 - recon_loss: 0.1289 - val_loss: 0.1031 - val_kl_loss: 118.8352 - val_recon_loss: 0.1031\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1282 - kl_loss: 114.3246 - recon_loss: 0.1282 - val_loss: 0.3748 - val_kl_loss: 121.2154 - val_recon_loss: 0.3748\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 86us/step - loss: 0.1286 - kl_loss: 114.7297 - recon_loss: 0.1286 - val_loss: 0.1219 - val_kl_loss: 120.5899 - val_recon_loss: 0.1219\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1233 - kl_loss: 115.0077 - recon_loss: 0.1233 - val_loss: 0.1162 - val_kl_loss: 119.9314 - val_recon_loss: 0.1162\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1258 - kl_loss: 114.9181 - recon_loss: 0.1258 - val_loss: 0.1003 - val_kl_loss: 120.6855 - val_recon_loss: 0.1003\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1281 - kl_loss: 114.7466 - recon_loss: 0.1281 - val_loss: 0.1934 - val_kl_loss: 120.8600 - val_recon_loss: 0.1934\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 96us/step - loss: 0.1264 - kl_loss: 114.7041 - recon_loss: 0.1264 - val_loss: 0.1232 - val_kl_loss: 120.9142 - val_recon_loss: 0.1232\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 89us/step - loss: 0.1233 - kl_loss: 114.6730 - recon_loss: 0.1233 - val_loss: 0.0943 - val_kl_loss: 119.3752 - val_recon_loss: 0.0943\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 87us/step - loss: 0.1238 - kl_loss: 115.0286 - recon_loss: 0.1238 - val_loss: 0.1178 - val_kl_loss: 119.9973 - val_recon_loss: 0.1178\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1275 - kl_loss: 115.3483 - recon_loss: 0.1275 - val_loss: 0.1352 - val_kl_loss: 121.1227 - val_recon_loss: 0.1352\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1216 - kl_loss: 115.9390 - recon_loss: 0.1216 - val_loss: 0.1040 - val_kl_loss: 120.7627 - val_recon_loss: 0.1040\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1219 - kl_loss: 115.9630 - recon_loss: 0.1219 - val_loss: 0.2187 - val_kl_loss: 120.1685 - val_recon_loss: 0.2187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1243 - kl_loss: 115.9754 - recon_loss: 0.1243 - val_loss: 0.0977 - val_kl_loss: 121.0609 - val_recon_loss: 0.0977\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1182 - kl_loss: 116.3012 - recon_loss: 0.1182 - val_loss: 0.1917 - val_kl_loss: 121.2812 - val_recon_loss: 0.1917\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1255 - kl_loss: 116.4802 - recon_loss: 0.1255 - val_loss: 0.0898 - val_kl_loss: 121.7452 - val_recon_loss: 0.0898\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1217 - kl_loss: 116.6687 - recon_loss: 0.1217 - val_loss: 0.1043 - val_kl_loss: 121.8610 - val_recon_loss: 0.1043\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1213 - kl_loss: 116.9201 - recon_loss: 0.1213 - val_loss: 0.1280 - val_kl_loss: 123.4264 - val_recon_loss: 0.1280\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1205 - kl_loss: 116.6713 - recon_loss: 0.1205 - val_loss: 0.1714 - val_kl_loss: 121.3252 - val_recon_loss: 0.1714\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1205 - kl_loss: 116.7488 - recon_loss: 0.1205 - val_loss: 0.3795 - val_kl_loss: 124.6769 - val_recon_loss: 0.3795\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1227 - kl_loss: 117.0984 - recon_loss: 0.1227 - val_loss: 0.1011 - val_kl_loss: 121.7488 - val_recon_loss: 0.1011\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1176 - kl_loss: 117.0312 - recon_loss: 0.1176 - val_loss: 0.1242 - val_kl_loss: 120.4479 - val_recon_loss: 0.1242\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1197 - kl_loss: 117.0720 - recon_loss: 0.1197 - val_loss: 0.0915 - val_kl_loss: 121.4327 - val_recon_loss: 0.0915\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1190 - kl_loss: 117.0693 - recon_loss: 0.1190 - val_loss: 0.1188 - val_kl_loss: 122.9067 - val_recon_loss: 0.1188\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1210 - kl_loss: 117.1654 - recon_loss: 0.1210 - val_loss: 0.2087 - val_kl_loss: 120.6065 - val_recon_loss: 0.2087\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1173 - kl_loss: 117.5416 - recon_loss: 0.1173 - val_loss: 0.0956 - val_kl_loss: 122.2245 - val_recon_loss: 0.0956\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1164 - kl_loss: 117.0647 - recon_loss: 0.1164 - val_loss: 0.1348 - val_kl_loss: 122.0188 - val_recon_loss: 0.1348\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1151 - kl_loss: 117.1728 - recon_loss: 0.1151 - val_loss: 0.2190 - val_kl_loss: 124.8747 - val_recon_loss: 0.2190\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1162 - kl_loss: 117.1858 - recon_loss: 0.1162 - val_loss: 0.1196 - val_kl_loss: 122.5338 - val_recon_loss: 0.1196\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1169 - kl_loss: 117.4379 - recon_loss: 0.1169 - val_loss: 0.1770 - val_kl_loss: 121.6091 - val_recon_loss: 0.1770\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1156 - kl_loss: 117.7224 - recon_loss: 0.1156 - val_loss: 0.1900 - val_kl_loss: 121.2687 - val_recon_loss: 0.1900\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1120 - kl_loss: 117.8177 - recon_loss: 0.1120 - val_loss: 0.0777 - val_kl_loss: 122.3468 - val_recon_loss: 0.0777\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1138 - kl_loss: 117.9633 - recon_loss: 0.1138 - val_loss: 0.1770 - val_kl_loss: 119.4430 - val_recon_loss: 0.1770\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1143 - kl_loss: 117.8118 - recon_loss: 0.1143 - val_loss: 0.0907 - val_kl_loss: 122.4405 - val_recon_loss: 0.0907\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1157 - kl_loss: 117.7979 - recon_loss: 0.1157 - val_loss: 0.1436 - val_kl_loss: 122.8929 - val_recon_loss: 0.1436\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1144 - kl_loss: 117.9650 - recon_loss: 0.1144 - val_loss: 0.1681 - val_kl_loss: 121.7661 - val_recon_loss: 0.1681\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1126 - kl_loss: 118.0738 - recon_loss: 0.1126 - val_loss: 0.2019 - val_kl_loss: 121.4897 - val_recon_loss: 0.2019\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1150 - kl_loss: 118.0120 - recon_loss: 0.1150 - val_loss: 0.1545 - val_kl_loss: 124.1792 - val_recon_loss: 0.1545\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1091 - kl_loss: 117.9135 - recon_loss: 0.1091 - val_loss: 0.1908 - val_kl_loss: 124.6080 - val_recon_loss: 0.1908\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1160 - kl_loss: 118.1291 - recon_loss: 0.1160 - val_loss: 0.1704 - val_kl_loss: 121.7841 - val_recon_loss: 0.1704\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1106 - kl_loss: 117.7597 - recon_loss: 0.1106 - val_loss: 0.2070 - val_kl_loss: 124.9847 - val_recon_loss: 0.2070\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1039 - kl_loss: 117.8919 - recon_loss: 0.1039 - val_loss: 0.0783 - val_kl_loss: 123.1490 - val_recon_loss: 0.0783\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1165 - kl_loss: 118.0638 - recon_loss: 0.1165 - val_loss: 0.1066 - val_kl_loss: 123.2514 - val_recon_loss: 0.1066\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1060 - kl_loss: 117.9812 - recon_loss: 0.1060 - val_loss: 0.2157 - val_kl_loss: 121.1633 - val_recon_loss: 0.2157\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1066 - kl_loss: 118.0538 - recon_loss: 0.1066 - val_loss: 0.1266 - val_kl_loss: 122.8697 - val_recon_loss: 0.1266\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1071 - kl_loss: 118.4242 - recon_loss: 0.1071 - val_loss: 0.2707 - val_kl_loss: 123.4241 - val_recon_loss: 0.2707\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1163 - kl_loss: 118.1965 - recon_loss: 0.1163 - val_loss: 0.0904 - val_kl_loss: 122.3965 - val_recon_loss: 0.0904\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1039 - kl_loss: 118.4343 - recon_loss: 0.1039 - val_loss: 0.1104 - val_kl_loss: 122.6373 - val_recon_loss: 0.1104\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1080 - kl_loss: 118.3376 - recon_loss: 0.1080 - val_loss: 0.0822 - val_kl_loss: 123.0331 - val_recon_loss: 0.0822\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1067 - kl_loss: 118.5236 - recon_loss: 0.1067 - val_loss: 0.1570 - val_kl_loss: 124.7362 - val_recon_loss: 0.1570\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1057 - kl_loss: 118.7192 - recon_loss: 0.1057 - val_loss: 0.1130 - val_kl_loss: 123.7692 - val_recon_loss: 0.1130\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1069 - kl_loss: 118.6706 - recon_loss: 0.1069 - val_loss: 0.1185 - val_kl_loss: 123.2819 - val_recon_loss: 0.1185\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1078 - kl_loss: 118.4926 - recon_loss: 0.1078 - val_loss: 0.0762 - val_kl_loss: 122.7778 - val_recon_loss: 0.0762\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1030 - kl_loss: 118.6656 - recon_loss: 0.1030 - val_loss: 0.0984 - val_kl_loss: 123.0040 - val_recon_loss: 0.0984\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1097 - kl_loss: 119.2758 - recon_loss: 0.1097 - val_loss: 0.1620 - val_kl_loss: 125.8525 - val_recon_loss: 0.1620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "1465/1465 [==============================] - 0s 87us/step - loss: 0.1024 - kl_loss: 119.2345 - recon_loss: 0.1024 - val_loss: 0.1296 - val_kl_loss: 124.2345 - val_recon_loss: 0.1296\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1023 - kl_loss: 118.8306 - recon_loss: 0.1023 - val_loss: 0.1133 - val_kl_loss: 123.1522 - val_recon_loss: 0.1133\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1017 - kl_loss: 118.8796 - recon_loss: 0.1017 - val_loss: 0.0816 - val_kl_loss: 122.7665 - val_recon_loss: 0.0816\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 86us/step - loss: 0.1082 - kl_loss: 119.0248 - recon_loss: 0.1082 - val_loss: 0.0738 - val_kl_loss: 123.1481 - val_recon_loss: 0.0738\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1021 - kl_loss: 119.1535 - recon_loss: 0.1021 - val_loss: 0.1176 - val_kl_loss: 122.8229 - val_recon_loss: 0.1176\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1001 - kl_loss: 119.1400 - recon_loss: 0.1001 - val_loss: 0.0859 - val_kl_loss: 123.1042 - val_recon_loss: 0.0859\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1060 - kl_loss: 118.6401 - recon_loss: 0.1060 - val_loss: 0.1265 - val_kl_loss: 123.6317 - val_recon_loss: 0.1265\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1055 - kl_loss: 118.8376 - recon_loss: 0.1055 - val_loss: 0.1168 - val_kl_loss: 123.2691 - val_recon_loss: 0.1168\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1011 - kl_loss: 118.5609 - recon_loss: 0.1011 - val_loss: 0.1183 - val_kl_loss: 123.0624 - val_recon_loss: 0.1183\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1025 - kl_loss: 118.5596 - recon_loss: 0.1025 - val_loss: 0.0934 - val_kl_loss: 123.6750 - val_recon_loss: 0.0934\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 86us/step - loss: 0.1012 - kl_loss: 119.0541 - recon_loss: 0.1012 - val_loss: 0.1043 - val_kl_loss: 123.0031 - val_recon_loss: 0.1043\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1011 - kl_loss: 118.9914 - recon_loss: 0.1011 - val_loss: 0.2086 - val_kl_loss: 124.2670 - val_recon_loss: 0.2086\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1052 - kl_loss: 119.1249 - recon_loss: 0.1052 - val_loss: 0.1484 - val_kl_loss: 121.4369 - val_recon_loss: 0.1484\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.0999 - kl_loss: 118.8156 - recon_loss: 0.0999 - val_loss: 0.1187 - val_kl_loss: 123.4232 - val_recon_loss: 0.1187\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0987 - kl_loss: 118.8864 - recon_loss: 0.0987 - val_loss: 0.2324 - val_kl_loss: 123.6434 - val_recon_loss: 0.2324\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1015 - kl_loss: 118.9413 - recon_loss: 0.1015 - val_loss: 0.0906 - val_kl_loss: 124.0532 - val_recon_loss: 0.0906\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1010 - kl_loss: 118.8905 - recon_loss: 0.1010 - val_loss: 0.1304 - val_kl_loss: 123.8667 - val_recon_loss: 0.1304\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.0997 - kl_loss: 119.1827 - recon_loss: 0.0997 - val_loss: 0.4723 - val_kl_loss: 126.5083 - val_recon_loss: 0.4723\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1032 - kl_loss: 119.6903 - recon_loss: 0.1032 - val_loss: 0.0920 - val_kl_loss: 123.9945 - val_recon_loss: 0.0920\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0991 - kl_loss: 119.6814 - recon_loss: 0.0991 - val_loss: 0.0825 - val_kl_loss: 123.5691 - val_recon_loss: 0.0825\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 96us/step - loss: 0.0986 - kl_loss: 119.7930 - recon_loss: 0.0986 - val_loss: 0.1506 - val_kl_loss: 122.7006 - val_recon_loss: 0.1506\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 108us/step - loss: 0.0973 - kl_loss: 120.2047 - recon_loss: 0.0973 - val_loss: 0.1634 - val_kl_loss: 125.4954 - val_recon_loss: 0.1634\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 86us/step - loss: 0.0982 - kl_loss: 120.2219 - recon_loss: 0.0982 - val_loss: 0.0921 - val_kl_loss: 123.7250 - val_recon_loss: 0.0921\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 88us/step - loss: 0.0950 - kl_loss: 120.4560 - recon_loss: 0.0950 - val_loss: 0.1013 - val_kl_loss: 124.7180 - val_recon_loss: 0.1013\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0972 - kl_loss: 120.4835 - recon_loss: 0.0972 - val_loss: 0.2771 - val_kl_loss: 122.7086 - val_recon_loss: 0.2771\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.0967 - kl_loss: 119.7854 - recon_loss: 0.0967 - val_loss: 0.0963 - val_kl_loss: 125.3831 - val_recon_loss: 0.0963\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0924 - kl_loss: 120.5065 - recon_loss: 0.0924 - val_loss: 0.1761 - val_kl_loss: 126.7602 - val_recon_loss: 0.1761\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0981 - kl_loss: 121.0146 - recon_loss: 0.0981 - val_loss: 0.0716 - val_kl_loss: 125.0851 - val_recon_loss: 0.0716\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.0974 - kl_loss: 120.8077 - recon_loss: 0.0974 - val_loss: 0.1234 - val_kl_loss: 125.8983 - val_recon_loss: 0.1234\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1006 - kl_loss: 120.7792 - recon_loss: 0.1006 - val_loss: 0.1186 - val_kl_loss: 124.2382 - val_recon_loss: 0.1186\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0908 - kl_loss: 121.1682 - recon_loss: 0.0908 - val_loss: 0.0710 - val_kl_loss: 125.2739 - val_recon_loss: 0.0710\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1013 - kl_loss: 121.2716 - recon_loss: 0.1013 - val_loss: 0.1011 - val_kl_loss: 124.2215 - val_recon_loss: 0.1011\n",
      "========================= Model10=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 10), (None,  2120        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 10)           0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1836        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,054\n",
      "Trainable params: 4,054\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 10)           130         enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 10)           130         enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,120\n",
      "Trainable params: 2,120\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 26)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           324         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,836\n",
      "Trainable params: 1,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 133us/step - loss: 27.9608 - kl_loss: 19.6681 - recon_loss: 27.9608 - val_loss: 9.0831 - val_kl_loss: 45.9606 - val_recon_loss: 9.0831\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 4.1442 - kl_loss: 47.9650 - recon_loss: 4.1442 - val_loss: 2.7985 - val_kl_loss: 62.6158 - val_recon_loss: 2.7985\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 2.0216 - kl_loss: 65.0485 - recon_loss: 2.0216 - val_loss: 1.5075 - val_kl_loss: 78.2478 - val_recon_loss: 1.5075\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 1.2879 - kl_loss: 79.4605 - recon_loss: 1.2879 - val_loss: 1.2518 - val_kl_loss: 91.1325 - val_recon_loss: 1.2518\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 1.0127 - kl_loss: 90.9646 - recon_loss: 1.0127 - val_loss: 0.8781 - val_kl_loss: 102.3764 - val_recon_loss: 0.8781\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.8689 - kl_loss: 100.5889 - recon_loss: 0.8689 - val_loss: 0.7917 - val_kl_loss: 113.0560 - val_recon_loss: 0.7917\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.7642 - kl_loss: 107.2447 - recon_loss: 0.7642 - val_loss: 0.7264 - val_kl_loss: 118.7150 - val_recon_loss: 0.7264\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.6959 - kl_loss: 111.9930 - recon_loss: 0.6959 - val_loss: 0.7900 - val_kl_loss: 122.4254 - val_recon_loss: 0.7900\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.6239 - kl_loss: 116.4211 - recon_loss: 0.6239 - val_loss: 0.5583 - val_kl_loss: 125.6549 - val_recon_loss: 0.5583\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.5553 - kl_loss: 119.0517 - recon_loss: 0.5553 - val_loss: 0.5601 - val_kl_loss: 129.1812 - val_recon_loss: 0.5601\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.5004 - kl_loss: 122.3137 - recon_loss: 0.5004 - val_loss: 0.4776 - val_kl_loss: 132.3577 - val_recon_loss: 0.4776\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.4599 - kl_loss: 125.4408 - recon_loss: 0.4599 - val_loss: 0.5843 - val_kl_loss: 136.9280 - val_recon_loss: 0.5843\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.4111 - kl_loss: 127.9055 - recon_loss: 0.4111 - val_loss: 0.4729 - val_kl_loss: 135.2601 - val_recon_loss: 0.4729\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.3916 - kl_loss: 130.0831 - recon_loss: 0.3916 - val_loss: 0.4493 - val_kl_loss: 141.0222 - val_recon_loss: 0.4493\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.3610 - kl_loss: 131.9744 - recon_loss: 0.3610 - val_loss: 0.4569 - val_kl_loss: 139.8712 - val_recon_loss: 0.4569\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.3494 - kl_loss: 133.2801 - recon_loss: 0.3494 - val_loss: 0.3408 - val_kl_loss: 142.8338 - val_recon_loss: 0.3408\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.3315 - kl_loss: 134.5262 - recon_loss: 0.3315 - val_loss: 0.5878 - val_kl_loss: 143.5904 - val_recon_loss: 0.5878\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3207 - kl_loss: 135.9141 - recon_loss: 0.3207 - val_loss: 0.3044 - val_kl_loss: 145.2905 - val_recon_loss: 0.3044\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2983 - kl_loss: 137.1449 - recon_loss: 0.2983 - val_loss: 0.3614 - val_kl_loss: 146.7264 - val_recon_loss: 0.3614\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2934 - kl_loss: 138.1490 - recon_loss: 0.2934 - val_loss: 0.4738 - val_kl_loss: 147.1070 - val_recon_loss: 0.4738\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2830 - kl_loss: 138.8157 - recon_loss: 0.2830 - val_loss: 0.3177 - val_kl_loss: 146.6078 - val_recon_loss: 0.3177\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2743 - kl_loss: 139.1460 - recon_loss: 0.2743 - val_loss: 0.2627 - val_kl_loss: 145.1313 - val_recon_loss: 0.2627\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2634 - kl_loss: 139.3931 - recon_loss: 0.2634 - val_loss: 0.4627 - val_kl_loss: 145.3649 - val_recon_loss: 0.4627\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2598 - kl_loss: 140.1460 - recon_loss: 0.2598 - val_loss: 0.2220 - val_kl_loss: 146.8931 - val_recon_loss: 0.2220\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.2548 - kl_loss: 140.2927 - recon_loss: 0.2548 - val_loss: 0.3103 - val_kl_loss: 146.4524 - val_recon_loss: 0.3103\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2552 - kl_loss: 140.5595 - recon_loss: 0.2552 - val_loss: 0.2418 - val_kl_loss: 146.9804 - val_recon_loss: 0.2418\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2437 - kl_loss: 140.8425 - recon_loss: 0.2437 - val_loss: 0.2144 - val_kl_loss: 147.7832 - val_recon_loss: 0.2144\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2444 - kl_loss: 141.1068 - recon_loss: 0.2444 - val_loss: 0.1880 - val_kl_loss: 148.2783 - val_recon_loss: 0.1880\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2451 - kl_loss: 141.4153 - recon_loss: 0.2451 - val_loss: 0.2252 - val_kl_loss: 146.2569 - val_recon_loss: 0.2252\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2391 - kl_loss: 141.3983 - recon_loss: 0.2391 - val_loss: 0.2563 - val_kl_loss: 146.6716 - val_recon_loss: 0.2563\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 87us/step - loss: 0.2311 - kl_loss: 141.8617 - recon_loss: 0.2311 - val_loss: 0.4141 - val_kl_loss: 151.0186 - val_recon_loss: 0.4141\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.2322 - kl_loss: 142.0984 - recon_loss: 0.2322 - val_loss: 0.1790 - val_kl_loss: 148.9925 - val_recon_loss: 0.1790\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2259 - kl_loss: 141.8141 - recon_loss: 0.2259 - val_loss: 0.2563 - val_kl_loss: 148.4624 - val_recon_loss: 0.2563\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2299 - kl_loss: 142.1522 - recon_loss: 0.2299 - val_loss: 0.1851 - val_kl_loss: 149.1311 - val_recon_loss: 0.1851\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.2204 - kl_loss: 142.6358 - recon_loss: 0.2204 - val_loss: 0.2990 - val_kl_loss: 147.5977 - val_recon_loss: 0.2990\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2252 - kl_loss: 142.4383 - recon_loss: 0.2252 - val_loss: 0.2508 - val_kl_loss: 146.4625 - val_recon_loss: 0.2508\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.2109 - kl_loss: 142.4817 - recon_loss: 0.2109 - val_loss: 0.3862 - val_kl_loss: 148.7272 - val_recon_loss: 0.3862\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2202 - kl_loss: 142.5310 - recon_loss: 0.2202 - val_loss: 0.2055 - val_kl_loss: 147.9669 - val_recon_loss: 0.2055\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2160 - kl_loss: 142.8189 - recon_loss: 0.2160 - val_loss: 0.1854 - val_kl_loss: 148.6404 - val_recon_loss: 0.1854\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2080 - kl_loss: 143.3925 - recon_loss: 0.2080 - val_loss: 0.1733 - val_kl_loss: 150.6805 - val_recon_loss: 0.1733\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2066 - kl_loss: 143.6425 - recon_loss: 0.2066 - val_loss: 0.2918 - val_kl_loss: 150.3295 - val_recon_loss: 0.2918\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2070 - kl_loss: 143.6072 - recon_loss: 0.2070 - val_loss: 0.4283 - val_kl_loss: 150.3091 - val_recon_loss: 0.4283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2015 - kl_loss: 143.7712 - recon_loss: 0.2015 - val_loss: 0.1929 - val_kl_loss: 150.7130 - val_recon_loss: 0.1929\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2068 - kl_loss: 144.1770 - recon_loss: 0.2068 - val_loss: 0.2422 - val_kl_loss: 151.1918 - val_recon_loss: 0.2422\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2016 - kl_loss: 144.4967 - recon_loss: 0.2016 - val_loss: 0.3586 - val_kl_loss: 151.7973 - val_recon_loss: 0.3586\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2018 - kl_loss: 145.0020 - recon_loss: 0.2018 - val_loss: 0.1760 - val_kl_loss: 151.2821 - val_recon_loss: 0.1760\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.1973 - kl_loss: 145.1399 - recon_loss: 0.1973 - val_loss: 0.2579 - val_kl_loss: 150.0439 - val_recon_loss: 0.2579\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1990 - kl_loss: 145.0586 - recon_loss: 0.1990 - val_loss: 0.3495 - val_kl_loss: 148.5920 - val_recon_loss: 0.3495\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1968 - kl_loss: 144.6697 - recon_loss: 0.1968 - val_loss: 0.2567 - val_kl_loss: 148.0188 - val_recon_loss: 0.2567\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1954 - kl_loss: 144.5696 - recon_loss: 0.1954 - val_loss: 0.3884 - val_kl_loss: 150.8912 - val_recon_loss: 0.3884\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1916 - kl_loss: 144.2917 - recon_loss: 0.1916 - val_loss: 0.1865 - val_kl_loss: 150.1062 - val_recon_loss: 0.1865\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1903 - kl_loss: 144.3109 - recon_loss: 0.1903 - val_loss: 0.1432 - val_kl_loss: 149.7768 - val_recon_loss: 0.1432\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1884 - kl_loss: 144.6080 - recon_loss: 0.1884 - val_loss: 0.2139 - val_kl_loss: 150.3333 - val_recon_loss: 0.2139\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1908 - kl_loss: 144.9442 - recon_loss: 0.1908 - val_loss: 0.1570 - val_kl_loss: 152.0876 - val_recon_loss: 0.1570\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1857 - kl_loss: 145.2065 - recon_loss: 0.1857 - val_loss: 0.1468 - val_kl_loss: 151.1182 - val_recon_loss: 0.1468\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1834 - kl_loss: 145.3251 - recon_loss: 0.1834 - val_loss: 0.2670 - val_kl_loss: 151.9182 - val_recon_loss: 0.2670\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1916 - kl_loss: 145.3076 - recon_loss: 0.1916 - val_loss: 0.3372 - val_kl_loss: 154.8937 - val_recon_loss: 0.3372\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1818 - kl_loss: 145.6814 - recon_loss: 0.1818 - val_loss: 0.3276 - val_kl_loss: 152.4876 - val_recon_loss: 0.3276\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1797 - kl_loss: 145.7668 - recon_loss: 0.1797 - val_loss: 0.2434 - val_kl_loss: 149.5669 - val_recon_loss: 0.2434\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1813 - kl_loss: 145.4676 - recon_loss: 0.1813 - val_loss: 0.2046 - val_kl_loss: 152.5047 - val_recon_loss: 0.2046\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1793 - kl_loss: 145.8987 - recon_loss: 0.1793 - val_loss: 0.1561 - val_kl_loss: 151.9019 - val_recon_loss: 0.1561\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1800 - kl_loss: 146.0983 - recon_loss: 0.1800 - val_loss: 0.1981 - val_kl_loss: 153.1060 - val_recon_loss: 0.1981\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1728 - kl_loss: 146.0592 - recon_loss: 0.1728 - val_loss: 0.3061 - val_kl_loss: 153.6494 - val_recon_loss: 0.3061\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1770 - kl_loss: 145.6041 - recon_loss: 0.1770 - val_loss: 0.1975 - val_kl_loss: 151.4994 - val_recon_loss: 0.1975\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1763 - kl_loss: 145.5868 - recon_loss: 0.1763 - val_loss: 0.1909 - val_kl_loss: 150.1007 - val_recon_loss: 0.1909\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1707 - kl_loss: 145.4889 - recon_loss: 0.1707 - val_loss: 0.1847 - val_kl_loss: 150.8608 - val_recon_loss: 0.1847\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1716 - kl_loss: 145.1753 - recon_loss: 0.1716 - val_loss: 0.1246 - val_kl_loss: 150.5026 - val_recon_loss: 0.1246\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1651 - kl_loss: 144.5122 - recon_loss: 0.1651 - val_loss: 0.1935 - val_kl_loss: 149.1642 - val_recon_loss: 0.1935\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1678 - kl_loss: 144.6385 - recon_loss: 0.1678 - val_loss: 0.5224 - val_kl_loss: 149.9400 - val_recon_loss: 0.5224\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1685 - kl_loss: 144.5821 - recon_loss: 0.1685 - val_loss: 0.1178 - val_kl_loss: 150.0606 - val_recon_loss: 0.1178\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 111us/step - loss: 0.1572 - kl_loss: 144.5877 - recon_loss: 0.1572 - val_loss: 0.1846 - val_kl_loss: 150.2667 - val_recon_loss: 0.1846\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 99us/step - loss: 0.1587 - kl_loss: 144.4172 - recon_loss: 0.1587 - val_loss: 0.1371 - val_kl_loss: 149.2603 - val_recon_loss: 0.1371\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1560 - kl_loss: 144.0070 - recon_loss: 0.1560 - val_loss: 0.1128 - val_kl_loss: 149.8857 - val_recon_loss: 0.1128\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1578 - kl_loss: 144.0297 - recon_loss: 0.1578 - val_loss: 0.1905 - val_kl_loss: 150.1894 - val_recon_loss: 0.1905\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1474 - kl_loss: 143.9782 - recon_loss: 0.1474 - val_loss: 0.4291 - val_kl_loss: 147.8967 - val_recon_loss: 0.4291\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1543 - kl_loss: 143.9896 - recon_loss: 0.1543 - val_loss: 0.2900 - val_kl_loss: 145.8099 - val_recon_loss: 0.2900\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1494 - kl_loss: 144.2887 - recon_loss: 0.1494 - val_loss: 0.1537 - val_kl_loss: 148.8653 - val_recon_loss: 0.1537\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1496 - kl_loss: 144.2666 - recon_loss: 0.1496 - val_loss: 0.1317 - val_kl_loss: 149.1178 - val_recon_loss: 0.1317\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1506 - kl_loss: 144.4461 - recon_loss: 0.1506 - val_loss: 0.1403 - val_kl_loss: 150.2458 - val_recon_loss: 0.1403\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1440 - kl_loss: 144.7521 - recon_loss: 0.1440 - val_loss: 0.1123 - val_kl_loss: 150.5221 - val_recon_loss: 0.1123\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1428 - kl_loss: 144.5064 - recon_loss: 0.1428 - val_loss: 0.1330 - val_kl_loss: 150.1024 - val_recon_loss: 0.1330\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1461 - kl_loss: 144.3481 - recon_loss: 0.1461 - val_loss: 0.1174 - val_kl_loss: 148.8079 - val_recon_loss: 0.1174\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1422 - kl_loss: 144.6883 - recon_loss: 0.1422 - val_loss: 0.1271 - val_kl_loss: 150.4814 - val_recon_loss: 0.1271\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1441 - kl_loss: 144.9395 - recon_loss: 0.1441 - val_loss: 0.1837 - val_kl_loss: 149.7218 - val_recon_loss: 0.1837\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1427 - kl_loss: 144.9394 - recon_loss: 0.1427 - val_loss: 0.1680 - val_kl_loss: 150.0609 - val_recon_loss: 0.1680\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1358 - kl_loss: 144.8196 - recon_loss: 0.1358 - val_loss: 0.1096 - val_kl_loss: 150.1888 - val_recon_loss: 0.1096\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1470 - kl_loss: 145.2725 - recon_loss: 0.1470 - val_loss: 0.0941 - val_kl_loss: 150.8092 - val_recon_loss: 0.0941\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1298 - kl_loss: 145.5265 - recon_loss: 0.1298 - val_loss: 0.1210 - val_kl_loss: 150.8220 - val_recon_loss: 0.1210\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1370 - kl_loss: 145.7585 - recon_loss: 0.1370 - val_loss: 0.1572 - val_kl_loss: 151.9529 - val_recon_loss: 0.1572\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1368 - kl_loss: 146.0087 - recon_loss: 0.1368 - val_loss: 0.1284 - val_kl_loss: 150.8591 - val_recon_loss: 0.1284\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1343 - kl_loss: 146.3335 - recon_loss: 0.1343 - val_loss: 0.2635 - val_kl_loss: 151.5891 - val_recon_loss: 0.2635\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1367 - kl_loss: 146.5648 - recon_loss: 0.1367 - val_loss: 0.2044 - val_kl_loss: 151.6525 - val_recon_loss: 0.2044\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1308 - kl_loss: 146.5280 - recon_loss: 0.1308 - val_loss: 0.2555 - val_kl_loss: 150.9717 - val_recon_loss: 0.2555\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1366 - kl_loss: 146.3664 - recon_loss: 0.1366 - val_loss: 0.1221 - val_kl_loss: 149.8984 - val_recon_loss: 0.1221\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1332 - kl_loss: 146.2798 - recon_loss: 0.1332 - val_loss: 0.1766 - val_kl_loss: 151.9770 - val_recon_loss: 0.1766\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1300 - kl_loss: 146.5893 - recon_loss: 0.1300 - val_loss: 0.2995 - val_kl_loss: 153.2967 - val_recon_loss: 0.2995\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1298 - kl_loss: 147.0481 - recon_loss: 0.1298 - val_loss: 0.0924 - val_kl_loss: 152.8720 - val_recon_loss: 0.0924\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1278 - kl_loss: 147.1836 - recon_loss: 0.1278 - val_loss: 0.0942 - val_kl_loss: 152.6264 - val_recon_loss: 0.0942\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1342 - kl_loss: 147.0765 - recon_loss: 0.1342 - val_loss: 0.0940 - val_kl_loss: 153.2732 - val_recon_loss: 0.0940\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1262 - kl_loss: 146.9642 - recon_loss: 0.1262 - val_loss: 0.1294 - val_kl_loss: 150.6011 - val_recon_loss: 0.1294\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1300 - kl_loss: 146.9925 - recon_loss: 0.1300 - val_loss: 0.2097 - val_kl_loss: 152.6459 - val_recon_loss: 0.2097\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1268 - kl_loss: 146.5713 - recon_loss: 0.1268 - val_loss: 0.1152 - val_kl_loss: 152.1387 - val_recon_loss: 0.1152\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1321 - kl_loss: 147.1830 - recon_loss: 0.1321 - val_loss: 0.1296 - val_kl_loss: 152.9061 - val_recon_loss: 0.1296\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1245 - kl_loss: 147.5004 - recon_loss: 0.1245 - val_loss: 0.0915 - val_kl_loss: 152.9359 - val_recon_loss: 0.0915\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1249 - kl_loss: 147.7072 - recon_loss: 0.1249 - val_loss: 0.2030 - val_kl_loss: 152.6716 - val_recon_loss: 0.2030\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 66us/step - loss: 0.1256 - kl_loss: 147.9391 - recon_loss: 0.1256 - val_loss: 0.0875 - val_kl_loss: 153.0623 - val_recon_loss: 0.0875\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1241 - kl_loss: 148.0522 - recon_loss: 0.1241 - val_loss: 0.2413 - val_kl_loss: 152.3785 - val_recon_loss: 0.2413\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1208 - kl_loss: 148.2963 - recon_loss: 0.1208 - val_loss: 0.1447 - val_kl_loss: 152.2731 - val_recon_loss: 0.1447\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1256 - kl_loss: 148.4691 - recon_loss: 0.1256 - val_loss: 0.1219 - val_kl_loss: 153.9122 - val_recon_loss: 0.1219\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1243 - kl_loss: 148.3569 - recon_loss: 0.1243 - val_loss: 0.1588 - val_kl_loss: 151.6355 - val_recon_loss: 0.1588\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1200 - kl_loss: 148.3302 - recon_loss: 0.1200 - val_loss: 0.0992 - val_kl_loss: 153.1826 - val_recon_loss: 0.0992\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1237 - kl_loss: 148.5284 - recon_loss: 0.1237 - val_loss: 0.1196 - val_kl_loss: 151.9591 - val_recon_loss: 0.1196\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1146 - kl_loss: 148.7555 - recon_loss: 0.1146 - val_loss: 0.1313 - val_kl_loss: 153.9850 - val_recon_loss: 0.1313\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1182 - kl_loss: 148.6031 - recon_loss: 0.1182 - val_loss: 0.2099 - val_kl_loss: 152.1221 - val_recon_loss: 0.2099\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1213 - kl_loss: 148.3677 - recon_loss: 0.1213 - val_loss: 0.1071 - val_kl_loss: 152.5118 - val_recon_loss: 0.1071\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1172 - kl_loss: 148.3197 - recon_loss: 0.1172 - val_loss: 0.1461 - val_kl_loss: 153.6977 - val_recon_loss: 0.1461\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1176 - kl_loss: 148.3602 - recon_loss: 0.1176 - val_loss: 0.2957 - val_kl_loss: 151.8277 - val_recon_loss: 0.2957\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.1172 - kl_loss: 148.5100 - recon_loss: 0.1172 - val_loss: 0.2251 - val_kl_loss: 155.6709 - val_recon_loss: 0.2251\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1244 - kl_loss: 149.2254 - recon_loss: 0.1244 - val_loss: 0.1014 - val_kl_loss: 153.0967 - val_recon_loss: 0.1014\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1129 - kl_loss: 148.8450 - recon_loss: 0.1129 - val_loss: 0.1409 - val_kl_loss: 153.3964 - val_recon_loss: 0.1409\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1161 - kl_loss: 148.7759 - recon_loss: 0.1161 - val_loss: 0.5081 - val_kl_loss: 155.5172 - val_recon_loss: 0.5081\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1173 - kl_loss: 148.7071 - recon_loss: 0.1173 - val_loss: 0.1078 - val_kl_loss: 152.3258 - val_recon_loss: 0.1078\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1118 - kl_loss: 148.6156 - recon_loss: 0.1118 - val_loss: 0.1226 - val_kl_loss: 152.0921 - val_recon_loss: 0.1226\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 62us/step - loss: 0.1153 - kl_loss: 148.4529 - recon_loss: 0.1153 - val_loss: 0.1520 - val_kl_loss: 151.9637 - val_recon_loss: 0.1520\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 63us/step - loss: 0.1166 - kl_loss: 148.5213 - recon_loss: 0.1166 - val_loss: 0.1177 - val_kl_loss: 152.8635 - val_recon_loss: 0.1177\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1111 - kl_loss: 148.9043 - recon_loss: 0.1111 - val_loss: 0.1059 - val_kl_loss: 154.1407 - val_recon_loss: 0.1059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1163 - kl_loss: 148.5602 - recon_loss: 0.1163 - val_loss: 0.1741 - val_kl_loss: 155.8168 - val_recon_loss: 0.1741\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.1129 - kl_loss: 149.1169 - recon_loss: 0.1129 - val_loss: 0.1541 - val_kl_loss: 153.8975 - val_recon_loss: 0.1541\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1126 - kl_loss: 149.0329 - recon_loss: 0.1126 - val_loss: 0.1063 - val_kl_loss: 152.9585 - val_recon_loss: 0.1063\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1144 - kl_loss: 149.2885 - recon_loss: 0.1144 - val_loss: 0.1422 - val_kl_loss: 155.3238 - val_recon_loss: 0.1422\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1104 - kl_loss: 149.5164 - recon_loss: 0.1104 - val_loss: 0.2160 - val_kl_loss: 153.0184 - val_recon_loss: 0.2160\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1149 - kl_loss: 148.9410 - recon_loss: 0.1149 - val_loss: 0.0979 - val_kl_loss: 152.9589 - val_recon_loss: 0.0979\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1107 - kl_loss: 148.8499 - recon_loss: 0.1107 - val_loss: 0.1082 - val_kl_loss: 153.7210 - val_recon_loss: 0.1082\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1126 - kl_loss: 149.1027 - recon_loss: 0.1126 - val_loss: 0.0999 - val_kl_loss: 153.1127 - val_recon_loss: 0.0999\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.1095 - kl_loss: 148.9467 - recon_loss: 0.1095 - val_loss: 0.1159 - val_kl_loss: 153.4720 - val_recon_loss: 0.1159\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1121 - kl_loss: 148.9892 - recon_loss: 0.1121 - val_loss: 0.1800 - val_kl_loss: 153.1501 - val_recon_loss: 0.1800\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1109 - kl_loss: 149.0312 - recon_loss: 0.1109 - val_loss: 0.1122 - val_kl_loss: 152.7887 - val_recon_loss: 0.1122\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1086 - kl_loss: 149.2746 - recon_loss: 0.1086 - val_loss: 0.3255 - val_kl_loss: 152.0624 - val_recon_loss: 0.3255\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1080 - kl_loss: 149.4518 - recon_loss: 0.1080 - val_loss: 0.0989 - val_kl_loss: 154.1520 - val_recon_loss: 0.0989\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1092 - kl_loss: 149.1658 - recon_loss: 0.1092 - val_loss: 0.2970 - val_kl_loss: 152.0587 - val_recon_loss: 0.2970\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1090 - kl_loss: 148.9506 - recon_loss: 0.1090 - val_loss: 0.1532 - val_kl_loss: 154.1877 - val_recon_loss: 0.1532\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1105 - kl_loss: 148.7065 - recon_loss: 0.1105 - val_loss: 0.2055 - val_kl_loss: 152.5865 - val_recon_loss: 0.2055\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1066 - kl_loss: 148.1607 - recon_loss: 0.1066 - val_loss: 0.1485 - val_kl_loss: 153.9896 - val_recon_loss: 0.1485\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1070 - kl_loss: 148.0624 - recon_loss: 0.1070 - val_loss: 0.2353 - val_kl_loss: 150.1393 - val_recon_loss: 0.2353\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1090 - kl_loss: 147.9520 - recon_loss: 0.1090 - val_loss: 0.0815 - val_kl_loss: 152.3697 - val_recon_loss: 0.0815\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1059 - kl_loss: 148.0917 - recon_loss: 0.1059 - val_loss: 0.1716 - val_kl_loss: 150.9502 - val_recon_loss: 0.1716\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1099 - kl_loss: 147.7155 - recon_loss: 0.1099 - val_loss: 0.0695 - val_kl_loss: 152.5629 - val_recon_loss: 0.0695\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1039 - kl_loss: 148.1054 - recon_loss: 0.1039 - val_loss: 0.0906 - val_kl_loss: 152.5179 - val_recon_loss: 0.0906\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1055 - kl_loss: 147.9677 - recon_loss: 0.1055 - val_loss: 0.1145 - val_kl_loss: 152.5275 - val_recon_loss: 0.1145\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1116 - kl_loss: 148.0588 - recon_loss: 0.1116 - val_loss: 0.2117 - val_kl_loss: 154.1103 - val_recon_loss: 0.2117\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1004 - kl_loss: 149.1328 - recon_loss: 0.1004 - val_loss: 0.0705 - val_kl_loss: 154.3670 - val_recon_loss: 0.0705\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1056 - kl_loss: 149.0186 - recon_loss: 0.1056 - val_loss: 0.0922 - val_kl_loss: 153.5216 - val_recon_loss: 0.0922\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1007 - kl_loss: 148.9711 - recon_loss: 0.1007 - val_loss: 0.0774 - val_kl_loss: 154.5931 - val_recon_loss: 0.0774\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1044 - kl_loss: 149.4048 - recon_loss: 0.1044 - val_loss: 0.0941 - val_kl_loss: 154.3405 - val_recon_loss: 0.0941\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1078 - kl_loss: 149.1580 - recon_loss: 0.1078 - val_loss: 0.1122 - val_kl_loss: 154.5262 - val_recon_loss: 0.1122\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1044 - kl_loss: 149.4917 - recon_loss: 0.1044 - val_loss: 0.1324 - val_kl_loss: 154.0730 - val_recon_loss: 0.1324\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1029 - kl_loss: 149.3677 - recon_loss: 0.1029 - val_loss: 0.1520 - val_kl_loss: 153.2363 - val_recon_loss: 0.1520\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1016 - kl_loss: 149.8059 - recon_loss: 0.1016 - val_loss: 0.1707 - val_kl_loss: 154.8411 - val_recon_loss: 0.1707\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0992 - kl_loss: 149.6951 - recon_loss: 0.0992 - val_loss: 0.2591 - val_kl_loss: 155.3267 - val_recon_loss: 0.2591\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1055 - kl_loss: 149.6221 - recon_loss: 0.1055 - val_loss: 0.1695 - val_kl_loss: 156.0134 - val_recon_loss: 0.1695\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0992 - kl_loss: 150.0968 - recon_loss: 0.0992 - val_loss: 0.5483 - val_kl_loss: 151.1599 - val_recon_loss: 0.5483\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1033 - kl_loss: 150.2045 - recon_loss: 0.1033 - val_loss: 0.1219 - val_kl_loss: 157.0911 - val_recon_loss: 0.1219\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0978 - kl_loss: 150.7963 - recon_loss: 0.0978 - val_loss: 0.1496 - val_kl_loss: 155.4971 - val_recon_loss: 0.1496\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1024 - kl_loss: 150.5649 - recon_loss: 0.1024 - val_loss: 0.0989 - val_kl_loss: 154.6358 - val_recon_loss: 0.0989\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1000 - kl_loss: 150.9302 - recon_loss: 0.1000 - val_loss: 0.1642 - val_kl_loss: 154.6039 - val_recon_loss: 0.1642\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1078 - kl_loss: 150.7210 - recon_loss: 0.1078 - val_loss: 0.0897 - val_kl_loss: 156.4170 - val_recon_loss: 0.0897\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0943 - kl_loss: 151.2291 - recon_loss: 0.0943 - val_loss: 0.1413 - val_kl_loss: 156.7356 - val_recon_loss: 0.1413\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0958 - kl_loss: 151.2807 - recon_loss: 0.0958 - val_loss: 0.1168 - val_kl_loss: 157.3840 - val_recon_loss: 0.1168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0988 - kl_loss: 151.3726 - recon_loss: 0.0988 - val_loss: 0.1737 - val_kl_loss: 158.3194 - val_recon_loss: 0.1737\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0977 - kl_loss: 151.2507 - recon_loss: 0.0977 - val_loss: 0.3484 - val_kl_loss: 154.5886 - val_recon_loss: 0.3484\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0983 - kl_loss: 151.0165 - recon_loss: 0.0983 - val_loss: 0.1957 - val_kl_loss: 157.6191 - val_recon_loss: 0.1957\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0996 - kl_loss: 150.9866 - recon_loss: 0.0996 - val_loss: 0.0761 - val_kl_loss: 155.6221 - val_recon_loss: 0.0761\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0980 - kl_loss: 150.5337 - recon_loss: 0.0980 - val_loss: 0.1406 - val_kl_loss: 155.5785 - val_recon_loss: 0.1406\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1014 - kl_loss: 151.0045 - recon_loss: 0.1014 - val_loss: 0.0831 - val_kl_loss: 157.0404 - val_recon_loss: 0.0831\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0950 - kl_loss: 151.6606 - recon_loss: 0.0950 - val_loss: 0.1876 - val_kl_loss: 157.3753 - val_recon_loss: 0.1876\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0998 - kl_loss: 151.3370 - recon_loss: 0.0998 - val_loss: 0.1226 - val_kl_loss: 156.2255 - val_recon_loss: 0.1226\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0932 - kl_loss: 151.5681 - recon_loss: 0.0932 - val_loss: 0.1000 - val_kl_loss: 155.2485 - val_recon_loss: 0.1000\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0970 - kl_loss: 151.5624 - recon_loss: 0.0970 - val_loss: 0.1191 - val_kl_loss: 158.1424 - val_recon_loss: 0.1191\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0968 - kl_loss: 151.7526 - recon_loss: 0.0968 - val_loss: 0.0623 - val_kl_loss: 157.4935 - val_recon_loss: 0.0623\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 86us/step - loss: 0.0923 - kl_loss: 152.3372 - recon_loss: 0.0923 - val_loss: 0.0761 - val_kl_loss: 156.8557 - val_recon_loss: 0.0761\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0961 - kl_loss: 152.4179 - recon_loss: 0.0961 - val_loss: 0.0841 - val_kl_loss: 157.2019 - val_recon_loss: 0.0841\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.0951 - kl_loss: 152.6191 - recon_loss: 0.0951 - val_loss: 0.1024 - val_kl_loss: 158.3364 - val_recon_loss: 0.1024\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0971 - kl_loss: 152.4987 - recon_loss: 0.0971 - val_loss: 0.1385 - val_kl_loss: 159.1561 - val_recon_loss: 0.1385\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0906 - kl_loss: 152.5749 - recon_loss: 0.0906 - val_loss: 0.2689 - val_kl_loss: 155.8391 - val_recon_loss: 0.2689\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0993 - kl_loss: 152.6050 - recon_loss: 0.0993 - val_loss: 0.0720 - val_kl_loss: 156.8846 - val_recon_loss: 0.0720\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0894 - kl_loss: 152.3684 - recon_loss: 0.0894 - val_loss: 0.0652 - val_kl_loss: 156.3705 - val_recon_loss: 0.0652\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.0900 - kl_loss: 152.4460 - recon_loss: 0.0900 - val_loss: 0.1399 - val_kl_loss: 156.7332 - val_recon_loss: 0.1399\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0964 - kl_loss: 152.3318 - recon_loss: 0.0964 - val_loss: 0.0785 - val_kl_loss: 156.8437 - val_recon_loss: 0.0785\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0922 - kl_loss: 152.2444 - recon_loss: 0.0922 - val_loss: 0.0733 - val_kl_loss: 157.1515 - val_recon_loss: 0.0733\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 89us/step - loss: 0.0975 - kl_loss: 152.1004 - recon_loss: 0.0975 - val_loss: 0.0596 - val_kl_loss: 157.3004 - val_recon_loss: 0.0596\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 89us/step - loss: 0.0886 - kl_loss: 152.4719 - recon_loss: 0.0886 - val_loss: 0.0752 - val_kl_loss: 157.9770 - val_recon_loss: 0.0752\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0939 - kl_loss: 152.5588 - recon_loss: 0.0939 - val_loss: 0.1724 - val_kl_loss: 159.1049 - val_recon_loss: 0.1724\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 88us/step - loss: 0.0872 - kl_loss: 152.2790 - recon_loss: 0.0872 - val_loss: 0.1459 - val_kl_loss: 156.8791 - val_recon_loss: 0.1459\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.0932 - kl_loss: 152.4537 - recon_loss: 0.0932 - val_loss: 0.2777 - val_kl_loss: 159.6856 - val_recon_loss: 0.2777\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0914 - kl_loss: 152.6005 - recon_loss: 0.0914 - val_loss: 0.2008 - val_kl_loss: 156.4844 - val_recon_loss: 0.2008\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.0937 - kl_loss: 152.4913 - recon_loss: 0.0937 - val_loss: 0.0909 - val_kl_loss: 156.5715 - val_recon_loss: 0.0909\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0889 - kl_loss: 152.7397 - recon_loss: 0.0889 - val_loss: 0.1082 - val_kl_loss: 156.9524 - val_recon_loss: 0.1082\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0909 - kl_loss: 152.2044 - recon_loss: 0.0909 - val_loss: 0.1004 - val_kl_loss: 158.1496 - val_recon_loss: 0.1004\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.0913 - kl_loss: 152.4418 - recon_loss: 0.0913 - val_loss: 0.0609 - val_kl_loss: 156.7123 - val_recon_loss: 0.0609\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.0896 - kl_loss: 152.4997 - recon_loss: 0.0896 - val_loss: 0.0981 - val_kl_loss: 157.7198 - val_recon_loss: 0.0981\n",
      "========================= Model11=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 11), (None,  2146        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 11)           0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1848        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,092\n",
      "Trainable params: 4,092\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 11)           143         enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 11)           143         enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,146\n",
      "Trainable params: 2,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 27)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           336         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,848\n",
      "Trainable params: 1,848\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 151us/step - loss: 25.6125 - kl_loss: 18.9624 - recon_loss: 25.6125 - val_loss: 7.6515 - val_kl_loss: 40.0091 - val_recon_loss: 7.6515\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 4.3144 - kl_loss: 50.6589 - recon_loss: 4.3144 - val_loss: 3.0005 - val_kl_loss: 64.9848 - val_recon_loss: 3.0005\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 2.3837 - kl_loss: 67.7443 - recon_loss: 2.3837 - val_loss: 1.7510 - val_kl_loss: 82.8384 - val_recon_loss: 1.7510\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 1.4553 - kl_loss: 81.9327 - recon_loss: 1.4553 - val_loss: 1.3261 - val_kl_loss: 91.3327 - val_recon_loss: 1.3261\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 1.1429 - kl_loss: 92.2507 - recon_loss: 1.1429 - val_loss: 0.9896 - val_kl_loss: 103.8081 - val_recon_loss: 0.9896\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.9607 - kl_loss: 99.7105 - recon_loss: 0.9607 - val_loss: 1.0005 - val_kl_loss: 107.5170 - val_recon_loss: 1.0005\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.8299 - kl_loss: 105.6764 - recon_loss: 0.8299 - val_loss: 0.7813 - val_kl_loss: 115.9373 - val_recon_loss: 0.7813\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.7412 - kl_loss: 108.9194 - recon_loss: 0.7412 - val_loss: 0.7504 - val_kl_loss: 116.6170 - val_recon_loss: 0.7504\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.6761 - kl_loss: 111.0147 - recon_loss: 0.6761 - val_loss: 0.6498 - val_kl_loss: 116.9742 - val_recon_loss: 0.6498\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.6526 - kl_loss: 111.6043 - recon_loss: 0.6526 - val_loss: 1.0024 - val_kl_loss: 117.1459 - val_recon_loss: 1.0024\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.6126 - kl_loss: 112.2495 - recon_loss: 0.6126 - val_loss: 0.7218 - val_kl_loss: 118.7860 - val_recon_loss: 0.7218\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.5849 - kl_loss: 112.3846 - recon_loss: 0.5849 - val_loss: 0.5712 - val_kl_loss: 118.6413 - val_recon_loss: 0.5712\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.5645 - kl_loss: 113.5445 - recon_loss: 0.5645 - val_loss: 0.6395 - val_kl_loss: 122.9890 - val_recon_loss: 0.6395\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.5358 - kl_loss: 114.4658 - recon_loss: 0.5358 - val_loss: 1.1030 - val_kl_loss: 124.5559 - val_recon_loss: 1.1030\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.5098 - kl_loss: 114.9076 - recon_loss: 0.5098 - val_loss: 0.5133 - val_kl_loss: 120.6377 - val_recon_loss: 0.5133\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.4892 - kl_loss: 114.6764 - recon_loss: 0.4892 - val_loss: 0.4855 - val_kl_loss: 122.1646 - val_recon_loss: 0.4855\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.4649 - kl_loss: 115.1473 - recon_loss: 0.4649 - val_loss: 0.5192 - val_kl_loss: 121.2951 - val_recon_loss: 0.5192\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.4411 - kl_loss: 115.7443 - recon_loss: 0.4411 - val_loss: 0.4161 - val_kl_loss: 121.7764 - val_recon_loss: 0.4161\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.4248 - kl_loss: 116.0684 - recon_loss: 0.4248 - val_loss: 0.3828 - val_kl_loss: 122.4998 - val_recon_loss: 0.3828\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.4095 - kl_loss: 116.2278 - recon_loss: 0.4095 - val_loss: 0.3861 - val_kl_loss: 122.8603 - val_recon_loss: 0.3861\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.3991 - kl_loss: 116.3672 - recon_loss: 0.3991 - val_loss: 0.3818 - val_kl_loss: 120.3004 - val_recon_loss: 0.3818\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.3801 - kl_loss: 116.8162 - recon_loss: 0.3801 - val_loss: 0.3797 - val_kl_loss: 122.5545 - val_recon_loss: 0.3797\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.3603 - kl_loss: 117.0782 - recon_loss: 0.3603 - val_loss: 0.9339 - val_kl_loss: 119.8904 - val_recon_loss: 0.9339\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.3511 - kl_loss: 118.6150 - recon_loss: 0.3511 - val_loss: 0.3415 - val_kl_loss: 125.3800 - val_recon_loss: 0.3415\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.3465 - kl_loss: 119.3826 - recon_loss: 0.3465 - val_loss: 0.3581 - val_kl_loss: 125.9753 - val_recon_loss: 0.3581\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.3359 - kl_loss: 120.6812 - recon_loss: 0.3359 - val_loss: 0.3640 - val_kl_loss: 122.9658 - val_recon_loss: 0.3640\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.3288 - kl_loss: 121.6103 - recon_loss: 0.3288 - val_loss: 0.5074 - val_kl_loss: 128.9261 - val_recon_loss: 0.5074\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.3128 - kl_loss: 122.1701 - recon_loss: 0.3128 - val_loss: 0.2672 - val_kl_loss: 127.1796 - val_recon_loss: 0.2672\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.3123 - kl_loss: 122.7143 - recon_loss: 0.3123 - val_loss: 0.2828 - val_kl_loss: 129.5220 - val_recon_loss: 0.2828\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2986 - kl_loss: 123.1275 - recon_loss: 0.2986 - val_loss: 0.8279 - val_kl_loss: 126.8808 - val_recon_loss: 0.8279\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 92us/step - loss: 0.2966 - kl_loss: 123.1383 - recon_loss: 0.2966 - val_loss: 0.2995 - val_kl_loss: 127.3952 - val_recon_loss: 0.2995\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.2941 - kl_loss: 123.1124 - recon_loss: 0.2941 - val_loss: 0.3556 - val_kl_loss: 127.5774 - val_recon_loss: 0.3556\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2834 - kl_loss: 124.0147 - recon_loss: 0.2834 - val_loss: 0.2268 - val_kl_loss: 129.2241 - val_recon_loss: 0.2268\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2744 - kl_loss: 124.0439 - recon_loss: 0.2744 - val_loss: 0.2272 - val_kl_loss: 128.5285 - val_recon_loss: 0.2272\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2681 - kl_loss: 123.8019 - recon_loss: 0.2681 - val_loss: 0.2776 - val_kl_loss: 128.9367 - val_recon_loss: 0.2776\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2672 - kl_loss: 123.7059 - recon_loss: 0.2672 - val_loss: 0.2597 - val_kl_loss: 128.1689 - val_recon_loss: 0.2597\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2578 - kl_loss: 123.4120 - recon_loss: 0.2578 - val_loss: 0.2561 - val_kl_loss: 129.5181 - val_recon_loss: 0.2561\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2551 - kl_loss: 122.9427 - recon_loss: 0.2551 - val_loss: 0.5803 - val_kl_loss: 127.3473 - val_recon_loss: 0.5803\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2470 - kl_loss: 122.6020 - recon_loss: 0.2470 - val_loss: 0.2048 - val_kl_loss: 127.8119 - val_recon_loss: 0.2048\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.2460 - kl_loss: 122.2191 - recon_loss: 0.2460 - val_loss: 0.2216 - val_kl_loss: 127.7098 - val_recon_loss: 0.2216\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2423 - kl_loss: 121.8743 - recon_loss: 0.2423 - val_loss: 0.2398 - val_kl_loss: 128.1310 - val_recon_loss: 0.2398\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2372 - kl_loss: 122.3662 - recon_loss: 0.2372 - val_loss: 0.2225 - val_kl_loss: 125.9529 - val_recon_loss: 0.2225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2336 - kl_loss: 121.6251 - recon_loss: 0.2336 - val_loss: 0.1987 - val_kl_loss: 126.3868 - val_recon_loss: 0.1987\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2377 - kl_loss: 120.9712 - recon_loss: 0.2377 - val_loss: 0.2702 - val_kl_loss: 125.8432 - val_recon_loss: 0.2702\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2271 - kl_loss: 120.9179 - recon_loss: 0.2271 - val_loss: 0.3129 - val_kl_loss: 124.7570 - val_recon_loss: 0.3129\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.2186 - kl_loss: 121.3932 - recon_loss: 0.2186 - val_loss: 0.2321 - val_kl_loss: 127.5294 - val_recon_loss: 0.2321\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 86us/step - loss: 0.2189 - kl_loss: 121.5111 - recon_loss: 0.2189 - val_loss: 0.1965 - val_kl_loss: 125.1113 - val_recon_loss: 0.1965\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2104 - kl_loss: 121.0970 - recon_loss: 0.2104 - val_loss: 0.2814 - val_kl_loss: 127.1177 - val_recon_loss: 0.2814\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2187 - kl_loss: 121.3617 - recon_loss: 0.2187 - val_loss: 0.3666 - val_kl_loss: 123.4952 - val_recon_loss: 0.3666\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.2039 - kl_loss: 121.2700 - recon_loss: 0.2039 - val_loss: 0.1799 - val_kl_loss: 126.3888 - val_recon_loss: 0.1799\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.2077 - kl_loss: 121.4933 - recon_loss: 0.2077 - val_loss: 0.3063 - val_kl_loss: 126.7635 - val_recon_loss: 0.3063\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2098 - kl_loss: 121.2629 - recon_loss: 0.2098 - val_loss: 0.2839 - val_kl_loss: 122.5160 - val_recon_loss: 0.2839\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1942 - kl_loss: 121.0054 - recon_loss: 0.1942 - val_loss: 0.2332 - val_kl_loss: 124.5823 - val_recon_loss: 0.2332\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2013 - kl_loss: 121.4371 - recon_loss: 0.2013 - val_loss: 0.1611 - val_kl_loss: 126.6214 - val_recon_loss: 0.1611\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1892 - kl_loss: 121.5055 - recon_loss: 0.1892 - val_loss: 0.2031 - val_kl_loss: 125.5889 - val_recon_loss: 0.2031\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1947 - kl_loss: 121.5190 - recon_loss: 0.1947 - val_loss: 0.2932 - val_kl_loss: 123.4384 - val_recon_loss: 0.2932\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1881 - kl_loss: 121.8280 - recon_loss: 0.1881 - val_loss: 0.3006 - val_kl_loss: 125.1947 - val_recon_loss: 0.3006\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1835 - kl_loss: 121.9604 - recon_loss: 0.1835 - val_loss: 0.3601 - val_kl_loss: 128.5583 - val_recon_loss: 0.3601\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1807 - kl_loss: 121.8974 - recon_loss: 0.1807 - val_loss: 0.2223 - val_kl_loss: 128.8788 - val_recon_loss: 0.2223\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1796 - kl_loss: 122.0378 - recon_loss: 0.1796 - val_loss: 0.1751 - val_kl_loss: 126.0630 - val_recon_loss: 0.1751\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1775 - kl_loss: 122.1443 - recon_loss: 0.1775 - val_loss: 0.2055 - val_kl_loss: 127.1195 - val_recon_loss: 0.2055\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1769 - kl_loss: 121.8415 - recon_loss: 0.1769 - val_loss: 0.3612 - val_kl_loss: 124.5891 - val_recon_loss: 0.3612\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1735 - kl_loss: 122.4434 - recon_loss: 0.1735 - val_loss: 0.3344 - val_kl_loss: 124.7409 - val_recon_loss: 0.3344\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1686 - kl_loss: 122.0442 - recon_loss: 0.1686 - val_loss: 0.2262 - val_kl_loss: 128.0913 - val_recon_loss: 0.2262\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1746 - kl_loss: 122.0598 - recon_loss: 0.1746 - val_loss: 0.1574 - val_kl_loss: 125.6420 - val_recon_loss: 0.1574\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1651 - kl_loss: 122.2301 - recon_loss: 0.1651 - val_loss: 0.2938 - val_kl_loss: 125.4724 - val_recon_loss: 0.2938\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1731 - kl_loss: 122.5320 - recon_loss: 0.1731 - val_loss: 0.1828 - val_kl_loss: 128.2119 - val_recon_loss: 0.1828\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1631 - kl_loss: 122.6813 - recon_loss: 0.1631 - val_loss: 0.1822 - val_kl_loss: 126.3912 - val_recon_loss: 0.1822\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1617 - kl_loss: 122.7377 - recon_loss: 0.1617 - val_loss: 0.1969 - val_kl_loss: 129.4709 - val_recon_loss: 0.1969\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1636 - kl_loss: 123.0608 - recon_loss: 0.1636 - val_loss: 0.2019 - val_kl_loss: 127.0375 - val_recon_loss: 0.2019\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1578 - kl_loss: 123.1906 - recon_loss: 0.1578 - val_loss: 0.2501 - val_kl_loss: 130.0298 - val_recon_loss: 0.2501\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1645 - kl_loss: 123.4137 - recon_loss: 0.1645 - val_loss: 0.1326 - val_kl_loss: 129.0034 - val_recon_loss: 0.1326\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1549 - kl_loss: 123.3050 - recon_loss: 0.1549 - val_loss: 0.1957 - val_kl_loss: 126.3173 - val_recon_loss: 0.1957\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1618 - kl_loss: 123.4597 - recon_loss: 0.1618 - val_loss: 0.1318 - val_kl_loss: 127.5229 - val_recon_loss: 0.1318\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1576 - kl_loss: 123.1525 - recon_loss: 0.1576 - val_loss: 0.4215 - val_kl_loss: 129.0811 - val_recon_loss: 0.4215\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1546 - kl_loss: 123.4654 - recon_loss: 0.1546 - val_loss: 0.2984 - val_kl_loss: 130.2784 - val_recon_loss: 0.2984\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1560 - kl_loss: 123.8264 - recon_loss: 0.1560 - val_loss: 0.1263 - val_kl_loss: 127.6369 - val_recon_loss: 0.1263\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1549 - kl_loss: 123.8028 - recon_loss: 0.1549 - val_loss: 0.1571 - val_kl_loss: 127.1162 - val_recon_loss: 0.1571\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1574 - kl_loss: 124.2359 - recon_loss: 0.1574 - val_loss: 0.1135 - val_kl_loss: 128.2585 - val_recon_loss: 0.1135\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1502 - kl_loss: 124.3395 - recon_loss: 0.1502 - val_loss: 0.1155 - val_kl_loss: 128.3403 - val_recon_loss: 0.1155\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1518 - kl_loss: 124.1909 - recon_loss: 0.1518 - val_loss: 0.1374 - val_kl_loss: 127.7864 - val_recon_loss: 0.1374\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1438 - kl_loss: 124.1320 - recon_loss: 0.1438 - val_loss: 0.3170 - val_kl_loss: 126.9407 - val_recon_loss: 0.3170\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1504 - kl_loss: 123.9214 - recon_loss: 0.1504 - val_loss: 0.2187 - val_kl_loss: 125.6444 - val_recon_loss: 0.2187\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1536 - kl_loss: 124.2765 - recon_loss: 0.1536 - val_loss: 0.1298 - val_kl_loss: 127.2365 - val_recon_loss: 0.1298\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1443 - kl_loss: 124.6366 - recon_loss: 0.1443 - val_loss: 0.2278 - val_kl_loss: 129.6938 - val_recon_loss: 0.2278\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1446 - kl_loss: 125.0049 - recon_loss: 0.1446 - val_loss: 0.1181 - val_kl_loss: 128.9447 - val_recon_loss: 0.1181\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1429 - kl_loss: 125.1732 - recon_loss: 0.1429 - val_loss: 0.3038 - val_kl_loss: 129.3500 - val_recon_loss: 0.3038\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1490 - kl_loss: 125.3258 - recon_loss: 0.1490 - val_loss: 0.1281 - val_kl_loss: 130.7325 - val_recon_loss: 0.1281\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1404 - kl_loss: 125.4903 - recon_loss: 0.1404 - val_loss: 0.2855 - val_kl_loss: 131.3134 - val_recon_loss: 0.2855\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1511 - kl_loss: 125.9655 - recon_loss: 0.1511 - val_loss: 0.3288 - val_kl_loss: 132.8872 - val_recon_loss: 0.3288\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 90us/step - loss: 0.1327 - kl_loss: 125.8357 - recon_loss: 0.1327 - val_loss: 0.1555 - val_kl_loss: 131.4453 - val_recon_loss: 0.1555\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1416 - kl_loss: 125.7543 - recon_loss: 0.1416 - val_loss: 0.1274 - val_kl_loss: 129.7543 - val_recon_loss: 0.1274\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1404 - kl_loss: 126.1036 - recon_loss: 0.1404 - val_loss: 0.1197 - val_kl_loss: 131.1966 - val_recon_loss: 0.1197\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1384 - kl_loss: 126.2423 - recon_loss: 0.1384 - val_loss: 0.5332 - val_kl_loss: 131.4395 - val_recon_loss: 0.5332\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 87us/step - loss: 0.1348 - kl_loss: 126.9837 - recon_loss: 0.1348 - val_loss: 0.1223 - val_kl_loss: 132.6287 - val_recon_loss: 0.1223\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1383 - kl_loss: 127.3172 - recon_loss: 0.1383 - val_loss: 0.3423 - val_kl_loss: 134.3407 - val_recon_loss: 0.3423\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1396 - kl_loss: 127.3179 - recon_loss: 0.1396 - val_loss: 0.2362 - val_kl_loss: 130.3213 - val_recon_loss: 0.2362\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1376 - kl_loss: 126.8212 - recon_loss: 0.1376 - val_loss: 0.2079 - val_kl_loss: 130.6662 - val_recon_loss: 0.2079\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1356 - kl_loss: 126.7031 - recon_loss: 0.1356 - val_loss: 0.1997 - val_kl_loss: 131.6370 - val_recon_loss: 0.1997\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1321 - kl_loss: 126.9469 - recon_loss: 0.1321 - val_loss: 0.1933 - val_kl_loss: 129.4251 - val_recon_loss: 0.1933\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1339 - kl_loss: 126.8220 - recon_loss: 0.1339 - val_loss: 0.2314 - val_kl_loss: 130.0903 - val_recon_loss: 0.2314\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1386 - kl_loss: 126.4507 - recon_loss: 0.1386 - val_loss: 0.1057 - val_kl_loss: 129.8491 - val_recon_loss: 0.1057\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1266 - kl_loss: 126.5331 - recon_loss: 0.1266 - val_loss: 0.2891 - val_kl_loss: 131.7121 - val_recon_loss: 0.2891\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1332 - kl_loss: 126.7963 - recon_loss: 0.1332 - val_loss: 0.2445 - val_kl_loss: 128.5937 - val_recon_loss: 0.2445\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1307 - kl_loss: 126.7557 - recon_loss: 0.1307 - val_loss: 0.1182 - val_kl_loss: 131.4644 - val_recon_loss: 0.1182\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1283 - kl_loss: 126.3334 - recon_loss: 0.1283 - val_loss: 0.1703 - val_kl_loss: 130.5297 - val_recon_loss: 0.1703\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1320 - kl_loss: 126.5054 - recon_loss: 0.1320 - val_loss: 0.1282 - val_kl_loss: 132.2118 - val_recon_loss: 0.1282\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1315 - kl_loss: 126.2191 - recon_loss: 0.1315 - val_loss: 0.1046 - val_kl_loss: 130.6733 - val_recon_loss: 0.1046\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1257 - kl_loss: 126.7247 - recon_loss: 0.1257 - val_loss: 0.1848 - val_kl_loss: 131.6586 - val_recon_loss: 0.1848\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 63us/step - loss: 0.1301 - kl_loss: 127.1605 - recon_loss: 0.1301 - val_loss: 0.1174 - val_kl_loss: 129.6617 - val_recon_loss: 0.1174\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 62us/step - loss: 0.1308 - kl_loss: 127.3055 - recon_loss: 0.1308 - val_loss: 0.0872 - val_kl_loss: 130.4838 - val_recon_loss: 0.0872\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 67us/step - loss: 0.1272 - kl_loss: 127.3837 - recon_loss: 0.1272 - val_loss: 0.1017 - val_kl_loss: 130.6107 - val_recon_loss: 0.1017\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1215 - kl_loss: 127.6816 - recon_loss: 0.1215 - val_loss: 0.1481 - val_kl_loss: 131.2345 - val_recon_loss: 0.1481\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1253 - kl_loss: 127.6728 - recon_loss: 0.1253 - val_loss: 0.0977 - val_kl_loss: 131.6741 - val_recon_loss: 0.0977\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1260 - kl_loss: 127.5043 - recon_loss: 0.1260 - val_loss: 0.2000 - val_kl_loss: 133.2759 - val_recon_loss: 0.2000\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1234 - kl_loss: 127.4826 - recon_loss: 0.1234 - val_loss: 0.1868 - val_kl_loss: 132.6552 - val_recon_loss: 0.1868\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1245 - kl_loss: 127.2093 - recon_loss: 0.1245 - val_loss: 0.1090 - val_kl_loss: 131.6327 - val_recon_loss: 0.1090\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1234 - kl_loss: 127.2500 - recon_loss: 0.1234 - val_loss: 0.1477 - val_kl_loss: 131.1075 - val_recon_loss: 0.1477\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1187 - kl_loss: 127.4537 - recon_loss: 0.1187 - val_loss: 0.2301 - val_kl_loss: 128.9871 - val_recon_loss: 0.2301\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1223 - kl_loss: 127.4793 - recon_loss: 0.1223 - val_loss: 0.0901 - val_kl_loss: 130.8170 - val_recon_loss: 0.0901\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1272 - kl_loss: 127.2073 - recon_loss: 0.1272 - val_loss: 0.0953 - val_kl_loss: 130.9264 - val_recon_loss: 0.0953\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1164 - kl_loss: 127.2368 - recon_loss: 0.1164 - val_loss: 0.2011 - val_kl_loss: 130.3160 - val_recon_loss: 0.2011\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1208 - kl_loss: 127.6661 - recon_loss: 0.1208 - val_loss: 0.1025 - val_kl_loss: 131.6546 - val_recon_loss: 0.1025\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1188 - kl_loss: 127.8395 - recon_loss: 0.1188 - val_loss: 0.1454 - val_kl_loss: 130.9839 - val_recon_loss: 0.1454\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1221 - kl_loss: 128.0215 - recon_loss: 0.1221 - val_loss: 0.0814 - val_kl_loss: 131.9000 - val_recon_loss: 0.0814\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1188 - kl_loss: 128.1067 - recon_loss: 0.1188 - val_loss: 0.1236 - val_kl_loss: 131.3043 - val_recon_loss: 0.1236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1186 - kl_loss: 128.3112 - recon_loss: 0.1186 - val_loss: 0.1328 - val_kl_loss: 132.3861 - val_recon_loss: 0.1328\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1204 - kl_loss: 128.3847 - recon_loss: 0.1204 - val_loss: 0.1192 - val_kl_loss: 130.3650 - val_recon_loss: 0.1192\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1185 - kl_loss: 128.1956 - recon_loss: 0.1185 - val_loss: 0.1031 - val_kl_loss: 131.0631 - val_recon_loss: 0.1031\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1230 - kl_loss: 127.9667 - recon_loss: 0.1230 - val_loss: 0.0905 - val_kl_loss: 132.0824 - val_recon_loss: 0.0905\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1130 - kl_loss: 128.5424 - recon_loss: 0.1130 - val_loss: 0.1527 - val_kl_loss: 133.6538 - val_recon_loss: 0.1527\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1187 - kl_loss: 128.8993 - recon_loss: 0.1187 - val_loss: 0.1138 - val_kl_loss: 131.4587 - val_recon_loss: 0.1138\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1158 - kl_loss: 128.8557 - recon_loss: 0.1158 - val_loss: 0.2350 - val_kl_loss: 136.0990 - val_recon_loss: 0.2350\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1165 - kl_loss: 129.0605 - recon_loss: 0.1165 - val_loss: 0.1829 - val_kl_loss: 131.9183 - val_recon_loss: 0.1829\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1179 - kl_loss: 128.5238 - recon_loss: 0.1179 - val_loss: 0.1884 - val_kl_loss: 134.0033 - val_recon_loss: 0.1884\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1194 - kl_loss: 128.7225 - recon_loss: 0.1194 - val_loss: 0.1046 - val_kl_loss: 132.1227 - val_recon_loss: 0.1046\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1059 - kl_loss: 128.7459 - recon_loss: 0.1059 - val_loss: 0.2784 - val_kl_loss: 134.5958 - val_recon_loss: 0.2784\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1161 - kl_loss: 128.4147 - recon_loss: 0.1161 - val_loss: 0.1077 - val_kl_loss: 132.9936 - val_recon_loss: 0.1077\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1154 - kl_loss: 128.5067 - recon_loss: 0.1154 - val_loss: 0.0832 - val_kl_loss: 132.7516 - val_recon_loss: 0.0832\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1103 - kl_loss: 128.7029 - recon_loss: 0.1103 - val_loss: 0.2693 - val_kl_loss: 130.2521 - val_recon_loss: 0.2693\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.1151 - kl_loss: 128.5003 - recon_loss: 0.1151 - val_loss: 0.2176 - val_kl_loss: 133.2061 - val_recon_loss: 0.2176\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1084 - kl_loss: 128.4532 - recon_loss: 0.1084 - val_loss: 0.2490 - val_kl_loss: 129.5457 - val_recon_loss: 0.2490\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1134 - kl_loss: 128.8885 - recon_loss: 0.1134 - val_loss: 0.0749 - val_kl_loss: 131.8207 - val_recon_loss: 0.0749\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1096 - kl_loss: 128.5603 - recon_loss: 0.1096 - val_loss: 0.1171 - val_kl_loss: 129.8714 - val_recon_loss: 0.1171\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1104 - kl_loss: 128.7118 - recon_loss: 0.1104 - val_loss: 0.2094 - val_kl_loss: 132.2224 - val_recon_loss: 0.2094\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1135 - kl_loss: 128.9541 - recon_loss: 0.1135 - val_loss: 0.1735 - val_kl_loss: 133.3461 - val_recon_loss: 0.1735\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1065 - kl_loss: 129.0376 - recon_loss: 0.1065 - val_loss: 0.0972 - val_kl_loss: 132.8036 - val_recon_loss: 0.0972\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1084 - kl_loss: 128.9275 - recon_loss: 0.1084 - val_loss: 0.0930 - val_kl_loss: 132.8774 - val_recon_loss: 0.0930\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1075 - kl_loss: 128.6932 - recon_loss: 0.1075 - val_loss: 0.1014 - val_kl_loss: 131.6462 - val_recon_loss: 0.1014\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1052 - kl_loss: 128.7293 - recon_loss: 0.1052 - val_loss: 0.2023 - val_kl_loss: 133.5219 - val_recon_loss: 0.2023\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1078 - kl_loss: 128.8212 - recon_loss: 0.1078 - val_loss: 0.0921 - val_kl_loss: 133.2178 - val_recon_loss: 0.0921\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.1081 - kl_loss: 129.5477 - recon_loss: 0.1081 - val_loss: 0.0756 - val_kl_loss: 133.6743 - val_recon_loss: 0.0756\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1078 - kl_loss: 129.5564 - recon_loss: 0.1078 - val_loss: 0.1600 - val_kl_loss: 135.0593 - val_recon_loss: 0.1600\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1035 - kl_loss: 129.9468 - recon_loss: 0.1035 - val_loss: 0.2186 - val_kl_loss: 135.3737 - val_recon_loss: 0.2186\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1046 - kl_loss: 129.9094 - recon_loss: 0.1046 - val_loss: 0.0819 - val_kl_loss: 133.5400 - val_recon_loss: 0.0819\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1059 - kl_loss: 130.0250 - recon_loss: 0.1059 - val_loss: 0.1911 - val_kl_loss: 131.9022 - val_recon_loss: 0.1911\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1087 - kl_loss: 130.2740 - recon_loss: 0.1087 - val_loss: 0.1306 - val_kl_loss: 134.5373 - val_recon_loss: 0.1306\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1086 - kl_loss: 130.0033 - recon_loss: 0.1086 - val_loss: 0.1292 - val_kl_loss: 133.6232 - val_recon_loss: 0.1292\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1005 - kl_loss: 129.6566 - recon_loss: 0.1005 - val_loss: 0.1088 - val_kl_loss: 132.6267 - val_recon_loss: 0.1088\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1030 - kl_loss: 130.1399 - recon_loss: 0.1030 - val_loss: 0.1339 - val_kl_loss: 133.7915 - val_recon_loss: 0.1339\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1078 - kl_loss: 130.5280 - recon_loss: 0.1078 - val_loss: 0.0739 - val_kl_loss: 133.3557 - val_recon_loss: 0.0739\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1041 - kl_loss: 130.1398 - recon_loss: 0.1041 - val_loss: 0.0700 - val_kl_loss: 134.5778 - val_recon_loss: 0.0700\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1052 - kl_loss: 130.3777 - recon_loss: 0.1052 - val_loss: 0.1070 - val_kl_loss: 135.6099 - val_recon_loss: 0.1070\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1014 - kl_loss: 130.8871 - recon_loss: 0.1014 - val_loss: 0.0774 - val_kl_loss: 134.2934 - val_recon_loss: 0.0774\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.0984 - kl_loss: 130.8390 - recon_loss: 0.0984 - val_loss: 0.1266 - val_kl_loss: 133.2641 - val_recon_loss: 0.1266\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1037 - kl_loss: 130.3639 - recon_loss: 0.1037 - val_loss: 0.1051 - val_kl_loss: 133.2319 - val_recon_loss: 0.1051\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1009 - kl_loss: 130.3032 - recon_loss: 0.1009 - val_loss: 0.1076 - val_kl_loss: 133.3457 - val_recon_loss: 0.1076\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1027 - kl_loss: 130.2954 - recon_loss: 0.1027 - val_loss: 0.1342 - val_kl_loss: 133.7018 - val_recon_loss: 0.1342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0989 - kl_loss: 129.9930 - recon_loss: 0.0989 - val_loss: 0.1216 - val_kl_loss: 132.9737 - val_recon_loss: 0.1216\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1059 - kl_loss: 130.2757 - recon_loss: 0.1059 - val_loss: 0.1506 - val_kl_loss: 136.2854 - val_recon_loss: 0.1506\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0964 - kl_loss: 130.6186 - recon_loss: 0.0964 - val_loss: 0.1349 - val_kl_loss: 134.6900 - val_recon_loss: 0.1349\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1001 - kl_loss: 130.1556 - recon_loss: 0.1001 - val_loss: 0.2910 - val_kl_loss: 134.1857 - val_recon_loss: 0.2910\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0982 - kl_loss: 129.6946 - recon_loss: 0.0982 - val_loss: 0.1607 - val_kl_loss: 132.2813 - val_recon_loss: 0.1607\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1004 - kl_loss: 129.3655 - recon_loss: 0.1004 - val_loss: 0.0772 - val_kl_loss: 132.9000 - val_recon_loss: 0.0772\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1010 - kl_loss: 129.7261 - recon_loss: 0.1010 - val_loss: 0.1111 - val_kl_loss: 133.3831 - val_recon_loss: 0.1111\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1004 - kl_loss: 129.5555 - recon_loss: 0.1004 - val_loss: 0.0674 - val_kl_loss: 133.3360 - val_recon_loss: 0.0674\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.0994 - kl_loss: 129.6222 - recon_loss: 0.0994 - val_loss: 0.0932 - val_kl_loss: 131.3003 - val_recon_loss: 0.0932\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0988 - kl_loss: 129.2157 - recon_loss: 0.0988 - val_loss: 0.0737 - val_kl_loss: 132.7658 - val_recon_loss: 0.0737\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0946 - kl_loss: 129.5441 - recon_loss: 0.0946 - val_loss: 0.1093 - val_kl_loss: 131.8835 - val_recon_loss: 0.1093\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0962 - kl_loss: 129.3936 - recon_loss: 0.0962 - val_loss: 0.1553 - val_kl_loss: 132.1412 - val_recon_loss: 0.1553\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0989 - kl_loss: 129.5308 - recon_loss: 0.0989 - val_loss: 0.0900 - val_kl_loss: 131.2922 - val_recon_loss: 0.0900\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1001 - kl_loss: 129.6559 - recon_loss: 0.1001 - val_loss: 0.1963 - val_kl_loss: 134.1075 - val_recon_loss: 0.1963\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.0955 - kl_loss: 129.8338 - recon_loss: 0.0955 - val_loss: 0.0917 - val_kl_loss: 134.1425 - val_recon_loss: 0.0917\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.0990 - kl_loss: 129.7652 - recon_loss: 0.0990 - val_loss: 0.0886 - val_kl_loss: 132.7749 - val_recon_loss: 0.0886\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0955 - kl_loss: 129.6730 - recon_loss: 0.0955 - val_loss: 0.0921 - val_kl_loss: 132.2067 - val_recon_loss: 0.0921\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0945 - kl_loss: 129.6986 - recon_loss: 0.0945 - val_loss: 0.1543 - val_kl_loss: 134.8952 - val_recon_loss: 0.1543\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.0971 - kl_loss: 130.1934 - recon_loss: 0.0971 - val_loss: 0.0746 - val_kl_loss: 133.9593 - val_recon_loss: 0.0746\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.0947 - kl_loss: 130.3759 - recon_loss: 0.0947 - val_loss: 0.0674 - val_kl_loss: 133.5307 - val_recon_loss: 0.0674\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0976 - kl_loss: 129.8092 - recon_loss: 0.0976 - val_loss: 0.1034 - val_kl_loss: 131.4872 - val_recon_loss: 0.1034\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0949 - kl_loss: 129.9182 - recon_loss: 0.0949 - val_loss: 0.0887 - val_kl_loss: 132.2882 - val_recon_loss: 0.0887\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.0927 - kl_loss: 129.9073 - recon_loss: 0.0927 - val_loss: 0.0652 - val_kl_loss: 132.9939 - val_recon_loss: 0.0652\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0926 - kl_loss: 130.1684 - recon_loss: 0.0926 - val_loss: 0.1065 - val_kl_loss: 133.6812 - val_recon_loss: 0.1065\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.0958 - kl_loss: 130.5706 - recon_loss: 0.0958 - val_loss: 0.1152 - val_kl_loss: 132.0923 - val_recon_loss: 0.1152\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.0933 - kl_loss: 130.6661 - recon_loss: 0.0933 - val_loss: 0.2614 - val_kl_loss: 134.7959 - val_recon_loss: 0.2614\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.0918 - kl_loss: 130.5832 - recon_loss: 0.0918 - val_loss: 0.0747 - val_kl_loss: 134.4396 - val_recon_loss: 0.0747\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.0914 - kl_loss: 130.4717 - recon_loss: 0.0914 - val_loss: 0.1212 - val_kl_loss: 133.4849 - val_recon_loss: 0.1212\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.0907 - kl_loss: 130.1729 - recon_loss: 0.0907 - val_loss: 0.1930 - val_kl_loss: 134.1053 - val_recon_loss: 0.1930\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0961 - kl_loss: 130.0835 - recon_loss: 0.0961 - val_loss: 0.0707 - val_kl_loss: 133.8486 - val_recon_loss: 0.0707\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.0913 - kl_loss: 130.5580 - recon_loss: 0.0913 - val_loss: 0.2094 - val_kl_loss: 135.0261 - val_recon_loss: 0.2094\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.0922 - kl_loss: 130.2204 - recon_loss: 0.0922 - val_loss: 0.0932 - val_kl_loss: 133.0972 - val_recon_loss: 0.0932\n",
      "========================= Model12=========================\n",
      "complete model: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "to_emb (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_pre (InputLayer)           (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Model)               (None, 2)            98          to_emb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_true (InputLayer)             (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conc_cond (Concatenate)         (None, 16)           0           cond_pre[0][0]                   \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 12), (None,  2172        x_true[0][0]                     \n",
      "                                                                 conc_cond[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sample_z (Lambda)               (None, 12)           0           encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 48)           1860        sample_z[0][0]                   \n",
      "                                                                 conc_cond[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,130\n",
      "Trainable params: 4,130\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "embedding: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "emb_input (InputLayer)       (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "emb_dense_last (Dense)       (None, 2)                 98        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_x_true (InputLayer)         (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (Concatenate)         (None, 64)           0           enc_x_true[0][0]                 \n",
      "                                                                 enc_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 24)           1560        enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_1 (Dense)             (None, 12)           300         enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_mu (Dense)         (None, 12)           156         enc_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense_log_sigma (Dense)  (None, 12)           156         enc_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,172\n",
      "Trainable params: 2,172\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "decoder: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_z (InputLayer)              (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_cond (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (Concatenate)         (None, 28)           0           dec_z[0][0]                      \n",
      "                                                                 dec_cond[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_0 (Dense)             (None, 12)           348         dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_dense_1 (Dense)             (None, 24)           312         dec_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_x_hat (Dense)               (None, 48)           1200        dec_dense_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,860\n",
      "Trainable params: 1,860\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "--- START TRAINING ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1465 samples, validate on 365 samples\n",
      "Epoch 1/200\n",
      "1465/1465 [==============================] - 0s 148us/step - loss: 27.5838 - kl_loss: 16.0719 - recon_loss: 27.5838 - val_loss: 9.1586 - val_kl_loss: 36.2791 - val_recon_loss: 9.1586\n",
      "Epoch 2/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 5.2632 - kl_loss: 39.5712 - recon_loss: 5.2632 - val_loss: 3.6029 - val_kl_loss: 53.7815 - val_recon_loss: 3.6029\n",
      "Epoch 3/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 2.9070 - kl_loss: 52.7672 - recon_loss: 2.9070 - val_loss: 2.6554 - val_kl_loss: 68.2264 - val_recon_loss: 2.6554\n",
      "Epoch 4/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 1.7706 - kl_loss: 66.2212 - recon_loss: 1.7706 - val_loss: 1.4504 - val_kl_loss: 87.3490 - val_recon_loss: 1.4504\n",
      "Epoch 5/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 1.2579 - kl_loss: 79.8635 - recon_loss: 1.2579 - val_loss: 1.2428 - val_kl_loss: 96.0330 - val_recon_loss: 1.2428\n",
      "Epoch 6/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 1.0289 - kl_loss: 91.6757 - recon_loss: 1.0289 - val_loss: 0.8710 - val_kl_loss: 108.6520 - val_recon_loss: 0.8710\n",
      "Epoch 7/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.8683 - kl_loss: 100.6933 - recon_loss: 0.8683 - val_loss: 0.8683 - val_kl_loss: 120.7075 - val_recon_loss: 0.8683\n",
      "Epoch 8/200\n",
      "1465/1465 [==============================] - 0s 87us/step - loss: 0.7607 - kl_loss: 108.0100 - recon_loss: 0.7607 - val_loss: 0.7493 - val_kl_loss: 122.2610 - val_recon_loss: 0.7493\n",
      "Epoch 9/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.6956 - kl_loss: 113.2851 - recon_loss: 0.6956 - val_loss: 0.7502 - val_kl_loss: 126.1064 - val_recon_loss: 0.7502\n",
      "Epoch 10/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.6455 - kl_loss: 117.9838 - recon_loss: 0.6455 - val_loss: 0.7067 - val_kl_loss: 132.1699 - val_recon_loss: 0.7067\n",
      "Epoch 11/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.5910 - kl_loss: 122.1345 - recon_loss: 0.5910 - val_loss: 0.7638 - val_kl_loss: 138.5673 - val_recon_loss: 0.7638\n",
      "Epoch 12/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.5613 - kl_loss: 124.5027 - recon_loss: 0.5613 - val_loss: 0.6780 - val_kl_loss: 137.0757 - val_recon_loss: 0.6780\n",
      "Epoch 13/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.5152 - kl_loss: 126.0781 - recon_loss: 0.5152 - val_loss: 0.5176 - val_kl_loss: 140.5411 - val_recon_loss: 0.5176\n",
      "Epoch 14/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.4762 - kl_loss: 127.2397 - recon_loss: 0.4762 - val_loss: 0.7106 - val_kl_loss: 140.3647 - val_recon_loss: 0.7106\n",
      "Epoch 15/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.4543 - kl_loss: 128.4271 - recon_loss: 0.4543 - val_loss: 0.4771 - val_kl_loss: 139.4581 - val_recon_loss: 0.4771\n",
      "Epoch 16/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.4226 - kl_loss: 128.3213 - recon_loss: 0.4226 - val_loss: 0.4503 - val_kl_loss: 138.5348 - val_recon_loss: 0.4503\n",
      "Epoch 17/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.3943 - kl_loss: 128.1042 - recon_loss: 0.3943 - val_loss: 1.0175 - val_kl_loss: 137.0542 - val_recon_loss: 1.0175\n",
      "Epoch 18/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.3731 - kl_loss: 128.2716 - recon_loss: 0.3731 - val_loss: 0.3179 - val_kl_loss: 139.8761 - val_recon_loss: 0.3179\n",
      "Epoch 19/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.3584 - kl_loss: 128.5887 - recon_loss: 0.3584 - val_loss: 0.3439 - val_kl_loss: 140.6872 - val_recon_loss: 0.3439\n",
      "Epoch 20/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.3320 - kl_loss: 128.4262 - recon_loss: 0.3320 - val_loss: 0.2869 - val_kl_loss: 138.5828 - val_recon_loss: 0.2869\n",
      "Epoch 21/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.3285 - kl_loss: 127.7938 - recon_loss: 0.3285 - val_loss: 0.4528 - val_kl_loss: 137.8535 - val_recon_loss: 0.4528\n",
      "Epoch 22/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.3175 - kl_loss: 128.6139 - recon_loss: 0.3175 - val_loss: 0.3159 - val_kl_loss: 141.0166 - val_recon_loss: 0.3159\n",
      "Epoch 23/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.3131 - kl_loss: 128.9572 - recon_loss: 0.3131 - val_loss: 0.3213 - val_kl_loss: 140.0056 - val_recon_loss: 0.3213\n",
      "Epoch 24/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.3062 - kl_loss: 129.5321 - recon_loss: 0.3062 - val_loss: 0.3136 - val_kl_loss: 141.3403 - val_recon_loss: 0.3136\n",
      "Epoch 25/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.2932 - kl_loss: 129.2817 - recon_loss: 0.2932 - val_loss: 0.2886 - val_kl_loss: 137.6064 - val_recon_loss: 0.2886\n",
      "Epoch 26/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2906 - kl_loss: 129.2595 - recon_loss: 0.2906 - val_loss: 0.3036 - val_kl_loss: 139.8626 - val_recon_loss: 0.3036\n",
      "Epoch 27/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2807 - kl_loss: 129.4954 - recon_loss: 0.2807 - val_loss: 0.3589 - val_kl_loss: 139.1698 - val_recon_loss: 0.3589\n",
      "Epoch 28/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2878 - kl_loss: 129.6754 - recon_loss: 0.2878 - val_loss: 0.4230 - val_kl_loss: 140.3460 - val_recon_loss: 0.4230\n",
      "Epoch 29/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2725 - kl_loss: 130.0345 - recon_loss: 0.2725 - val_loss: 0.3122 - val_kl_loss: 142.2552 - val_recon_loss: 0.3122\n",
      "Epoch 30/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2749 - kl_loss: 129.8680 - recon_loss: 0.2749 - val_loss: 0.4118 - val_kl_loss: 140.3291 - val_recon_loss: 0.4118\n",
      "Epoch 31/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2707 - kl_loss: 129.6900 - recon_loss: 0.2707 - val_loss: 0.4471 - val_kl_loss: 137.3169 - val_recon_loss: 0.4471\n",
      "Epoch 32/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2587 - kl_loss: 129.8878 - recon_loss: 0.2587 - val_loss: 0.3180 - val_kl_loss: 142.1898 - val_recon_loss: 0.3180\n",
      "Epoch 33/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2622 - kl_loss: 130.2573 - recon_loss: 0.2622 - val_loss: 0.3056 - val_kl_loss: 141.4356 - val_recon_loss: 0.3056\n",
      "Epoch 34/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2629 - kl_loss: 130.4165 - recon_loss: 0.2629 - val_loss: 0.3994 - val_kl_loss: 138.4153 - val_recon_loss: 0.3994\n",
      "Epoch 35/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.2516 - kl_loss: 130.7742 - recon_loss: 0.2516 - val_loss: 0.2057 - val_kl_loss: 140.3839 - val_recon_loss: 0.2057\n",
      "Epoch 36/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2466 - kl_loss: 130.6396 - recon_loss: 0.2466 - val_loss: 0.2556 - val_kl_loss: 141.8638 - val_recon_loss: 0.2556\n",
      "Epoch 37/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2484 - kl_loss: 130.4753 - recon_loss: 0.2484 - val_loss: 0.3448 - val_kl_loss: 137.2259 - val_recon_loss: 0.3448\n",
      "Epoch 38/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2452 - kl_loss: 129.7491 - recon_loss: 0.2452 - val_loss: 0.2919 - val_kl_loss: 137.4433 - val_recon_loss: 0.2919\n",
      "Epoch 39/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2498 - kl_loss: 129.0980 - recon_loss: 0.2498 - val_loss: 0.3734 - val_kl_loss: 135.4243 - val_recon_loss: 0.3734\n",
      "Epoch 40/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2322 - kl_loss: 129.2236 - recon_loss: 0.2322 - val_loss: 0.4023 - val_kl_loss: 137.6882 - val_recon_loss: 0.4023\n",
      "Epoch 41/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2397 - kl_loss: 128.9479 - recon_loss: 0.2397 - val_loss: 0.3561 - val_kl_loss: 142.6351 - val_recon_loss: 0.3561\n",
      "Epoch 42/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2353 - kl_loss: 129.6797 - recon_loss: 0.2353 - val_loss: 0.2468 - val_kl_loss: 139.5254 - val_recon_loss: 0.2468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.2276 - kl_loss: 129.8273 - recon_loss: 0.2276 - val_loss: 0.2385 - val_kl_loss: 140.9750 - val_recon_loss: 0.2385\n",
      "Epoch 44/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.2336 - kl_loss: 130.1440 - recon_loss: 0.2336 - val_loss: 0.2263 - val_kl_loss: 139.5326 - val_recon_loss: 0.2263\n",
      "Epoch 45/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2347 - kl_loss: 130.1587 - recon_loss: 0.2347 - val_loss: 0.2244 - val_kl_loss: 139.4347 - val_recon_loss: 0.2244\n",
      "Epoch 46/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.2236 - kl_loss: 130.1692 - recon_loss: 0.2236 - val_loss: 0.2288 - val_kl_loss: 140.8911 - val_recon_loss: 0.2288\n",
      "Epoch 47/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2228 - kl_loss: 130.3126 - recon_loss: 0.2228 - val_loss: 0.3808 - val_kl_loss: 143.6001 - val_recon_loss: 0.3808\n",
      "Epoch 48/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.2217 - kl_loss: 130.1825 - recon_loss: 0.2217 - val_loss: 0.2260 - val_kl_loss: 138.6842 - val_recon_loss: 0.2260\n",
      "Epoch 49/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.2180 - kl_loss: 130.0146 - recon_loss: 0.2180 - val_loss: 0.5259 - val_kl_loss: 134.1731 - val_recon_loss: 0.5259\n",
      "Epoch 50/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2186 - kl_loss: 129.9872 - recon_loss: 0.2186 - val_loss: 0.2462 - val_kl_loss: 140.2414 - val_recon_loss: 0.2462\n",
      "Epoch 51/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2168 - kl_loss: 130.3339 - recon_loss: 0.2168 - val_loss: 0.3707 - val_kl_loss: 141.3681 - val_recon_loss: 0.3707\n",
      "Epoch 52/200\n",
      "1465/1465 [==============================] - 0s 84us/step - loss: 0.2126 - kl_loss: 130.5073 - recon_loss: 0.2126 - val_loss: 0.2781 - val_kl_loss: 142.2154 - val_recon_loss: 0.2781\n",
      "Epoch 53/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.2126 - kl_loss: 130.3960 - recon_loss: 0.2126 - val_loss: 0.3197 - val_kl_loss: 138.3592 - val_recon_loss: 0.3197\n",
      "Epoch 54/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2114 - kl_loss: 130.2377 - recon_loss: 0.2114 - val_loss: 0.2522 - val_kl_loss: 141.3990 - val_recon_loss: 0.2522\n",
      "Epoch 55/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.2106 - kl_loss: 131.0289 - recon_loss: 0.2106 - val_loss: 0.2274 - val_kl_loss: 137.1868 - val_recon_loss: 0.2274\n",
      "Epoch 56/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2041 - kl_loss: 130.8858 - recon_loss: 0.2041 - val_loss: 0.2687 - val_kl_loss: 138.2131 - val_recon_loss: 0.2687\n",
      "Epoch 57/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.2118 - kl_loss: 131.7063 - recon_loss: 0.2118 - val_loss: 0.2098 - val_kl_loss: 139.9158 - val_recon_loss: 0.2098\n",
      "Epoch 58/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.2024 - kl_loss: 131.8906 - recon_loss: 0.2024 - val_loss: 0.3321 - val_kl_loss: 140.8086 - val_recon_loss: 0.3321\n",
      "Epoch 59/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.2071 - kl_loss: 131.5290 - recon_loss: 0.2071 - val_loss: 0.2010 - val_kl_loss: 141.4110 - val_recon_loss: 0.2010\n",
      "Epoch 60/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.2026 - kl_loss: 131.7221 - recon_loss: 0.2026 - val_loss: 0.1693 - val_kl_loss: 140.8498 - val_recon_loss: 0.1693\n",
      "Epoch 61/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1959 - kl_loss: 131.4920 - recon_loss: 0.1959 - val_loss: 0.4107 - val_kl_loss: 143.3019 - val_recon_loss: 0.4107\n",
      "Epoch 62/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.2016 - kl_loss: 130.9803 - recon_loss: 0.2016 - val_loss: 0.1935 - val_kl_loss: 140.1321 - val_recon_loss: 0.1935\n",
      "Epoch 63/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.2007 - kl_loss: 130.7458 - recon_loss: 0.2007 - val_loss: 0.2062 - val_kl_loss: 138.6210 - val_recon_loss: 0.2062\n",
      "Epoch 64/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1965 - kl_loss: 130.9481 - recon_loss: 0.1965 - val_loss: 0.7128 - val_kl_loss: 133.0882 - val_recon_loss: 0.7128\n",
      "Epoch 65/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1972 - kl_loss: 130.6704 - recon_loss: 0.1972 - val_loss: 0.1905 - val_kl_loss: 139.9314 - val_recon_loss: 0.1905\n",
      "Epoch 66/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1928 - kl_loss: 130.6321 - recon_loss: 0.1928 - val_loss: 0.2259 - val_kl_loss: 139.9239 - val_recon_loss: 0.2259\n",
      "Epoch 67/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1894 - kl_loss: 131.2728 - recon_loss: 0.1894 - val_loss: 0.4764 - val_kl_loss: 138.3449 - val_recon_loss: 0.4764\n",
      "Epoch 68/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1970 - kl_loss: 131.3323 - recon_loss: 0.1970 - val_loss: 0.2328 - val_kl_loss: 138.4238 - val_recon_loss: 0.2328\n",
      "Epoch 69/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1900 - kl_loss: 131.4402 - recon_loss: 0.1900 - val_loss: 0.2388 - val_kl_loss: 139.4905 - val_recon_loss: 0.2388\n",
      "Epoch 70/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1921 - kl_loss: 131.4966 - recon_loss: 0.1921 - val_loss: 0.1909 - val_kl_loss: 139.6210 - val_recon_loss: 0.1909\n",
      "Epoch 71/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1948 - kl_loss: 131.9554 - recon_loss: 0.1948 - val_loss: 0.1843 - val_kl_loss: 138.6578 - val_recon_loss: 0.1843\n",
      "Epoch 72/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1859 - kl_loss: 131.9151 - recon_loss: 0.1859 - val_loss: 0.3434 - val_kl_loss: 138.3583 - val_recon_loss: 0.3434\n",
      "Epoch 73/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1903 - kl_loss: 131.6782 - recon_loss: 0.1903 - val_loss: 0.1746 - val_kl_loss: 140.8042 - val_recon_loss: 0.1746\n",
      "Epoch 74/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1828 - kl_loss: 132.0259 - recon_loss: 0.1828 - val_loss: 0.3384 - val_kl_loss: 143.6482 - val_recon_loss: 0.3384\n",
      "Epoch 75/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1873 - kl_loss: 132.0168 - recon_loss: 0.1873 - val_loss: 0.1550 - val_kl_loss: 141.1041 - val_recon_loss: 0.1550\n",
      "Epoch 76/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1795 - kl_loss: 132.1368 - recon_loss: 0.1795 - val_loss: 0.1753 - val_kl_loss: 139.3867 - val_recon_loss: 0.1753\n",
      "Epoch 77/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1853 - kl_loss: 132.1012 - recon_loss: 0.1853 - val_loss: 0.2177 - val_kl_loss: 140.1789 - val_recon_loss: 0.2177\n",
      "Epoch 78/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1818 - kl_loss: 131.8921 - recon_loss: 0.1818 - val_loss: 0.3448 - val_kl_loss: 136.9575 - val_recon_loss: 0.3448\n",
      "Epoch 79/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1815 - kl_loss: 132.0649 - recon_loss: 0.1815 - val_loss: 0.1694 - val_kl_loss: 138.9057 - val_recon_loss: 0.1694\n",
      "Epoch 80/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1765 - kl_loss: 132.4686 - recon_loss: 0.1765 - val_loss: 0.2391 - val_kl_loss: 139.7983 - val_recon_loss: 0.2391\n",
      "Epoch 81/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1795 - kl_loss: 132.9348 - recon_loss: 0.1795 - val_loss: 0.1643 - val_kl_loss: 140.1190 - val_recon_loss: 0.1643\n",
      "Epoch 82/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1799 - kl_loss: 132.7735 - recon_loss: 0.1799 - val_loss: 0.2725 - val_kl_loss: 137.3106 - val_recon_loss: 0.2725\n",
      "Epoch 83/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1768 - kl_loss: 132.6393 - recon_loss: 0.1768 - val_loss: 0.1499 - val_kl_loss: 140.6150 - val_recon_loss: 0.1499\n",
      "Epoch 84/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1741 - kl_loss: 132.9403 - recon_loss: 0.1741 - val_loss: 0.2254 - val_kl_loss: 139.2596 - val_recon_loss: 0.2254\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1802 - kl_loss: 132.9595 - recon_loss: 0.1802 - val_loss: 0.1698 - val_kl_loss: 141.5449 - val_recon_loss: 0.1698\n",
      "Epoch 86/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1727 - kl_loss: 133.6486 - recon_loss: 0.1727 - val_loss: 0.1385 - val_kl_loss: 141.4768 - val_recon_loss: 0.1385\n",
      "Epoch 87/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1732 - kl_loss: 133.9079 - recon_loss: 0.1732 - val_loss: 0.5088 - val_kl_loss: 142.8435 - val_recon_loss: 0.5088\n",
      "Epoch 88/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1730 - kl_loss: 133.4982 - recon_loss: 0.1730 - val_loss: 0.2056 - val_kl_loss: 141.7392 - val_recon_loss: 0.2056\n",
      "Epoch 89/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1781 - kl_loss: 133.8215 - recon_loss: 0.1781 - val_loss: 0.1662 - val_kl_loss: 141.9176 - val_recon_loss: 0.1662\n",
      "Epoch 90/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1698 - kl_loss: 134.3930 - recon_loss: 0.1698 - val_loss: 0.1955 - val_kl_loss: 140.0924 - val_recon_loss: 0.1955\n",
      "Epoch 91/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1661 - kl_loss: 133.9200 - recon_loss: 0.1661 - val_loss: 0.1860 - val_kl_loss: 142.2576 - val_recon_loss: 0.1860\n",
      "Epoch 92/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1726 - kl_loss: 133.9991 - recon_loss: 0.1726 - val_loss: 0.2195 - val_kl_loss: 142.0540 - val_recon_loss: 0.2195\n",
      "Epoch 93/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1647 - kl_loss: 134.3674 - recon_loss: 0.1647 - val_loss: 0.1968 - val_kl_loss: 141.9016 - val_recon_loss: 0.1968\n",
      "Epoch 94/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1690 - kl_loss: 134.9538 - recon_loss: 0.1690 - val_loss: 0.2579 - val_kl_loss: 145.2211 - val_recon_loss: 0.2579\n",
      "Epoch 95/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1689 - kl_loss: 134.6953 - recon_loss: 0.1689 - val_loss: 0.1534 - val_kl_loss: 142.3641 - val_recon_loss: 0.1534\n",
      "Epoch 96/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1646 - kl_loss: 134.3419 - recon_loss: 0.1646 - val_loss: 0.2003 - val_kl_loss: 141.2115 - val_recon_loss: 0.2003\n",
      "Epoch 97/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1696 - kl_loss: 134.6187 - recon_loss: 0.1696 - val_loss: 0.1459 - val_kl_loss: 142.8603 - val_recon_loss: 0.1459\n",
      "Epoch 98/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1670 - kl_loss: 135.1519 - recon_loss: 0.1670 - val_loss: 0.2837 - val_kl_loss: 145.0611 - val_recon_loss: 0.2837\n",
      "Epoch 99/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1640 - kl_loss: 135.4230 - recon_loss: 0.1640 - val_loss: 0.2326 - val_kl_loss: 143.6624 - val_recon_loss: 0.2326\n",
      "Epoch 100/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1610 - kl_loss: 135.9431 - recon_loss: 0.1610 - val_loss: 0.2390 - val_kl_loss: 145.2571 - val_recon_loss: 0.2390\n",
      "Epoch 101/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1665 - kl_loss: 136.0785 - recon_loss: 0.1665 - val_loss: 0.1701 - val_kl_loss: 142.7562 - val_recon_loss: 0.1701\n",
      "Epoch 102/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1627 - kl_loss: 136.2641 - recon_loss: 0.1627 - val_loss: 0.1886 - val_kl_loss: 145.5138 - val_recon_loss: 0.1886\n",
      "Epoch 103/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1578 - kl_loss: 136.7804 - recon_loss: 0.1578 - val_loss: 0.3652 - val_kl_loss: 141.7777 - val_recon_loss: 0.3652\n",
      "Epoch 104/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1594 - kl_loss: 136.1726 - recon_loss: 0.1594 - val_loss: 0.1851 - val_kl_loss: 141.5181 - val_recon_loss: 0.1851\n",
      "Epoch 105/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1648 - kl_loss: 136.1695 - recon_loss: 0.1648 - val_loss: 0.1284 - val_kl_loss: 144.3489 - val_recon_loss: 0.1284\n",
      "Epoch 106/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1595 - kl_loss: 136.6407 - recon_loss: 0.1595 - val_loss: 0.1883 - val_kl_loss: 145.9399 - val_recon_loss: 0.1883\n",
      "Epoch 107/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1639 - kl_loss: 136.6780 - recon_loss: 0.1639 - val_loss: 0.1579 - val_kl_loss: 144.9614 - val_recon_loss: 0.1579\n",
      "Epoch 108/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1554 - kl_loss: 137.0165 - recon_loss: 0.1554 - val_loss: 0.2417 - val_kl_loss: 146.6611 - val_recon_loss: 0.2417\n",
      "Epoch 109/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1624 - kl_loss: 137.3816 - recon_loss: 0.1624 - val_loss: 0.1510 - val_kl_loss: 145.2217 - val_recon_loss: 0.1510\n",
      "Epoch 110/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1623 - kl_loss: 137.4680 - recon_loss: 0.1623 - val_loss: 0.1320 - val_kl_loss: 145.4373 - val_recon_loss: 0.1320\n",
      "Epoch 111/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1558 - kl_loss: 137.5215 - recon_loss: 0.1558 - val_loss: 0.1693 - val_kl_loss: 145.1464 - val_recon_loss: 0.1693\n",
      "Epoch 112/200\n",
      "1465/1465 [==============================] - 0s 65us/step - loss: 0.1568 - kl_loss: 137.4238 - recon_loss: 0.1568 - val_loss: 0.2235 - val_kl_loss: 145.1965 - val_recon_loss: 0.2235\n",
      "Epoch 113/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1557 - kl_loss: 138.1075 - recon_loss: 0.1557 - val_loss: 0.1861 - val_kl_loss: 144.8868 - val_recon_loss: 0.1861\n",
      "Epoch 114/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1600 - kl_loss: 138.5600 - recon_loss: 0.1600 - val_loss: 0.1357 - val_kl_loss: 146.7687 - val_recon_loss: 0.1357\n",
      "Epoch 115/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1505 - kl_loss: 138.9616 - recon_loss: 0.1505 - val_loss: 0.1357 - val_kl_loss: 146.7714 - val_recon_loss: 0.1357\n",
      "Epoch 116/200\n",
      "1465/1465 [==============================] - 0s 88us/step - loss: 0.1531 - kl_loss: 138.7690 - recon_loss: 0.1531 - val_loss: 0.1663 - val_kl_loss: 147.8348 - val_recon_loss: 0.1663\n",
      "Epoch 117/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1495 - kl_loss: 138.6479 - recon_loss: 0.1495 - val_loss: 0.1704 - val_kl_loss: 147.5383 - val_recon_loss: 0.1704\n",
      "Epoch 118/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1513 - kl_loss: 138.2904 - recon_loss: 0.1513 - val_loss: 0.1573 - val_kl_loss: 144.9059 - val_recon_loss: 0.1573\n",
      "Epoch 119/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1539 - kl_loss: 138.2124 - recon_loss: 0.1539 - val_loss: 0.2097 - val_kl_loss: 144.6210 - val_recon_loss: 0.2097\n",
      "Epoch 120/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1509 - kl_loss: 138.7548 - recon_loss: 0.1509 - val_loss: 0.1470 - val_kl_loss: 146.0511 - val_recon_loss: 0.1470\n",
      "Epoch 121/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1519 - kl_loss: 139.0130 - recon_loss: 0.1519 - val_loss: 0.2509 - val_kl_loss: 144.4664 - val_recon_loss: 0.2509\n",
      "Epoch 122/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1514 - kl_loss: 138.6462 - recon_loss: 0.1514 - val_loss: 0.1527 - val_kl_loss: 146.6884 - val_recon_loss: 0.1527\n",
      "Epoch 123/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1567 - kl_loss: 138.4437 - recon_loss: 0.1567 - val_loss: 0.1305 - val_kl_loss: 145.6473 - val_recon_loss: 0.1305\n",
      "Epoch 124/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1495 - kl_loss: 138.7915 - recon_loss: 0.1495 - val_loss: 0.2210 - val_kl_loss: 144.4581 - val_recon_loss: 0.2210\n",
      "Epoch 125/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1502 - kl_loss: 139.5162 - recon_loss: 0.1502 - val_loss: 0.1720 - val_kl_loss: 147.4100 - val_recon_loss: 0.1720\n",
      "Epoch 126/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1511 - kl_loss: 139.8601 - recon_loss: 0.1511 - val_loss: 0.1130 - val_kl_loss: 147.8231 - val_recon_loss: 0.1130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1529 - kl_loss: 140.4075 - recon_loss: 0.1529 - val_loss: 0.2250 - val_kl_loss: 150.1227 - val_recon_loss: 0.2250\n",
      "Epoch 128/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1443 - kl_loss: 141.0047 - recon_loss: 0.1443 - val_loss: 0.1442 - val_kl_loss: 148.7678 - val_recon_loss: 0.1442\n",
      "Epoch 129/200\n",
      "1465/1465 [==============================] - 0s 69us/step - loss: 0.1492 - kl_loss: 140.5149 - recon_loss: 0.1492 - val_loss: 0.2050 - val_kl_loss: 149.8277 - val_recon_loss: 0.2050\n",
      "Epoch 130/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1496 - kl_loss: 140.9577 - recon_loss: 0.1496 - val_loss: 0.2051 - val_kl_loss: 148.3938 - val_recon_loss: 0.2051\n",
      "Epoch 131/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1452 - kl_loss: 141.1647 - recon_loss: 0.1452 - val_loss: 0.3316 - val_kl_loss: 148.4791 - val_recon_loss: 0.3316\n",
      "Epoch 132/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1444 - kl_loss: 141.2011 - recon_loss: 0.1444 - val_loss: 0.1540 - val_kl_loss: 149.7817 - val_recon_loss: 0.1540\n",
      "Epoch 133/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1473 - kl_loss: 141.6042 - recon_loss: 0.1473 - val_loss: 0.1347 - val_kl_loss: 148.3344 - val_recon_loss: 0.1347\n",
      "Epoch 134/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1419 - kl_loss: 141.4930 - recon_loss: 0.1419 - val_loss: 0.1462 - val_kl_loss: 150.0310 - val_recon_loss: 0.1462\n",
      "Epoch 135/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1451 - kl_loss: 141.6316 - recon_loss: 0.1451 - val_loss: 0.4145 - val_kl_loss: 150.2329 - val_recon_loss: 0.4145\n",
      "Epoch 136/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1464 - kl_loss: 141.8716 - recon_loss: 0.1464 - val_loss: 0.1359 - val_kl_loss: 149.8529 - val_recon_loss: 0.1359\n",
      "Epoch 137/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1421 - kl_loss: 142.3053 - recon_loss: 0.1421 - val_loss: 0.3127 - val_kl_loss: 146.9149 - val_recon_loss: 0.3127\n",
      "Epoch 138/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1457 - kl_loss: 142.3336 - recon_loss: 0.1457 - val_loss: 0.2271 - val_kl_loss: 148.6407 - val_recon_loss: 0.2271\n",
      "Epoch 139/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1378 - kl_loss: 142.3049 - recon_loss: 0.1378 - val_loss: 0.1993 - val_kl_loss: 147.8804 - val_recon_loss: 0.1993\n",
      "Epoch 140/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1421 - kl_loss: 142.1252 - recon_loss: 0.1421 - val_loss: 0.3244 - val_kl_loss: 148.3311 - val_recon_loss: 0.3244\n",
      "Epoch 141/200\n",
      "1465/1465 [==============================] - 0s 81us/step - loss: 0.1392 - kl_loss: 142.7459 - recon_loss: 0.1392 - val_loss: 0.2410 - val_kl_loss: 152.8718 - val_recon_loss: 0.2410\n",
      "Epoch 142/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1468 - kl_loss: 142.9573 - recon_loss: 0.1468 - val_loss: 0.1701 - val_kl_loss: 148.8679 - val_recon_loss: 0.1701\n",
      "Epoch 143/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1415 - kl_loss: 142.6045 - recon_loss: 0.1415 - val_loss: 0.1248 - val_kl_loss: 149.7804 - val_recon_loss: 0.1248\n",
      "Epoch 144/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1401 - kl_loss: 142.1033 - recon_loss: 0.1401 - val_loss: 0.2886 - val_kl_loss: 150.8538 - val_recon_loss: 0.2886\n",
      "Epoch 145/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1381 - kl_loss: 142.1757 - recon_loss: 0.1381 - val_loss: 0.1289 - val_kl_loss: 150.8387 - val_recon_loss: 0.1289\n",
      "Epoch 146/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1407 - kl_loss: 142.5896 - recon_loss: 0.1407 - val_loss: 0.1520 - val_kl_loss: 150.2499 - val_recon_loss: 0.1520\n",
      "Epoch 147/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1386 - kl_loss: 142.4875 - recon_loss: 0.1386 - val_loss: 0.1195 - val_kl_loss: 150.1943 - val_recon_loss: 0.1195\n",
      "Epoch 148/200\n",
      "1465/1465 [==============================] - 0s 82us/step - loss: 0.1427 - kl_loss: 142.3079 - recon_loss: 0.1427 - val_loss: 0.2448 - val_kl_loss: 147.9643 - val_recon_loss: 0.2448\n",
      "Epoch 149/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1379 - kl_loss: 142.4614 - recon_loss: 0.1379 - val_loss: 0.2192 - val_kl_loss: 148.8524 - val_recon_loss: 0.2192\n",
      "Epoch 150/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1325 - kl_loss: 142.6837 - recon_loss: 0.1325 - val_loss: 0.2852 - val_kl_loss: 154.0589 - val_recon_loss: 0.2852\n",
      "Epoch 151/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1349 - kl_loss: 143.3640 - recon_loss: 0.1349 - val_loss: 0.2288 - val_kl_loss: 150.5736 - val_recon_loss: 0.2288\n",
      "Epoch 152/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1436 - kl_loss: 143.1566 - recon_loss: 0.1436 - val_loss: 0.1234 - val_kl_loss: 149.8147 - val_recon_loss: 0.1234\n",
      "Epoch 153/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1392 - kl_loss: 142.9751 - recon_loss: 0.1392 - val_loss: 0.1352 - val_kl_loss: 150.1648 - val_recon_loss: 0.1352\n",
      "Epoch 154/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1339 - kl_loss: 142.9477 - recon_loss: 0.1339 - val_loss: 0.1405 - val_kl_loss: 149.1860 - val_recon_loss: 0.1405\n",
      "Epoch 155/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1327 - kl_loss: 142.5141 - recon_loss: 0.1327 - val_loss: 0.2880 - val_kl_loss: 147.0623 - val_recon_loss: 0.2880\n",
      "Epoch 156/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1428 - kl_loss: 142.5727 - recon_loss: 0.1428 - val_loss: 0.1002 - val_kl_loss: 149.6480 - val_recon_loss: 0.1002\n",
      "Epoch 157/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1286 - kl_loss: 143.0032 - recon_loss: 0.1286 - val_loss: 0.1396 - val_kl_loss: 150.6955 - val_recon_loss: 0.1396\n",
      "Epoch 158/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1345 - kl_loss: 143.1224 - recon_loss: 0.1345 - val_loss: 0.1250 - val_kl_loss: 151.3656 - val_recon_loss: 0.1250\n",
      "Epoch 159/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1350 - kl_loss: 142.8497 - recon_loss: 0.1350 - val_loss: 0.1195 - val_kl_loss: 150.3400 - val_recon_loss: 0.1195\n",
      "Epoch 160/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1372 - kl_loss: 143.2237 - recon_loss: 0.1372 - val_loss: 0.1766 - val_kl_loss: 151.0327 - val_recon_loss: 0.1766\n",
      "Epoch 161/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1302 - kl_loss: 143.4419 - recon_loss: 0.1302 - val_loss: 0.1458 - val_kl_loss: 150.6480 - val_recon_loss: 0.1458\n",
      "Epoch 162/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1390 - kl_loss: 143.0640 - recon_loss: 0.1390 - val_loss: 0.1178 - val_kl_loss: 149.5319 - val_recon_loss: 0.1178\n",
      "Epoch 163/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1311 - kl_loss: 142.7877 - recon_loss: 0.1311 - val_loss: 0.1385 - val_kl_loss: 149.8490 - val_recon_loss: 0.1385\n",
      "Epoch 164/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1283 - kl_loss: 142.7725 - recon_loss: 0.1283 - val_loss: 0.2777 - val_kl_loss: 151.5170 - val_recon_loss: 0.2777\n",
      "Epoch 165/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1344 - kl_loss: 143.0514 - recon_loss: 0.1344 - val_loss: 0.3446 - val_kl_loss: 151.9846 - val_recon_loss: 0.3446\n",
      "Epoch 166/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1276 - kl_loss: 143.3423 - recon_loss: 0.1276 - val_loss: 0.1166 - val_kl_loss: 150.8894 - val_recon_loss: 0.1166\n",
      "Epoch 167/200\n",
      "1465/1465 [==============================] - 0s 79us/step - loss: 0.1324 - kl_loss: 143.0364 - recon_loss: 0.1324 - val_loss: 0.0948 - val_kl_loss: 150.2537 - val_recon_loss: 0.0948\n",
      "Epoch 168/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1236 - kl_loss: 143.3225 - recon_loss: 0.1236 - val_loss: 0.1126 - val_kl_loss: 150.9385 - val_recon_loss: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "1465/1465 [==============================] - 0s 71us/step - loss: 0.1319 - kl_loss: 142.8920 - recon_loss: 0.1319 - val_loss: 0.1028 - val_kl_loss: 150.2756 - val_recon_loss: 0.1028\n",
      "Epoch 170/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1252 - kl_loss: 143.0119 - recon_loss: 0.1252 - val_loss: 0.1126 - val_kl_loss: 149.5390 - val_recon_loss: 0.1126\n",
      "Epoch 171/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1263 - kl_loss: 143.1437 - recon_loss: 0.1263 - val_loss: 0.1641 - val_kl_loss: 148.5875 - val_recon_loss: 0.1641\n",
      "Epoch 172/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1239 - kl_loss: 143.0285 - recon_loss: 0.1239 - val_loss: 0.1217 - val_kl_loss: 150.2891 - val_recon_loss: 0.1217\n",
      "Epoch 173/200\n",
      "1465/1465 [==============================] - 0s 70us/step - loss: 0.1248 - kl_loss: 143.6516 - recon_loss: 0.1248 - val_loss: 0.1387 - val_kl_loss: 151.0904 - val_recon_loss: 0.1387\n",
      "Epoch 174/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1198 - kl_loss: 144.1106 - recon_loss: 0.1198 - val_loss: 0.1303 - val_kl_loss: 152.5175 - val_recon_loss: 0.1303\n",
      "Epoch 175/200\n",
      "1465/1465 [==============================] - 0s 73us/step - loss: 0.1176 - kl_loss: 144.2357 - recon_loss: 0.1176 - val_loss: 0.0952 - val_kl_loss: 151.0399 - val_recon_loss: 0.0952\n",
      "Epoch 176/200\n",
      "1465/1465 [==============================] - 0s 68us/step - loss: 0.1174 - kl_loss: 143.6020 - recon_loss: 0.1174 - val_loss: 0.0902 - val_kl_loss: 151.7517 - val_recon_loss: 0.0902\n",
      "Epoch 177/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1174 - kl_loss: 144.2288 - recon_loss: 0.1174 - val_loss: 0.1511 - val_kl_loss: 148.9934 - val_recon_loss: 0.1511\n",
      "Epoch 178/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1153 - kl_loss: 143.9781 - recon_loss: 0.1153 - val_loss: 0.1069 - val_kl_loss: 149.8763 - val_recon_loss: 0.1069\n",
      "Epoch 179/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1209 - kl_loss: 144.2092 - recon_loss: 0.1209 - val_loss: 0.3468 - val_kl_loss: 152.9482 - val_recon_loss: 0.3468\n",
      "Epoch 180/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1162 - kl_loss: 144.6558 - recon_loss: 0.1162 - val_loss: 0.0882 - val_kl_loss: 151.4807 - val_recon_loss: 0.0882\n",
      "Epoch 181/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1179 - kl_loss: 144.5962 - recon_loss: 0.1179 - val_loss: 0.1141 - val_kl_loss: 151.5262 - val_recon_loss: 0.1141\n",
      "Epoch 182/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1149 - kl_loss: 145.0367 - recon_loss: 0.1149 - val_loss: 0.0941 - val_kl_loss: 152.1407 - val_recon_loss: 0.0941\n",
      "Epoch 183/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1173 - kl_loss: 145.3277 - recon_loss: 0.1173 - val_loss: 0.1228 - val_kl_loss: 153.5594 - val_recon_loss: 0.1228\n",
      "Epoch 184/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1163 - kl_loss: 145.4840 - recon_loss: 0.1163 - val_loss: 0.1728 - val_kl_loss: 153.8155 - val_recon_loss: 0.1728\n",
      "Epoch 185/200\n",
      "1465/1465 [==============================] - 0s 61us/step - loss: 0.1159 - kl_loss: 145.6107 - recon_loss: 0.1159 - val_loss: 0.1156 - val_kl_loss: 152.1253 - val_recon_loss: 0.1156\n",
      "Epoch 186/200\n",
      "1465/1465 [==============================] - 0s 64us/step - loss: 0.1094 - kl_loss: 145.5521 - recon_loss: 0.1094 - val_loss: 0.1788 - val_kl_loss: 154.1673 - val_recon_loss: 0.1788\n",
      "Epoch 187/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1191 - kl_loss: 145.7744 - recon_loss: 0.1191 - val_loss: 0.1666 - val_kl_loss: 153.4528 - val_recon_loss: 0.1666\n",
      "Epoch 188/200\n",
      "1465/1465 [==============================] - 0s 72us/step - loss: 0.1193 - kl_loss: 146.2270 - recon_loss: 0.1193 - val_loss: 0.1388 - val_kl_loss: 151.5827 - val_recon_loss: 0.1388\n",
      "Epoch 189/200\n",
      "1465/1465 [==============================] - 0s 85us/step - loss: 0.1052 - kl_loss: 146.6054 - recon_loss: 0.1052 - val_loss: 0.1829 - val_kl_loss: 154.8234 - val_recon_loss: 0.1829\n",
      "Epoch 190/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1149 - kl_loss: 146.9060 - recon_loss: 0.1149 - val_loss: 0.1039 - val_kl_loss: 153.7605 - val_recon_loss: 0.1039\n",
      "Epoch 191/200\n",
      "1465/1465 [==============================] - 0s 74us/step - loss: 0.1080 - kl_loss: 147.1576 - recon_loss: 0.1080 - val_loss: 0.2173 - val_kl_loss: 151.8089 - val_recon_loss: 0.2173\n",
      "Epoch 192/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1143 - kl_loss: 147.4521 - recon_loss: 0.1143 - val_loss: 0.1013 - val_kl_loss: 153.6111 - val_recon_loss: 0.1013\n",
      "Epoch 193/200\n",
      "1465/1465 [==============================] - 0s 83us/step - loss: 0.1084 - kl_loss: 147.4134 - recon_loss: 0.1084 - val_loss: 0.0859 - val_kl_loss: 154.8290 - val_recon_loss: 0.0859\n",
      "Epoch 194/200\n",
      "1465/1465 [==============================] - 0s 76us/step - loss: 0.1104 - kl_loss: 147.3452 - recon_loss: 0.1104 - val_loss: 0.1107 - val_kl_loss: 154.7393 - val_recon_loss: 0.1107\n",
      "Epoch 195/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1116 - kl_loss: 147.6802 - recon_loss: 0.1116 - val_loss: 0.0850 - val_kl_loss: 154.6089 - val_recon_loss: 0.0850\n",
      "Epoch 196/200\n",
      "1465/1465 [==============================] - 0s 78us/step - loss: 0.1050 - kl_loss: 147.8975 - recon_loss: 0.1050 - val_loss: 0.1233 - val_kl_loss: 154.7903 - val_recon_loss: 0.1233\n",
      "Epoch 197/200\n",
      "1465/1465 [==============================] - 0s 77us/step - loss: 0.1076 - kl_loss: 148.2621 - recon_loss: 0.1076 - val_loss: 0.1687 - val_kl_loss: 153.1915 - val_recon_loss: 0.1687\n",
      "Epoch 198/200\n",
      "1465/1465 [==============================] - 0s 80us/step - loss: 0.1083 - kl_loss: 148.6675 - recon_loss: 0.1083 - val_loss: 0.1082 - val_kl_loss: 154.4751 - val_recon_loss: 0.1082\n",
      "Epoch 199/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1083 - kl_loss: 148.3295 - recon_loss: 0.1083 - val_loss: 0.1565 - val_kl_loss: 154.3532 - val_recon_loss: 0.1565\n",
      "Epoch 200/200\n",
      "1465/1465 [==============================] - 0s 75us/step - loss: 0.1081 - kl_loss: 148.4964 - recon_loss: 0.1081 - val_loss: 0.2642 - val_kl_loss: 156.7740 - val_recon_loss: 0.2642\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34f30c3278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, z_dim in enumerate(z_dims):\n",
    "        \n",
    "    print('========================= Model{}========================='.format(idx+1))\n",
    "\n",
    "    # Prepare model characteristics\n",
    "    name_model = 'cae_z{}_conso_temp-emb_e48-24-12_d12-24-48_gran-{}_x-{}_cond-{}'.format(z_dim,name_granu,name_type_x, name_type_cond)\n",
    "    \n",
    "    \n",
    "    # Compile model\n",
    "    model = CVAE_temp(input_dim=input_dim,\n",
    "              to_emb_dim=to_emb_dim,\n",
    "              cond_pre_dim=cond_pre_dim, \n",
    "              e_dims=e_dims, \n",
    "              d_dims=d_dims, \n",
    "              emb_dims=emb_dims,\n",
    "              z_dim=z_dim, \n",
    "              beta=beta,\n",
    "              name=name_model, \n",
    "              output=path_benchmark)\n",
    "\n",
    "    tensorboard_model = TensorBoard(log_dir=os.path.join(path_benchmark, name_model, 'results', 'logs', time.strftime('%Y-%m-%d_%H:%M', time.localtime(time.time()))))\n",
    "    tensorboard_summary = TensorBoard(log_dir=os.path.join(path_benchmark, 'logs', name_model))\n",
    "\n",
    "    callbacks = []\n",
    "    callbacks.append(tensorboard_model)\n",
    "    callbacks.append(tensorboard_summary)\n",
    "\n",
    "    # Train model\n",
    "    model.main_train(dataset, training_epochs=200, batch_size=batch_size, verbose=False, callbacks=callbacks)      \n",
    "\n",
    "    history = model.history\n",
    "    best_iter = np.argmin(history['val_loss'])\n",
    "    \n",
    "    # result\n",
    "    result = {\n",
    "        'name': 'model_{}'.format(idx+1),\n",
    "        'z_dim': z_dim,\n",
    "        'emb_dims': emb_dims,\n",
    "        'layer_dims': e_dims,\n",
    "        'batchsize': batch_size,\n",
    "        'best_iter': best_iter,\n",
    "        'train_mse': history['loss'][best_iter],\n",
    "        'test_mse': history['val_loss'][best_iter],\n",
    "        'last_train_mse': history['loss'][-1],\n",
    "        'last_test_mse': history['val_loss'][-1]\n",
    "    }\n",
    "\n",
    "    results_df= results_df.append(result, ignore_index=True)\n",
    "    results_df.to_csv(os.path.join(path_results, 'main_results.csv'), sep=';')\n",
    "\n",
    "    # Reset graph\n",
    "    K.clear_session()\n",
    "    import tensorflow as tf\n",
    "    tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history['recon_loss'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_set_plot = 'train'\n",
    "version = '-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1830, 48)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['x'][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_emb = model.embedding.predict(dataset['train']['x'][2])\n",
    "cond_pre = dataset['train']['x'][1]\n",
    "cond = np.concatenate((cond_pre, temp_emb), axis=1)\n",
    "\n",
    "x_input = dataset['train']['x'][0]\n",
    "\n",
    "input_encoder = [x_input, cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fcc7a4d8358>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc83029748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(temp_emb[:,0], temp_emb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_encoded = model.encoder.predict(input_encoder)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-sne if latent space more than 2 dimension\n",
    "x_encoded = TSNE(n_components=2).fit_transform(x_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_info = pd.DataFrame(dataset[name_set_plot]['ds'])\n",
    "calendar_info['month'] = calendar_info.ds.dt.month\n",
    "calendar_info['weekday'] = calendar_info.ds.dt.weekday\n",
    "calendar_info['is_weekday'] = (calendar_info.weekday < 5).apply(lambda x:int(x))\n",
    "calendar_info = pd.merge(calendar_info, holiday_days_df[['ds', 'is_hd']], on='ds', how ='left')\n",
    "calendar_info.loc[calendar_info['is_hd'].isna(),'is_hd'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc7a5d3080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name_plot = 'emb{}_z{}_n-{}_beta-{}_train-{}_set-{}_cond-{}{}'.format(str(emb_dims[-1]),str(z_dim),type_scaler,str(beta), name_train, name_set_plot,str(name_type_cond),version)\n",
    "plot_latent_space_projection(x_proj=x_encoded, calendar_info=calendar_info,\n",
    "                             path_folder_out=os.path.join(path_out,name_model,'results'), name=name_plot, \n",
    "                             pyplot=True, plotly = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = get_cond_autoencoder(dataset['train']['x'],dataset['train']['ds'], type_cond=['temp'], data_conso_df=data_conso_df)\n",
    "temp = temp.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc7a566710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name_plot = 'emb{}_temp_z{}_n-{}_beta-{}_train-{}_set-{}_cond-{}{}'.format(str(emb_dims[-1]),str(z_dim),type_scaler,str(beta), name_train, name_set_plot,str(name_type_cond),version)\n",
    "pyplot_latent_space_projection_temp(x_encoded, calendar_info, temp,os.path.join(path_out,name_model,'results'), name_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
